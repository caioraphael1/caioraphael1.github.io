<!doctype html>
<html
	lang="en" >
	<head>
		<title>
            Caio Raphael
		</title>
		<meta
			charset="utf-8" >
		<meta
			name="viewport" 
			content="width=device-width, initial-scale=1" >
		<meta
			name="description" 
			content="Senior Game Developer, Engine Developer, Low-Level Network, Low-Level Systems" >
		<meta
			name="author" 
			content="Caio Raphael" >
		<meta
			name="theme-color" 
			content="#ffffff" 
			media="(prefers-color-scheme: light)" >
		<meta
			name="theme-color" 
			content="#101010" 
			media="(prefers-color-scheme: dark)" >
		<link
			rel="icon" 
			href="/assets/icon.ico" >
		<link
			rel="icon" 
			href="/assets/icon-16x16.png" 
			sizes="16x16" 
			type="image/png" >
		<link
			rel="icon" 
			href="/assets/icon-32x32.png" 
			sizes="32x32" 
			type="image/png" >
		<script>
window.MathJax = {
                tex: {
                    inlineMath: [['$', '$']],
                    displayMath: [['$$', '$$']]
                }
                };
		</script>
		<script
			src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" >
		</script>
		<script
			type="module" >

                    import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.11.1/es/highlight.min.js';
                    import hljs_odin from 'https://unpkg.com/highlightjs-odinlang@1.4.0/dist/odin.es.min.js';
                    import hljs_glsl from 'https://unpkg.com/@highlightjs/cdn-assets@11.11.1/es/languages/glsl.min.js';
                    import hljs_swift  from 'https://unpkg.com/@highlightjs/cdn-assets@11.11.1/es/languages/swift.min.js';
                    hljs.registerLanguage('odin', hljs_odin);
                    hljs.registerLanguage('glsl', hljs_glsl);
                    hljs.registerLanguage('gdscript', hljs_swift);
                    hljs.highlightAll();
                
		</script>
		<link
			rel="stylesheet" 
			href="/static/studies.36380.css" >
	</head>
	<body>
		<aside
			id="left-sidebar" >
			<a
				href="/" 
				class="site-logo" >
                Caio Raphael
			</a>
			<nav>
				<details
					open="">
					<summary>
                        Odin
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/about.html" >
                                About
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/my-impressions.html" >
                                My Impressions
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/installation.html" >
                                Installation
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/building.html" >
                                Building
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/compile-time-stuff.html" >
                                Compile-time Stuff
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/package-system.html" >
                                Package System
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/lsp-ols-odin-language-server.html" >
                                LSP (OLS - Odin Language Server)
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/operations.html" >
                                Operations
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/control-flow-if-when-switch-for-defer.html" >
                                Control Flow (if, when, switch, for, defer)
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/procedures.html" >
                                Procedures
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/typing.html" >
                                Typing
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/any.html" >
                                any
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/primitive-types.html" >
                                Primitive Types
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/math-types.html" >
                                Math Types
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/strings.html" >
                                Strings
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/rune.html" >
                                Rune
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/maps-hash-maps.html" >
                                Maps (Hash Maps)
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/struct.html" >
                                Struct
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/union.html" >
                                Union
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/bit-sets.html" >
                                Bit Sets
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/arrays.html" >
                                Arrays
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/interfaces-methods-vtables.html" >
                                Interfaces / Methods / VTables
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/error-handling.html" >
                                Error Handling
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/context.html" >
                                Context
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/memory.html" >
                                Memory
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/memory-address.html" >
                                Memory: Address
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="active" 
								href="/studies/Low-Level Systems/Odin/memory-allocators.html" >
                                Memory: Allocators
							</a>
							<ul>
								<li>
									<a
										href="#implicit-allocator-usage" >
                                        Implicit Allocator Usage
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#default-allocators" >
                                        Default Allocators
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#nil-allocator" >
                                        Nil Allocator
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#panic-allocator" >
                                        Panic Allocator
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#arena-backed-directly-by-virtual-memory-codevmem-arena-code" >
                                        Arena: Backed directly by virtual memory (<code>vmem.Arena</code>)
									</a>
									<ul>
										<li>
											<a
												href="#rollback-the-offset-from-codevmem-arena-greater-static-code-with-codevmem-arena_static_reset_to-code" >
                                                Rollback the offset from <code>vmem.Arena -&gt; .Static</code> with <code>vmem.arena_static_reset_to</code>
											</a>
										</li>
										<li>
											<a
												href="#free-last-memory-block-from-codevmem-arena-greater-growing-code-with-codevmem-arena_temp-code" >
                                                Free last Memory Block from&nbsp;&nbsp;<code>vmem.Arena -&gt; .Growing</code> with <code>vmem.Arena_Temp</code>
											</a>
										</li>
									</ul>
								</li>
								<li>
									<a
										href="#arena-backed-buffer-as-an-arena-codemem-arena-code" >
                                        Arena: Backed buffer as an arena (<code>mem.Arena</code>)
									</a>
									<ul>
										<li>
											<a
												href="#rollback-the-offset-from-codemem-arena-code-with-codemem-arena_temp_memory-code" >
                                                Rollback the offset from <code>mem.Arena</code> with: <code>mem.Arena_Temp_Memory</code>
											</a>
										</li>
									</ul>
								</li>
								<li>
									<a
										href="#arena-growing-codemem-arena-code-codemem-dynamic_arena-code" >
                                        Arena: Growing <code>mem.Arena</code> (<code>mem.Dynamic_Arena</code>)
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#arena-codecontext-temp_allocator-code-coderuntime-default_temp_allocator-code" >
                                        Arena: <code>context.temp_allocator</code> (<code>runtime.Default_Temp_Allocator</code>)
									</a>
									<ul>
										<li>
											<a
												href="#free-last-memory-block-from-coderuntime-arena-code-codecontext-temp_allocator-code-with-coderuntime-arena_temp-code-quotetemp-allocator-tempquote-coderuntime-default_temp_allocator_temp_guard-code" >
                                                Free last Memory Block from <code>runtime.Arena</code> (<code>context.temp_allocator</code>) with <code>runtime.Arena_Temp</code> / &quot;Temp Allocator Temp&quot; / <code>runtime.DEFAULT_TEMP_ALLOCATOR_TEMP_GUARD</code>
											</a>
										</li>
									</ul>
								</li>
								<li>
									<a
										href="#scratch-allocator" >
                                        Scratch Allocator
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#stack-allocator-lifo" >
                                        Stack Allocator (LIFO)
									</a>
									<ul>
										<li>
											<a
												href="#small-stack-allocator" >
                                                Small Stack Allocator
											</a>
										</li>
									</ul>
								</li>
								<li>
									<a
										href="#buddy-memory-allocation" >
                                        Buddy Memory Allocation
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#pool-allocator" >
                                        Pool Allocator
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#general-purpose-free-list-based-allocator" >
                                        General Purpose: Free List Based Allocator
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#general-purpose-heap-allocator" >
                                        General Purpose: Heap Allocator
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#compact-allocator" >
                                        Compact Allocator
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#mutex-allocator" >
                                        Mutex Allocator
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#rollback-stack-allocator" >
                                        Rollback Stack Allocator
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#wasm-allocator" >
                                        WASM Allocator
									</a>
									<ul>
									</ul>
								</li>
								<li>
									<a
										href="#tracking-allocator" >
                                        Tracking Allocator
									</a>
									<ul>
									</ul>
								</li>
							</ul>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/memory-operations.html" >
                                Memory: Operations
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/entry-point.html" >
                                Entry Point
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/multi-threading.html" >
                                Multi-Threading
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/simd.html" >
                                SIMD
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/directives.html" >
                                Directives
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/ffi-foreign-function-interface-bindings.html" >
                                FFI (Foreign Function Interface) / Bindings
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/web-build.html" >
                                Web Build
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/file-system-process-cli-shell.html" >
                                File System / Process / CLI / Shell
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Odin/useful-packages.html" >
                                Useful Packages
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Memory
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/virtual-memory.html" >
                                Virtual Memory
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/os-memory-on-windows.html" >
                                OS: Memory on Windows
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/memory-alignment.html" >
                                Memory Alignment
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/address.html" >
                                Address
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/allocators.html" >
                                Allocators
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/tools-memory-analysis.html" >
                                Tools: Memory Analysis
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/handles-instead-of-pointers.html" >
                                Handles instead of Pointers
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/ownership-strategies-destruction-strategies.html" >
                                Ownership Strategies / Destruction Strategies
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/strategies-for-handling-short-lived-memory.html" >
                                Strategies for handling short lived memory
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/garbage-collection.html" >
                                Garbage Collection
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Memory/initialization.html" >
                                Initialization
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        CPU
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/CPU/concepts.html" >
                                Concepts
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/CPU/physical-structure.html" >
                                Physical Structure
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/CPU/cache.html" >
                                Cache
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/CPU/soa-struct-of-arrays-ecs-entity-component-system.html" >
                                SOA (Struct Of Arrays) / ECS (Entity Component System)
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/CPU/simd.html" >
                                SIMD
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Multithreading
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Multithreading/core-concepts.html" >
                                Core Concepts
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Multithreading/thread.html" >
                                Thread
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Multithreading/strategies.html" >
                                Strategies
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Multithreading/implementation-detail.html" >
                                Implementation Detail
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Multithreading/synchronization-primitives.html" >
                                Synchronization Primitives
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Multithreading/double-buffering.html" >
                                Double-Buffering
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Multithreading/networking-strategies.html" >
                                Networking Strategies
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Handmade Hero
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Handmade Hero/about.html" >
                                About
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Profilers
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Profilers/tracy.html" >
                                Tracy
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Profilers/spall.html" >
                                Spall
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Profilers/nvidia-nsight-graphics-gpu-trace.html" >
                                Nvidia Nsight Graphics - GPU Trace
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Profilers/amd-gpu-profiler-amd-rgp.html" >
                                AMD GPU Profiler (AMD RGP)
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Profilers/intel-gpa.html" >
                                Intel GPA
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Profilers/nsight-systems.html" >
                                <s>Nsight Systems</s>
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        C
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/about.html" >
                                About
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/critiques.html" >
                                Critiques
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/c-standard.html" >
                                C Standard
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/c-standard-library-libc.html" >
                                C Standard Library (libc)
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/building.html" >
                                Building
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/memory.html" >
                                Memory
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/loops.html" >
                                Loops
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/strings.html" >
                                Strings
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/structs.html" >
                                Structs
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/pointers.html" >
                                Pointers
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/arrays.html" >
                                Arrays
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/preprocessors.html" >
                                Preprocessors
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/undefined-behavior.html" >
                                Undefined Behavior
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/gamedev.html" >
                                GameDev
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/windows-c-api.html" >
                                WIndows C API
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Build Systems - Compilation - Linking
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Build Systems - Compilation - Linking/compilation-process.html" >
                                Compilation Process
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Build Systems - Compilation - Linking/compilers.html" >
                                Compilers
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Build Systems - Compilation - Linking/build-tools.html" >
                                Build Tools
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Build Systems - Compilation - Linking/meta-build-tools.html" >
                                Meta Build Tools
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Build Systems - Compilation - Linking/extra-annoying-things-on-windows.html" >
                                Extra: Annoying things on Windows
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Debuggers
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/file-types.html" >
                                File Types
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/rad-debbuger.html" >
                                RAD Debbuger
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/gdb-gnu-debugger.html" >
                                GDB (GNU Debugger)
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/lldb.html" >
                                LLDB
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/vscode.html" >
                                VSCode
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/visual-studio-debugger.html" >
                                Visual Studio Debugger
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/others.html" >
                                Others
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/web.html" >
                                Web
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Assembly - ASM
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Assembly/assembly.html" >
                                Assembly
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Assembly/notes.html" >
                                Notes
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Assembly/reverse-engineering.html" >
                                Reverse Engineering
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/Assembly/operations.html" >
                                Operations
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Parsing
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/parsing.html" >
                                Parsing
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/lexer.html" >
                                Lexer
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/tools.html" >
                                Tools
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        JAI
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/impressions.html" >
                                Impressions
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/build.html" >
                                Build
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/types.html" >
                                Types
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/meta-programming.html" >
                                Meta programming
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Low-Level Systems/control-flow.html" >
                                Control flow
							</a>
						</li>
					</ul>
				</details>
			</nav>
		</aside>
		<div
			id="central-wrapper" >
			<a
				href="/" 
				class="icon-home" >

                <svg version="1.1" id="Capa_1" fill="currentColor" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 299.021 299.021" xml:space="preserve" style="color: whitesmoke;">
                    <g>
                        <g>
                            <path d="M292.866,254.432c-2.288,0-4.443-1.285-5.5-3.399c-0.354-0.684-28.541-52.949-146.169-54.727v51.977
                                c0,2.342-1.333,4.48-3.432,5.513c-2.096,1.033-4.594,0.793-6.461-0.63L2.417,154.392C0.898,153.227,0,151.425,0,149.516
                                c0-1.919,0.898-3.72,2.417-4.888l128.893-98.77c1.87-1.426,4.365-1.667,6.461-0.639c2.099,1.026,3.432,3.173,3.432,5.509v54.776
                                c3.111-0.198,7.164-0.37,11.947-0.37c43.861,0,145.871,13.952,145.871,143.136c0,2.858-1.964,5.344-4.75,5.993
                                C293.802,254.384,293.34,254.432,292.866,254.432z"></path>
                        </g>
                    </g>
                </svg>
                    
			</a>
			<main>
				<article
					id="note-article" >
					<header>
						<h1>
                            Memory: Allocators
						</h1>
						<p>
							<time
								datetime="2025-03-28" >
                                ðŸ•’ Created: 2025-03-28
							</time>
							<time
								datetime="2026-01-20" >
                                | Updated: 2026-01-20
							</time>
						</p>
					</header>
					<div
						id="note-content" >
<pre><code class="language-odin" data-lang="odin">Allocator :: struct {
Â  Â  procedure: Allocator_Proc,
Â  Â  data: Â  Â  Â rawptr,
}
</code></pre>
<ul>
	<li>
		<p>
			<a
				href="https://www.youtube.com/watch?v=GZ6PuLikw84" 
				class="external-link" 
				target="_blank" >
                Allocators, Linear Allocators, Fragmentation, Stack Allocators - Nic Barker
			</a>
            .
		</p>
		<ul>
			<li>
				<p>
                    To improve the fragmentation from Linear Allocators, the memory region is divided by blocks.
				</p>
			</li>
			<li>
				<p>
                    Memory that is all together, with sequentially increasing addresses as 
					<strong>
                        Contiguous
					</strong>
                    .
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="why-use-allocators" >
    Why use allocators
</h5>
<ul>
	<li>
		<p>
            In C and C++ memory models, allocations of objects in memory are typically treated individually with a generic allocator (The 
            <code>malloc</code>
            &nbsp;procedure). Which in some scenarios can lead to poor cache utilization, slowdowns on individual objects' memory management and growing complexity of the code needing to keep track of the pointers and their lifetimes.
		</p>
	</li>
	<li>
		<p>
            Using different kinds of 
			<em>
                allocators
			</em>
            &nbsp;for different purposes can solve these problems. The allocators are typically optimized for specific use-cases and can potentially simplify the memory management code.
		</p>
	</li>
	<li>
		<p>
            For example, in the context of making a game, having an Arena allocator could simplify allocations of any temporary memory, because the programmer doesn't have to keep track of which objects need to be freed every time they are allocated, because at the end of every frame the whole allocator is reset to its initial state and all objects are freed at once.
		</p>
	</li>
	<li>
		<p>
            The allocators have different kinds of restrictions on object lifetimes, sizes, alignment and can be a significant gain, if used properly. Odin supports allocators on a language level.
		</p>
	</li>
	<li>
		<p>
            Operations such as 
            <code>new</code>
            , 
            <code>free</code>
            &nbsp;and 
            <code>delete</code>
            &nbsp;by default will use 
            <code>context.allocator</code>
            , which can be overridden by the user. When an override happens all called procedures will inherit the new context and use the same allocator.
		</p>
	</li>
	<li>
		<p>
            We will define one concept to simplify the description of some allocator-related procedures, which is ownership. If the memory was allocated via a specific allocator, that allocator is said to be the 
			<em>
                owner
			</em>
            &nbsp;of that memory region. To note, unlike Rust, in Odin the memory ownership model is not strict.
		</p>
	</li>
</ul>
<h5
	id="notes" >
    Notes
</h5>
<ul>
	<li>
		<p>
            There are some allocator requirements for 
            <code>map</code>
            s; see the&nbsp;&nbsp;
            <a href="#maps-hash-maps">
            Maps (Hash Maps)
            </a>
            &nbsp;section.
		</p>
	</li>
	<li>
		<p>
            &quot;Arenas and Dynamic Allocators together can sometimes be inefficient&quot;.
		</p>
		<ul>
			<li>
				<p>
					<a
						href="https://www.youtube.com/watch?v=1WnqZPD-qVc" 
						class="external-link" 
						target="_blank" >
                        Arenas + Dynamic Allocators
					</a>
                    .
				</p>
			</li>
			<li>
				<p>
                    I didn't fully understand the concept.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h3
	id="implicit-allocator-usage" >
    Implicit Allocator Usage
</h3>
<h5
	id="for-codecontext-allocator-code" >
    For 
    <code>context.allocator</code>
</h5>
<ul>
	<li>
		<p>
			<input
				type="checkbox" 
				disabled=""
				checked="">
            
            <code>runtime.default_allocator()</code>
		</p>
		<ul>
			<li>
				<p>
                    Only used if the 
                    <code>context.temp_allocator</code>
                    &nbsp;is not manually initialized.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<input
				type="checkbox" 
				disabled=""
>
            
            <code>runtime.heap_allocator()</code>
            .
		</p>
		<ul>
			<li>
				<p>
                    Used a lot around 
                    <code>os2</code>
                    &nbsp;and 
                    <code>os</code>
                    .
				</p>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
						checked="">
                    
                    <code>TEMP_ALLOCATOR_GUARD</code>
				</p>
				<ul>
					<li>
						<p>
                            if the 
                            <code>context.temp_allocator</code>
                            &nbsp;is not manually initialized.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>os2._env: [dynamic]string</code>
                    &nbsp;in the 
                    <code>os2/env_linux.odin</code>
                    .
				</p>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>os2.get_args()</code>
                    &nbsp;/ 
                    <code>os2.delete_args()</code>
				</p>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>os2.file_allocator()</code>
				</p>
				<ul>
					<li>
						<p>
							<input
								type="checkbox" 
								disabled=""
>
                            
                            <code>os2.walkers</code>
						</p>
					</li>
					<li>
						<p>
							<input
								type="checkbox" 
								disabled=""
>
                            etc, a LOT of places inside the 
                            <code>os2</code>
                            &nbsp;lib.
						</p>
					</li>
				</ul>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<input
				type="checkbox" 
				disabled=""
				checked="">
            
            <code>os.args</code>
		</p>
		<ul>
			<li>
				<p>
                    Uses it implicitly.
				</p>
			</li>
			<li>
				<p>
                    This is fixed by using 
                    <code>os2</code>
                    , which still uses a heap allocator implicitly, but at least is not the 
                    <code>context.allocator</code>
                    , but the 
                    <code>os2.heap_allocator</code>
                    .
				</p>
				<ul>
					<li>
						<p>
                            It's technically the same thing, but at least this doesn't break 
                            <code>-default-to-panic-allocator</code>
                            .
						</p>
					</li>
				</ul>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="for-codecontext-temp_allocator-code" >
    For 
    <code>context.temp_allocator</code>
</h5>
<ul>
	<li>
		<p>
			<em>
                Conclusion
			</em>
            :
		</p>
		<ul>
			<li>
				<p>
                    <code>context.temp_allocator</code>
                    &nbsp;/ 
                    <code>runtime.DEFAULT_TEMP_ALLOCATOR_TEMP_GUARD</code>
                    &nbsp;is used implicitly A LOT inside the 
                    <code>core</code>
                    &nbsp;libraries.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            <code>base</code>
            :
		</p>
		<ul>
			<li>
				<p>
                    Nothing uses it. Just definition.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            <code>core</code>
            :
		</p>
		<ul>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>compress/common</code>
				</p>
				<ul>
					<li>
						<p>
                            Has 
							<em>
                                todo
							</em>
                            s to remove it.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>encoding/json</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>encoding/xml</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>flags</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>fmt</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>image/jpeg</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>image/netbpm</code>
                    .
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly with guard.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>image/png</code>
                    .
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly with guard.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>net</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>odin/parser</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>os</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly with guard.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>os/os2</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly with guard.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>path/filepath</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly with guard.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>path/slashpath</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly with guard.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>sys/windows</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>sys/darwin</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>sys/info</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>sys/orca</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    
                    <code>testing</code>
				</p>
				<ul>
					<li>
						<p>
                            Uses implicitly.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
						checked="">
                    
                    <code>encoding/cbor</code>
				</p>
				<ul>
					<li>
						<p>
                            It's overridable in the parameters.
						</p>
					</li>
					<li>
						<p>
							<input
								type="checkbox" 
								disabled=""
>
                            
                            <code>cbor/tags.odin</code>
                            , wtf?
						</p>
						<ul>
							<li>
								<p>
                                    I'm seeing 
                                    <code>delete</code>
                                    &nbsp;with 
                                    <code>context.temp_allocator</code>
                                    ...
								</p>
							</li>
						</ul>
					</li>
					<li>
						<p>
                            The library is really messy.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
						checked="">
                    
                    <code>container</code>
                    .
				</p>
				<ul>
					<li>
						<p>
                            It's overridable in the parameters.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
						checked="">
                    
                    <code>container/kmac</code>
				</p>
				<ul>
					<li>
						<p>
                            It's overridable in the parameters.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
						checked="">
                    
                    <code>dynlib</code>
				</p>
				<ul>
					<li>
						<p>
                            It's overridable in the parameters.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
						checked="">
                    
                    <code>thread</code>
				</p>
				<ul>
					<li>
						<p>
                            Deletes the 
                            <code>context.temp_allocator</code>
                            &nbsp;if set.
						</p>
					</li>
				</ul>
			</li>
		</ul>
	</li>
</ul>
<h3
	id="default-allocators" >
    Default Allocators
</h3>
<ul>
	<li>
		<p>
            For 
            <code>context.allocator</code>
            :
		</p>
<pre><code class="language-odin" data-lang="odin">when ODIN_DEFAULT_TO_NIL_ALLOCATOR {
Â  Â  default_allocator_proc :: nil_allocator_proc
Â  Â  default_allocator&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:: nil_allocator
} else when ODIN_DEFAULT_TO_PANIC_ALLOCATOR {
Â  Â  default_allocator_proc :: panic_allocator_proc
Â  Â  default_allocator&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:: panic_allocator
} else when ODIN_OS != .Orca && (ODIN_ARCH == .wasm32 || ODIN_ARCH == .wasm64p32) {
Â  Â  default_allocator&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:: default_wasm_allocator
Â  Â  default_allocator_proc :: wasm_allocator_proc
} else {
Â  Â  default_allocator&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:: heap_allocator
Â  Â  default_allocator_proc :: heap_allocator_proc
}
</code></pre>
	</li>
	<li>
		<p>
            For 
            <code>context.temp_allocator</code>
            :
		</p>
<pre><code class="language-odin" data-lang="odin">when NO_DEFAULT_TEMP_ALLOCATOR {
Â  Â  default_temp_allocator_proc :: nil_allocator_proc
} else {
&nbsp;&nbsp;&nbsp;&nbsp;default_temp_allocator_proc :: proc(allocator_data: rawptr, mode: Allocator_Mode,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;size, alignment: int,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;old_memory: rawptr, old_size: int, loc := #caller_location) -&gt; (data: []byte, err: Allocator_Error) {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s := (^Default_Temp_Allocator)(allocator_data)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return arena_allocator_proc(&s.arena, mode, size, alignment, old_memory, old_size, loc)
&nbsp;&nbsp;&nbsp;&nbsp;}
}
</code></pre>
	</li>
	<li>
		<p>
            Both are used here:
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">__init_context :: proc "contextless" (c: ^Context) {
&nbsp;&nbsp;&nbsp;&nbsp;// etc
&nbsp;&nbsp;&nbsp;&nbsp;c.allocator.procedure = default_allocator_proc
&nbsp;&nbsp;&nbsp;&nbsp;c.allocator.data = nil
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;c.temp_allocator.procedure = default_temp_allocator_proc
&nbsp;&nbsp;&nbsp;&nbsp;when !NO_DEFAULT_TEMP_ALLOCATOR {
Â  Â  Â  Â  c.temp_allocator.data = &global_default_temp_allocator_data
Â  Â  }
&nbsp;&nbsp;&nbsp;&nbsp;// etcÂ  Â 
}
</code></pre>
<h3
	id="nil-allocator" >
    Nil Allocator
</h3>
<ul>
	<li>
		<p>
            The 
            <code>nil</code>
            &nbsp;allocator returns 
            <code>nil</code>
            &nbsp;on every allocation attempt. This type of allocator can be used in scenarios where memory doesn't need to be allocated, but an attempt to allocate memory is not an error.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">@(require_results)
nil_allocator :: proc() -&gt; Allocator {
Â  Â  return Allocator{
Â  Â  Â  Â  procedure = nil_allocator_proc,
Â  Â  Â  Â  data Â  Â  Â = nil,
Â  Â  }
}

nil_allocator_proc :: proc(
Â  Â  allocator_data: Â rawptr,
Â  Â  mode: Â  Â  Â  Â  Â  Â Allocator_Mode,
Â  Â  size, alignment: int,
Â  Â  old_memory: Â  Â  Â rawptr,
Â  Â  old_size: Â  Â  Â  Â int,
Â  Â  loc := #caller_location,
) -&gt; ([]byte, Allocator_Error) {
Â  Â  return nil, nil
}
</code></pre>
<h5
	id="default-to-nil" >
    Default to Nil
</h5>
<ul>
	<li>
		<p>
            Use 
            <code>-default-to-nil-allocator</code>
            &nbsp;as a compilation flag.
		</p>
	</li>
	<li>
		<p>
            Keep in mind: 
            <code>-default-to-panic-allocator</code>
            &nbsp;cannot be used with 
            <code>-default-to-nil-allocator</code>
            .
		</p>
	</li>
</ul>
<h3
	id="panic-allocator" >
    Panic Allocator
</h3>
<ul>
	<li>
		<p>
            The panic allocator is a type of allocator that panics on any allocation attempt. This type of allocator can be used in scenarios where memory should not be allocated, and an attempt to allocate memory is an error.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">// basically the same as the Nil Allocator, but panics.
</code></pre>
<h5
	id="uses" >
    Uses
</h5>
<ul>
	<li>
		<p>
			<strong>
                To ensure explicit allocators, different from 
                <code>context.allocator</code>
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    You could set 
                    <code>context.allocator</code>
                    &nbsp;to a 
                    <code>runtime.panic_allocator()</code>
                    &nbsp;so that if anything uses it by accident it'll panic, then pass your allocator around explicitly.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="default-to-panic" >
    Default to Panic
</h5>
<ul>
	<li>
		<p>
            Use 
            <code>-default-to-panic-allocator</code>
            &nbsp;as a compilation flag.
		</p>
	</li>
	<li>
		<p>
            Keep in mind: 
            <code>-default-to-panic-allocator</code>
            &nbsp;cannot be used with 
            <code>-default-to-nil-allocator</code>
            .
		</p>
	</li>
</ul>
<h3
	id="arena-backed-directly-by-virtual-memory-codevmem-arena-code" >
    Arena: Backed directly by virtual memory (
    <code>vmem.Arena</code>
    )
</h3>
<ul>
	<li>
		<p>
            Reserving virtual memory does not increase memory usage. It goes up when the dynamic array actually grows into that reserved space.
		</p>
	</li>
	<li>
		<p>
            Uses virtual memory 
			<em>
                directly
			</em>
            , whereas the arenas in mem use a 
            <code>[]byte</code>
            &nbsp;or 
            <code>[dynamic]byte</code>
            &nbsp;for their memory, so they basically still exist inside the heap allocator.
		</p>
	</li>
	<li>
		<p>
			<a
				href="https://github.com/karl-zylinski/odin-handle-map?tab=readme-ov-file#which-variant-should-i-use" 
				class="external-link" 
				target="_blank" >
                How virtual arenas are used in odin-handle-map
			</a>
            .
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">// Create an `Allocator` from the provided `Arena`
@(require_results, no_sanitize_address)
arena_allocator :: proc(arena: ^Arena) -&gt; mem.Allocator {
Â  Â  return mem.Allocator{arena_allocator_proc, arena}
}
</code></pre>
<h5
	id="kind-code-static-code" >
    kind 
    <code>.Static</code>
</h5>
<ul>
	<li>
		<p>
            Contains a single 
            <code>Memory_Block</code>
            &nbsp;allocated with virtual memory.
		</p>
	</li>
</ul>
<h5
	id="kind-code-growing-code" >
    kind 
    <code>.Growing</code>
</h5>
<ul>
	<li>
		<p>
            Is a linked list of 
            <code>Memory_Block</code>
            s allocated with virtual memory.
		</p>
	</li>
	<li>
		<p>
            Allows for 
            <code>vmem.Arena_Temp</code>
            &nbsp;which can call 
            <code>vmem.arena_growing_free_last_memory_block</code>
            , shrinking itself, from my understanding.
		</p>
	</li>
</ul>
<h5
	id="kind-code-buffer-code" >
    <s>kind 
    <code>.Buffer</code>
    </s>
</h5>
<ul>
	<li>
		<p>
            I'm not using this one, seems redundant. Just use 
            <code>mem.Arena</code>
            .
		</p>
	</li>
	<li>
		<p>
			<em>
                Demo
			</em>
            :
		</p>
		<ul>
			<li>
				<p>
                    <img src="assets/image_20250402091802.png" width="525" >
                    .
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<em>
                Discussion
			</em>
            :
		</p>
		<ul>
			<li>
				<p>
                    Caio:
				</p>
				<ul>
					<li>
						<p>
                            Is the arena buffer from 
                            <code>mem/virtual</code>
                            &nbsp;actually virtual? I'm confused as the buffer is externally passed to 
                            <code>arena_init_buffer</code>
                            , and for what I was able to understand, the memory is never committed.
						</p>
					</li>
					<li>
						<p>
                            I mean, isn't a 
                            <code>mem.Arena</code>
                            &nbsp;more efficient, as it avoids unnecessary checks for something that will never be committed? They both seem to do the same thing, while 
                            <code>mem/virtual</code>
                            &nbsp;buffer uses the concept of 
                            <code>Memory_Blocks</code>
                            &nbsp;as an abstraction, but it doesn't seem to matter in this case
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
                    Barinzaya:
				</p>
				<ul>
					<li>
						<p>
                            <code>buffer</code>
                            &nbsp;is one mode, but in that one 
							<em>
                                you
							</em>
                            &nbsp;provide the memory. The other modes (the default 
                            <code>growing</code>
                            &nbsp;as well as 
                            <code>static</code>
                            ) do their own allocation, indeed using virtual memory.
						</p>
					</li>
					<li>
						<p>
                            I guess it's just a matter of flexibility. It already has a mode to check anyway, and a lot of the logic is the same, so I guess it's a &quot;might as well&quot;--though I do find 
                            <code>virtual.Arena</code>
                            &nbsp;to be trying to do a bit too much myself
						</p>
					</li>
					<li>
						<p>
                            In the bigger picture, using the same code for both 
							<em>
                                could
							</em>
                            &nbsp;prove beneficial in terms of instruction cache, even if the code is less specialized
						</p>
					</li>
					<li>
						<p>
                            If you're actually 
							<em>
                                using
							</em>
                            &nbsp;it in both modes, that is.
						</p>
					</li>
				</ul>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="bootstrapping" >
    Bootstrapping
</h5>
<pre><code class="language-odin" data-lang="odin">// Ability to bootstrap allocate a struct with an arena within the struct itself using the growing variant strategy.
arena_growing_bootstrap_new :: proc{
Â  Â  arena_growing_bootstrap_new_by_offset,
Â  Â  arena_growing_bootstrap_new_by_name,
}

// Ability to bootstrap allocate a struct with an arena within the struct itself using the static variant strategy.
arena_static_bootstrap_new :: proc{
Â  Â  arena_static_bootstrap_new_by_offset,
Â  Â  arena_static_bootstrap_new_by_name,
}
</code></pre>
<h5
	id="alloc-from-memory-block" >
    Alloc from Memory Block
</h5>
<ul>
	<li>
		<p>
            Allocates memory from the provided arena.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">@(require_results, no_sanitize_address, private)
arena_alloc_unguarded :: proc(arena: ^Arena, size: uint, alignment: uint, loc := #caller_location) -&gt; (data: []byte, err: Allocator_Error) {
Â  Â  size := size
Â  Â  if size == 0 {
Â  Â  Â  Â  return nil, nil
Â  Â  }
Â  Â  switch arena.kind {
Â  Â  case .Growing:
Â  Â  Â  Â  prev_used := 0 if arena.curr_block == nil else arena.curr_block.used
Â  Â  Â  Â  data, err = alloc_from_memory_block(arena.curr_block, size, alignment, default_commit_size=arena.default_commit_size)
Â  Â  Â  Â  if err == .Out_Of_Memory {
Â  Â  Â  Â  Â  Â  if arena.minimum_block_size == 0 {
Â  Â  Â  Â  Â  Â  Â  Â  arena.minimum_block_size = DEFAULT_ARENA_GROWING_MINIMUM_BLOCK_SIZE
Â  Â  Â  Â  Â  Â  Â  Â  arena.minimum_block_size = mem.align_forward_uint(arena.minimum_block_size, DEFAULT_PAGE_SIZE)
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  if arena.default_commit_size == 0 {
Â  Â  Â  Â  Â  Â  Â  Â  arena.default_commit_size = min(DEFAULT_ARENA_GROWING_COMMIT_SIZE, arena.minimum_block_size)
Â  Â  Â  Â  Â  Â  Â  Â  arena.default_commit_size = mem.align_forward_uint(arena.default_commit_size, DEFAULT_PAGE_SIZE)
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  if arena.default_commit_size != 0 {
Â  Â  Â  Â  Â  Â  Â  Â  arena.default_commit_size, arena.minimum_block_size =
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  min(arena.default_commit_size, arena.minimum_block_size),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  max(arena.default_commit_size, arena.minimum_block_size)
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  needed := mem.align_forward_uint(size, alignment)
Â  Â  Â  Â  Â  Â  needed = max(needed, arena.default_commit_size)
Â  Â  Â  Â  Â  Â  block_size := max(needed, arena.minimum_block_size)
Â  Â  Â  Â  Â  Â  new_block := memory_block_alloc(needed, block_size, alignment, {}) or_return
Â  Â  Â  Â  Â  Â  new_block.prev = arena.curr_block
Â  Â  Â  Â  Â  Â  arena.curr_block = new_block
Â  Â  Â  Â  Â  Â  arena.total_reserved += new_block.reserved
Â  Â  Â  Â  Â  Â  prev_used = 0
Â  Â  Â  Â  Â  Â  data, err = alloc_from_memory_block(arena.curr_block, size, alignment, default_commit_size=arena.default_commit_size)
Â  Â  Â  Â  }
Â  Â  Â  Â  arena.total_used += arena.curr_block.used - prev_used
Â  Â  case .Static:
Â  Â  Â  Â  if arena.curr_block == nil {
Â  Â  Â  Â  Â  Â  if arena.minimum_block_size == 0 {
Â  Â  Â  Â  Â  Â  Â  Â  arena.minimum_block_size = DEFAULT_ARENA_STATIC_RESERVE_SIZE
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  arena_init_static(arena, reserved=arena.minimum_block_size, commit_size=DEFAULT_ARENA_STATIC_COMMIT_SIZE) or_return
Â  Â  Â  Â  }
Â  Â  Â  Â  if arena.curr_block == nil {
Â  Â  Â  Â  Â  Â  return nil, .Out_Of_Memory
Â  Â  Â  Â  }
Â  Â  Â  Â  data, err = alloc_from_memory_block(arena.curr_block, size, alignment, default_commit_size=arena.default_commit_size)
Â  Â  Â  Â  arena.total_used = arena.curr_block.used
Â  Â  case .Buffer:
Â  Â  Â  Â  if arena.curr_block == nil {
Â  Â  Â  Â  Â  Â  return nil, .Out_Of_Memory
Â  Â  Â  Â  }
Â  Â  Â  Â  data, err = alloc_from_memory_block(arena.curr_block, size, alignment, default_commit_size=0)
Â  Â  Â  Â  arena.total_used = arena.curr_block.used
Â  Â  }
Â  Â  // sanitizer.address_unpoison(data)
Â  Â  return
}

@(require_results, no_sanitize_address)
alloc_from_memory_block :: proc(block: ^Memory_Block, min_size, alignment: uint, default_commit_size: uint = 0) -&gt; (data: []byte, err: Allocator_Error) {
Â  Â  @(no_sanitize_address)
Â  Â  calc_alignment_offset :: proc "contextless" (block: ^Memory_Block, alignment: uintptr) -&gt; uint {
Â  Â  Â  Â  alignment_offset := uint(0)
Â  Â  Â  Â  ptr := uintptr(block.base[block.used:])
Â  Â  Â  Â  mask := alignment-1
Â  Â  Â  Â  if ptr & mask != 0 {
Â  Â  Â  Â  Â  Â  alignment_offset = uint(alignment - (ptr & mask))
Â  Â  Â  Â  }
Â  Â  Â  Â  return alignment_offset
Â  Â  }
Â  Â  @(no_sanitize_address)
Â  Â  do_commit_if_necessary :: proc(block: ^Memory_Block, size: uint, default_commit_size: uint) -&gt; (err: Allocator_Error) {
Â  Â  Â  Â  if block.committed - block.used &lt; size {
Â  Â  Â  Â  Â  Â  pmblock := (^Platform_Memory_Block)(block)
Â  Â  Â  Â  Â  Â  base_offset := uint(uintptr(pmblock.block.base) - uintptr(pmblock))
Â  Â  Â  Â  Â  Â  // NOTE(bill): [Heuristic] grow the commit size larger than needed
Â  Â  Â  Â  Â  Â  // TODO(bill): determine a better heuristic for this behaviour
Â  Â  Â  Â  Â  Â  extra_size := max(size, block.committed&gt;&gt;1)
Â  Â  Â  Â  Â  Â  platform_total_commit := base_offset + block.used + extra_size
Â  Â  Â  Â  Â  Â  platform_total_commit = align_formula(platform_total_commit, DEFAULT_PAGE_SIZE)
Â  Â  Â  Â  Â  Â  platform_total_commit = min(max(platform_total_commit, default_commit_size), pmblock.reserved)
Â  Â  Â  Â  Â  Â  assert(pmblock.committed &lt;= pmblock.reserved)
Â  Â  Â  Â  Â  Â  assert(pmblock.committed &lt; platform_total_commit)
Â  Â  Â  Â  Â  Â  platform_memory_commit(pmblock, platform_total_commit) or_return
Â  Â  Â  Â  Â  Â  pmblock.committed = platform_total_commit
Â  Â  Â  Â  Â  Â  block.committed = pmblock.committed - base_offset
Â  Â  Â  Â  }
Â  Â  Â  Â  return
Â  Â  }
Â  Â  if block == nil {
Â  Â  Â  Â  return nil, .Out_Of_Memory
Â  Â  }
Â  Â  alignment_offset := calc_alignment_offset(block, uintptr(alignment))
Â  Â  size, size_ok := safe_add(min_size, alignment_offset)
Â  Â  if !size_ok {
Â  Â  Â  Â  err = .Out_Of_Memory
Â  Â  Â  Â  return
Â  Â  }
Â  Â  if to_be_used, ok := safe_add(block.used, size); !ok || to_be_used &gt; block.reserved {
Â  Â  Â  Â  err = .Out_Of_Memory
Â  Â  Â  Â  return
Â  Â  }
Â  Â  assert(block.committed &lt;= block.reserved)
Â  Â  do_commit_if_necessary(block, size, default_commit_size) or_return
Â  Â  data = block.base[block.used+alignment_offset:][:min_size]
Â  Â  block.used += size
Â  Â  // sanitizer.address_unpoison(data)
Â  Â  return
}

@(require_results, no_sanitize_address)
arena_alloc :: proc(arena: ^Arena, size: uint, alignment: uint, loc := #caller_location) -&gt; (data: []byte, err: Allocator_Error) {
Â  Â  assert(alignment & (alignment-1) == 0, "non-power of two alignment", loc)
Â  Â  size := size
Â  Â  if size == 0 {
Â  Â  Â  Â  return nil, nil
Â  Â  }
Â  Â  sync.mutex_guard(&arena.mutex)
Â  Â  return arena_alloc_unguarded(arena, size, alignment, loc)
}

@(no_sanitize_address)
arena_allocator_proc :: proc(allocator_data: rawptr, mode: mem.Allocator_Mode,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â size, alignment: int,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â old_memory: rawptr, old_size: int,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â location := #caller_location) -&gt; (data: []byte, err: Allocator_Error) {
Â  Â  switch mode {
Â  Â  case .Resize, .Resize_Non_Zeroed:
Â  Â  Â  Â  // etc
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_ = alloc_from_memory_block(block, new_end - old_end, 1, default_commit_size=arena.default_commit_size) or_return
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// etc
Â  Â  Â  Â  new_memory := arena_alloc_unguarded(arena, size, alignment, location) or_return
Â  Â  }
Â  Â  return
}
</code></pre>
<h5
	id="memory-block-alloc" >
    Memory Block Alloc
</h5>
<pre><code class="language-odin" data-lang="odin">// Linux
_commit :: proc "contextless" (data: rawptr, size: uint) -&gt; Allocator_Error {
Â  Â  errno := linux.mprotect(data, size, {.READ, .WRITE})
Â  Â  if errno == .EINVAL {
Â  Â  Â  Â  return .Invalid_Pointer
Â  Â  } else if errno == .ENOMEM {
Â  Â  Â  Â  return .Out_Of_Memory
Â  Â  }
Â  Â  return nil
}

// Windows
@(no_sanitize_address)
_commit :: proc "contextless" (data: rawptr, size: uint) -&gt; Allocator_Error {
Â  Â  result := VirtualAlloc(data, size, MEM_COMMIT, PAGE_READWRITE)
Â  Â  if result == nil {
Â  Â  Â  Â  switch err := GetLastError(); err {
Â  Â  Â  Â  case 0:
Â  Â  Â  Â  Â  Â  return .Invalid_Argument
Â  Â  Â  Â  case ERROR_INVALID_ADDRESS, ERROR_COMMITMENT_LIMIT:
Â  Â  Â  Â  Â  Â  return .Out_Of_Memory
Â  Â  Â  Â  }
Â  Â  Â  Â  return .Out_Of_Memory
Â  Â  }
Â  Â  return nil
}

@(no_sanitize_address)
commit :: proc "contextless" (data: rawptr, size: uint) -&gt; Allocator_Error {
Â  Â  // sanitizer.address_unpoison(data, size)
Â  Â  return _commit(data, size)
}

// Linux
_reserve :: proc "contextless" (size: uint) -&gt; (data: []byte, err: Allocator_Error) {
Â  Â  addr, errno := linux.mmap(0, size, {}, {.PRIVATE, .ANONYMOUS})
Â  Â  if errno == .ENOMEM {
Â  Â  Â  Â  return nil, .Out_Of_Memory
Â  Â  } else if errno == .EINVAL {
Â  Â  Â  Â  return nil, .Invalid_Argument
Â  Â  }
Â  Â  return (cast([^]byte)addr)[:size], nil
}

// Windows
@(no_sanitize_address)
_reserve :: proc "contextless" (size: uint) -&gt; (data: []byte, err: Allocator_Error) {
Â  Â  result := VirtualAlloc(nil, size, MEM_RESERVE, PAGE_READWRITE)
Â  Â  if result == nil {
Â  Â  Â  Â  err = .Out_Of_Memory
Â  Â  Â  Â  return
Â  Â  }
Â  Â  data = ([^]byte)(result)[:size]
Â  Â  return
}

@(require_results, no_sanitize_address)
reserve :: proc "contextless" (size: uint) -&gt; (data: []byte, err: Allocator_Error) {
Â  Â  return _reserve(size)
}

@(no_sanitize_address)
platform_memory_alloc :: proc "contextless" (to_commit, to_reserve: uint) -&gt; (block: ^Platform_Memory_Block, err: Allocator_Error) {
Â  Â  to_commit, to_reserve := to_commit, to_reserve
Â  Â  to_reserve = max(to_commit, to_reserve)
Â  Â  
Â  Â  total_to_reserved := max(to_reserve, size_of(Platform_Memory_Block))
Â  Â  to_commit = clamp(to_commit, size_of(Platform_Memory_Block), total_to_reserved)
Â  Â  
Â  Â  data := reserve(total_to_reserved) or_return
Â  Â  
Â  Â  commit_err := commit(raw_data(data), to_commit)
Â  Â  assert_contextless(commit_err == nil)
Â  Â  
Â  Â  block = (^Platform_Memory_Block)(raw_data(data))
Â  Â  block.committed = to_commit
Â  Â  block.reserved Â = to_reserve
Â  Â  return
}

@(require_results, no_sanitize_address)
memory_block_alloc :: proc(committed, reserved: uint, alignment: uint = 0, flags: Memory_Block_Flags = {}) -&gt; (block: ^Memory_Block, err: Allocator_Error) {
Â  Â  page_size := DEFAULT_PAGE_SIZE
Â  Â  assert(mem.is_power_of_two(uintptr(page_size)))
Â  Â  
Â  Â  committed := committed
Â  Â  reserved Â := reserved
Â  Â  
Â  Â  committed = align_formula(committed, page_size)
Â  Â  reserved Â = align_formula(reserved, page_size)
Â  Â  committed = clamp(committed, 0, reserved)
Â  Â  
Â  Â  total_size Â  Â  := reserved + alignment + size_of(Platform_Memory_Block)
Â  Â  base_offset Â  Â := mem.align_forward_uintptr(size_of(Platform_Memory_Block), max(uintptr(alignment), align_of(Platform_Memory_Block)))
Â  Â  protect_offset := uintptr(0)
Â  Â  
Â  Â  do_protection := false
Â  Â  if .Overflow_Protection in flags { // overflow protection
Â  Â  Â  Â  rounded_size Â  := reserved
Â  Â  Â  Â  total_size Â  Â  = uint(rounded_size + 2*page_size)
Â  Â  Â  Â  base_offset Â  Â = uintptr(page_size + rounded_size - uint(reserved))
Â  Â  Â  Â  protect_offset = uintptr(page_size + rounded_size)
Â  Â  Â  Â  do_protection Â = true
Â  Â  }
Â  Â  
Â  Â  pmblock := platform_memory_alloc(0, total_size) or_return
Â  Â  
Â  Â  pmblock.block.base = ([^]byte)(pmblock)[base_offset:]
Â  Â  platform_memory_commit(pmblock, uint(base_offset) + committed) or_return
Â  Â  
Â  Â  // Should be zeroed
Â  Â  assert(pmblock.block.used == 0)
Â  Â  assert(pmblock.block.prev == nil) Â 
Â  Â  if do_protection {
Â  Â  Â  Â  protect(([^]byte)(pmblock)[protect_offset:], page_size, Protect_No_Access)
Â  Â  }
Â  Â  pmblock.block.committed = committed
Â  Â  pmblock.block.reserved Â = reserved
Â  Â  
Â  Â  return &pmblock.block, nil
}

@(require_results, no_sanitize_address)
arena_init_growing :: proc(arena: ^Arena, reserved: uint = DEFAULT_ARENA_GROWING_MINIMUM_BLOCK_SIZE) -&gt; (err: Allocator_Error) {
Â  Â  arena.kind Â  Â  Â  Â  Â  = .Growing
Â  Â  arena.curr_block Â  Â  = memory_block_alloc(0, reserved, {}) or_return
Â  Â  arena.total_used Â  Â  = 0
Â  Â  arena.total_reserved = arena.curr_block.reserved
Â  Â  if arena.minimum_block_size == 0 {
Â  Â  Â  Â  arena.minimum_block_size = reserved
Â  Â  }
Â  Â  // sanitizer.address_poison(arena.curr_block.base[:arena.curr_block.committed])
Â  Â  return
}

@(require_results, no_sanitize_address)
arena_init_static :: proc(arena: ^Arena, reserved: uint = DEFAULT_ARENA_STATIC_RESERVE_SIZE, commit_size: uint = DEFAULT_ARENA_STATIC_COMMIT_SIZE) -&gt; (err: Allocator_Error) {
Â  Â  arena.kind Â  Â  Â  Â  Â  = .Static
Â  Â  arena.curr_block Â  Â  = memory_block_alloc(commit_size, reserved, {}) or_return
Â  Â  arena.total_used Â  Â  = 0
Â  Â  arena.total_reserved = arena.curr_block.reserved
Â  Â  // sanitizer.address_poison(arena.curr_block.base[:arena.curr_block.committed])
Â  Â  return
}
</code></pre>
<h5
	id="memory-block-dealloc" >
    Memory Block Dealloc
</h5>
<pre><code class="language-odin" data-lang="odin">// Windows (this one seems odd)
@(no_sanitize_address)
_release :: proc "contextless" (data: rawptr, size: uint) {
&nbsp;&nbsp;&nbsp;&nbsp;VirtualFree(data, 0, MEM_RELEASE)
}

// Linux
_release :: proc "contextless" (data: rawptr, size: uint) {
&nbsp;&nbsp;&nbsp;&nbsp;_ = linux.munmap(data, size)
}

@(no_sanitize_address)
release :: proc "contextless" (data: rawptr, size: uint) {
&nbsp;&nbsp;&nbsp;&nbsp;// sanitizer.address_unpoison(data, size)
&nbsp;&nbsp;&nbsp;&nbsp;_release(data, size)
}

@(no_sanitize_address)
platform_memory_free :: proc "contextless" (block: ^Platform_Memory_Block) {
&nbsp;&nbsp;&nbsp;&nbsp;if block != nil {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;release(block, block.reserved)
&nbsp;&nbsp;&nbsp;&nbsp;}
}

@(no_sanitize_address)
memory_block_dealloc :: proc(block_to_free: ^Memory_Block) {
&nbsp;&nbsp;&nbsp;&nbsp;if block := (^Platform_Memory_Block)(block_to_free); block != nil {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;platform_memory_free(block)
&nbsp;&nbsp;&nbsp;&nbsp;}
}
</code></pre>
<ul>
	<li>
		<p>
			<strong>
                For Growing arenas
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    <code>vmem.arena_free_all()</code>
				</p>
				<ul>
					<li>
						<p>
                            Will shrink the arena to the size of the first Memory Block.
						</p>
					</li>
					<li>
						<p>
							<strong>
                                Confirmed
							</strong>
                            : This is also shown in the Task Manager, as having much less memory when freeing all.
						</p>
					</li>
					<li>
						<p>
                            Deallocates all but the first memory block of the arena and resets the allocator's usage to 0.
						</p>
					</li>
				</ul>
<pre><code class="language-Odin" data-lang="Odin">@(no_sanitize_address)
arena_free_all :: proc(arena: ^Arena, loc := #caller_location) {
Â  Â  switch arena.kind {
Â  Â  case .Growing:
Â  Â  Â  Â  sync.mutex_guard(&arena.mutex)
Â  Â  Â  Â  // NOTE(bill): Free all but the first memory block (if it exists)
Â  Â  Â  Â  for arena.curr_block != nil && arena.curr_block.prev != nil {
Â  Â  Â  Â  Â  Â  arena_growing_free_last_memory_block(arena, loc)
Â  Â  Â  Â  }
Â  Â  Â  Â  // Zero the first block's memory
Â  Â  Â  Â  if arena.curr_block != nil {
Â  Â  Â  Â  Â  Â  curr_block_used := int(arena.curr_block.used)
Â  Â  Â  Â  Â  Â  arena.curr_block.used = 0
Â  Â  Â  Â  Â  Â  // sanitizer.address_unpoison(arena.curr_block.base[:curr_block_used])
Â  Â  Â  Â  Â  Â  mem.zero(arena.curr_block.base, curr_block_used)
Â  Â  Â  Â  Â  Â  // sanitizer.address_poison(arena.curr_block.base[:arena.curr_block.committed])
Â  Â  Â  Â  }
Â  Â  Â  Â  arena.total_used = 0
Â  Â  case .Static, .Buffer:
Â  Â  Â  Â  arena_static_reset_to(arena, 0)
Â  Â  }
Â  Â  arena.total_used = 0
}
</code></pre>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="allocator-procedure" >
    Allocator Procedure
</h5>
<pre><code class="language-odin" data-lang="odin">// The allocator procedure used by an `Allocator` produced by `arena_allocator`
@(no_sanitize_address)
arena_allocator_proc :: proc(allocator_data: rawptr, mode: mem.Allocator_Mode,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â size, alignment: int,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â old_memory: rawptr, old_size: int,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â location := #caller_location) -&gt; (data: []byte, err: Allocator_Error) {
Â  Â  arena := (^Arena)(allocator_data)
Â  Â  size, alignment := uint(size), uint(alignment)
Â  Â  old_size := uint(old_size)
Â  Â  switch mode {
Â  Â  case .Alloc, .Alloc_Non_Zeroed:
Â  Â  Â  Â  return arena_alloc(arena, size, alignment, location)
Â  Â  case .Free:
Â  Â  Â  Â  err = .Mode_Not_Implemented
Â  Â  case .Free_All:
Â  Â  Â  Â  arena_free_all(arena, location)
Â  Â  case .Resize, .Resize_Non_Zeroed:
Â  Â  Â  Â  old_data := ([^]byte)(old_memory)
Â  Â  Â  Â  switch {
Â  Â  Â  Â  case old_data == nil:
Â  Â  Â  Â  Â  Â  return arena_alloc(arena, size, alignment, location)
Â  Â  Â  Â  case size == old_size:
Â  Â  Â  Â  Â  Â  // return old memory
Â  Â  Â  Â  Â  Â  data = old_data[:size]
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  case size == 0:
Â  Â  Â  Â  Â  Â  err = .Mode_Not_Implemented
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  }
Â  Â  Â  Â  sync.mutex_guard(&arena.mutex)
Â  Â  Â  Â  if uintptr(old_data) & uintptr(alignment-1) == 0 {
Â  Â  Â  Â  Â  Â  if size &lt; old_size {
Â  Â  Â  Â  Â  Â  Â  Â  // shrink data in-place
Â  Â  Â  Â  Â  Â  Â  Â  data = old_data[:size]
Â  Â  Â  Â  Â  Â  Â  Â  // sanitizer.address_poison(old_data[size:old_size])
Â  Â  Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  if block := arena.curr_block; block != nil {
Â  Â  Â  Â  Â  Â  Â  Â  start := uint(uintptr(old_memory)) - uint(uintptr(block.base))
Â  Â  Â  Â  Â  Â  Â  Â  old_end := start + old_size
Â  Â  Â  Â  Â  Â  Â  Â  new_end := start + size
Â  Â  Â  Â  Â  Â  Â  Â  if start &lt; old_end && old_end == block.used && new_end &lt;= block.reserved {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // grow data in-place, adjusting next allocation
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prev_used := block.used
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  _ = alloc_from_memory_block(block, new_end - old_end, 1, default_commit_size=arena.default_commit_size) or_return
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  arena.total_used += block.used - prev_used
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data = block.base[start:new_end]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // sanitizer.address_unpoison(data)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  new_memory := arena_alloc_unguarded(arena, size, alignment, location) or_return
Â  Â  Â  Â  if new_memory == nil {
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  }
Â  Â  Â  Â  copy(new_memory, old_data[:old_size])
Â  Â  Â  Â  // sanitizer.address_poison(old_data[:old_size])
Â  Â  Â  Â  return new_memory, nil
Â  Â  case .Query_Features:
Â  Â  Â  Â  set := (^mem.Allocator_Mode_Set)(old_memory)
Â  Â  Â  Â  if set != nil {
Â  Â  Â  Â  Â  Â  set^ = {.Alloc, .Alloc_Non_Zeroed, .Free_All, .Resize, .Query_Features}
Â  Â  Â  Â  }
Â  Â  case .Query_Info:
Â  Â  Â  Â  err = .Mode_Not_Implemented
Â  Â  }
Â  Â  return
}
</code></pre>
<h4
	id="rollback-the-offset-from-codevmem-arena-greater-static-code-with-codevmem-arena_static_reset_to-code" >
    Rollback the offset from 
    <code>vmem.Arena -&gt; .Static</code>
    &nbsp;with 
    <code>vmem.arena_static_reset_to</code>
</h4>
<ul>
	<li>
		<p>
            Unlike other &quot;rollback arena options&quot;, there's no helper with that, but the following procedure can be used:
		</p>
		<ul>
			<li>
				<p>
                    Resets the memory of a Static or Buffer arena to a specific 
                    <code>position</code>
                    &nbsp;(offset) and zeroes the previously used memory.
				</p>
			</li>
			<li>
				<p>
                    It doesn't have a 
					<em>
                        begin
					</em>
                    , 
					<em>
                        end
					</em>
                    , or 
					<em>
                        guard
					</em>
                    ; the offset need to be defined by the user without any helpers.
				</p>
			</li>
			<li>
				<p>
					<input
						type="checkbox" 
						disabled=""
>
                    It doesn't &quot;free&quot; the memory, etc.
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">@(no_sanitize_address)
arena_static_reset_to :: proc(arena: ^Arena, pos: uint, loc := #caller_location) -&gt; bool {
&nbsp;&nbsp;&nbsp;&nbsp;sync.mutex_guard(&arena.mutex)
&nbsp;&nbsp;&nbsp;&nbsp;if arena.curr_block != nil {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert(arena.kind != .Growing, "expected a non .Growing arena", loc)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prev_pos := arena.curr_block.used
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arena.curr_block.used = clamp(pos, 0, arena.curr_block.reserved)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if prev_pos &gt; pos {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mem.zero_slice(arena.curr_block.base[arena.curr_block.used:][:prev_pos-pos])
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arena.total_used = arena.curr_block.used
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// sanitizer.address_poison(arena.curr_block.base[:arena.curr_block.committed])
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return true
&nbsp;&nbsp;&nbsp;&nbsp;} else if pos == 0 {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arena.total_used = 0
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return true
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;return false
}
</code></pre>
	</li>
</ul>
<h4
	id="free-last-memory-block-from-codevmem-arena-greater-growing-code-with-codevmem-arena_temp-code" >
    Free last Memory Block from&nbsp;&nbsp;
    <code>vmem.Arena -&gt; .Growing</code>
    &nbsp;with 
    <code>vmem.Arena_Temp</code>
</h4>
<ul>
	<li>
		<p>
            Is a way to produce temporary watermarks to reset an arena to a previous state.
		</p>
	</li>
	<li>
		<p>
            All uses of an 
            <code>Arena_Temp</code>
            &nbsp;must be handled by ending them with 
            <code>arena_temp_end</code>
            &nbsp;or ignoring them with 
            <code>arena_temp_ignore</code>
            .
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Arena :: struct {
Â  Â  kind: Â  Â  Â  Â  Â  Â  Â  Â Arena_Kind,
Â  Â  curr_block: Â  Â  Â  Â  Â ^Memory_Block,
Â  Â  total_used: Â  Â  Â  Â  Â uint,
Â  Â  total_reserved: Â  Â  Â uint,
Â  Â  default_commit_size: uint, // commit size &lt;= reservation size
Â  Â  minimum_block_size: Â uint, // block size == total reservation
Â  Â  temp_count: Â  Â  Â  Â  Â uint,
Â  Â  mutex: Â  Â  Â  Â  Â  Â  Â  sync.Mutex,
}

Memory_Block :: struct {
Â  Â  prev: ^Memory_Block,
Â  Â  base: Â  Â  Â [^]byte,
Â  Â  used: Â  Â  Â uint,
Â  Â  committed: uint,
Â  Â  reserved: Â uint,
}

Arena_Temp :: struct {
Â  Â  arena: ^Arena,
Â  Â  block: ^Memory_Block,
Â  Â  used: Â uint,
}
</code></pre>
<h5
	id="usage" >
    Usage
</h5>
<ul>
	<li>
		<p>
			<strong>
                Begin
			</strong>
            :
		</p>
<pre><code class="language-odin" data-lang="odin">@(require_results, no_sanitize_address)
arena_temp_begin :: proc(arena: ^Arena, loc := #caller_location) -&gt; (temp: Arena_Temp) {
Â  Â  assert(arena != nil, "nil arena", loc)
Â  Â  sync.mutex_guard(&arena.mutex)
Â  Â  
Â  Â  temp.arena = arena
Â  Â  temp.block = arena.curr_block
Â  Â  if arena.curr_block != nil {
Â  Â  Â  Â  temp.used = arena.curr_block.used
Â  Â  }
Â  Â  arena.temp_count += 1
Â  Â  return
}
</code></pre>
	</li>
	<li>
		<p>
			<strong>
                End
			</strong>
            :
		</p>
<pre><code class="language-odin" data-lang="odin">@(no_sanitize_address)
arena_growing_free_last_memory_block :: proc(arena: ^Arena, loc := #caller_location) {
Â  Â  if free_block := arena.curr_block; free_block != nil {
Â  Â  Â  Â  assert(arena.kind == .Growing, "expected a .Growing arena", loc)
Â  Â  Â  Â  arena.total_used -= free_block.used
Â  Â  Â  Â  arena.total_reserved -= free_block.reserved
Â  Â  Â  Â  arena.curr_block = free_block.prev
Â  Â  Â  Â  // sanitizer.address_poison(free_block.base[:free_block.committed])
Â  Â  Â  Â  memory_block_dealloc(free_block)
Â  Â  }
}

@(no_sanitize_address)
arena_temp_end :: proc(temp: Arena_Temp, loc := #caller_location) {
Â  Â  assert(temp.arena != nil, "nil arena", loc)
Â  Â  arena := temp.arena
Â  Â  sync.mutex_guard(&arena.mutex)
Â  Â  if temp.block != nil {
Â  Â  Â  Â  memory_block_found := false
Â  Â  Â  Â  for block := arena.curr_block; block != nil; block = block.prev {
Â  Â  Â  Â  Â  Â  if block == temp.block {
Â  Â  Â  Â  Â  Â  Â  Â  memory_block_found = true
Â  Â  Â  Â  Â  Â  Â  Â  break
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  if !memory_block_found {
Â  Â  Â  Â  Â  Â  assert(arena.curr_block == temp.block, "memory block stored within Arena_Temp not owned by Arena", loc)
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  for arena.curr_block != temp.block {
Â  Â  Â  Â  Â  Â  arena_growing_free_last_memory_block(arena)
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  if block := arena.curr_block; block != nil {
Â  Â  Â  Â  Â  Â  assert(block.used &gt;= temp.used, "out of order use of arena_temp_end", loc)
Â  Â  Â  Â  Â  Â  amount_to_zero := block.used-temp.used
Â  Â  Â  Â  Â  Â  mem.zero_slice(block.base[temp.used:][:amount_to_zero])
Â  Â  Â  Â  Â  Â  block.used = temp.used
Â  Â  Â  Â  Â  Â  arena.total_used -= amount_to_zero
Â  Â  Â  Â  }
Â  Â  }
Â  Â  assert(arena.temp_count &gt; 0, "double-use of arena_temp_end", loc)
Â  Â  arena.temp_count -= 1
}
</code></pre>
	</li>
	<li>
		<p>
			<strong>
                Guard
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    I didn't find any guard implementations for this one.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Ignore
			</strong>
            :
		</p>
<pre><code class="language-odin" data-lang="odin">@(no_sanitize_address)
arena_temp_ignore :: proc(temp: Arena_Temp, loc := #caller_location) {
Â  Â  assert(temp.arena != nil, "nil arena", loc)
Â  Â  arena := temp.arena
Â  Â  sync.mutex_guard(&arena.mutex)
Â  Â  assert(arena.temp_count &gt; 0, "double-use of arena_temp_end", loc)
Â  Â  arena.temp_count -= 1
}
</code></pre>
	</li>
	<li>
		<p>
			<strong>
                Check
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Asserts that all uses of 
                    <code>Arena_Temp</code>
                    &nbsp;has been used by an 
                    <code>Arena</code>
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">@(no_sanitize_address)
arena_check_temp :: proc(arena: ^Arena, loc := #caller_location) {
Â  Â  assert(arena.temp_count == 0, "Arena_Temp not been ended", loc)
}
</code></pre>
	</li>
</ul>
<h3
	id="arena-backed-buffer-as-an-arena-codemem-arena-code" >
    Arena: Backed buffer as an arena (
    <code>mem.Arena</code>
    )
</h3>
<ul>
	<li>
		<p>
            All those names are interchangeable.
		</p>
	</li>
	<li>
		<p>
            It's an allocator that uses a single backing buffer for allocations.
		</p>
	</li>
	<li>
		<p>
            The buffer is used contiguously, from start to end. Each subsequent allocation occupies the next adjacent region of memory in the buffer. Since the arena allocator does not keep track of any metadata associated with the allocations and their locations, it is impossible to free individual allocations.
		</p>
	</li>
	<li>
		<p>
            The arena allocator can be used for temporary allocations in frame-based memory management. Games are one example of such applications. A global arena can be used for any temporary memory allocations, and at the end of each frame all temporary allocations are freed. Since no temporary object is going to live longer than a frame, no lifetimes are violated.
		</p>
	</li>
	<li>
		<p>
            The arenaâ€™s logic only requires an offset (or pointer) to indicate the end of the last allocation.
		</p>
	</li>
	<li>
		<p>
            To allocate some memory from the arena, it is as simple as moving the offset (or pointer) forward. In Big-O notation, the allocation has complexity of 
			<em>
				<strong>
                    O(1)
				</strong>
			</em>
            &nbsp;(constant).
		</p>
	</li>
	<li>
		<p>
            On arenas being slices, it's important to realize that what they are is an implementation. All the abstract idea is, is to allocate linearly from a buffer such that you can quickly free everything. Whether it's a single buffer and cannot grow at all depends entirely on the arena allocator implementation in question.
		</p>
	</li>
	<li>
		<p>
            You cannot deallocate memory individually in an arena allocator.
		</p>
		<ul>
			<li>
				<p>
                    <code>free</code>
                    &nbsp;for pointers created using an arena does not work.
				</p>
				<ul>
					<li>
						<p>
                            Returns the error 
                            <code>Mode_Not_Implemented</code>
                            .
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
                    The correct approach is to use 
                    <code>delete</code>
                    &nbsp;on the entire arena.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<a
				href="https://www.youtube.com/watch?v=hI9aN8ZG4vg" 
				class="external-link" 
				target="_blank" >
                Arena Allocators - Nic Barker
			</a>
            .
		</p>
	</li>
	<li>
		<p>
			<a
				href="https://www.youtube.com/watch?v=1WnqZPD-qVc" 
				class="external-link" 
				target="_blank" >
                Problems of using Arena Allocators for arrays with changing capacity - Karl Zylinski
			</a>
            .
		</p>
		<ul>
			<li>
				<p>
					<a
						href="https://zylinski.se/posts/dynamic-arrays-and-arenas/" 
						class="external-link" 
						target="_blank" >
                        Article
					</a>
                    .
				</p>
			</li>
			<li>
				<p>
                    Shows problems with using 
                    <code>make([dynamic]int, arena_alloc)</code>
                    .
				</p>
				<ul>
					<li>
						<p>
							<a
								href="https://zylinski.se/posts/dynamic-arrays-and-arenas/#what-happened" 
								class="external-link" 
								target="_blank" >
                                Explanation
							</a>
                            .
						</p>
					</li>
					<li>
						<p>
                            &quot;Trail of dead stuff, for every resize&quot;.
						</p>
					</li>
					<li>
						<p>
                            <img src="assets/Pasted%20image%2020251111172505.png" width="323" alt="" >
                            .
						</p>
					</li>
					<li>
						<p>
                            Virtual Arenas doesn't always have this problem, as there's a special condition to avoid this, but it doesn't solve for every case.
						</p>
					</li>
				</ul>
			</li>
		</ul>
	</li>
	<li>
		<p>
            ~
			<a
				href="https://www.youtube.com/watch?v=TZ5a3gCCZYo" 
				class="external-link" 
				target="_blank" >
                Arena Allocators - Ryan Fleury
			</a>
            .
		</p>
		<ul>
			<li>
				<p>
                    It introduces DOD and tries to justify to the students how RAII can be really bad, etc.
				</p>
			</li>
			<li>
				<p>
                    When it comes to the arena, tho, I didn't really love the explanation. The arena could be really simple, but I felt like his examples went to a specific direction that could be simplified.
				</p>
			</li>
			<li>
				<p>
                    Most of the talk is: DOD -&gt; A specific implementation of Arena.
				</p>
			</li>
			<li>
				<p>
					<a
						href="https://www.rfleury.com/p/untangling-lifetimes-the-arena-allocator" 
						class="external-link" 
						target="_blank" >
                        Article
					</a>
                    .
				</p>
			</li>
		</ul>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Arena :: struct {
Â  Â  data: Â  Â  Â  []byte,
Â  Â  offset: Â  Â  int,
Â  Â  peak_used: Â int,
Â  Â  temp_count: int,
}

@(require_results)
arena_allocator :: proc(arena: ^Arena) -&gt; Allocator {
Â  Â  return Allocator{
Â  Â  Â  Â  procedure = arena_allocator_proc,
Â  Â  Â  Â  data = arena,&nbsp;&nbsp; // The DATA is the arena.
Â  Â  }
}
</code></pre>
<h5
	id="rationale" >
    Rationale
</h5>
<ul>
	<li>
		<p>
			<a
				href="https://www.gingerbill.org/article/2019/02/08/memory-allocation-strategies-002/" 
				class="external-link" 
				target="_blank" >
                Arena Allocator - Ginger Bill
			</a>
            .
		</p>
	</li>
	<li>
		<p>
            The simplest arena allocator 
			<em>
                could
			</em>
            &nbsp;look like this:
		</p>
	</li>
</ul>
<pre><code class="language-c" data-lang="c">static unsigned char *arena_buffer;
static size_t arena_buffer_length;
static size_t arena_offset;

void *arena_alloc(size_t size) {
&nbsp;&nbsp;&nbsp;&nbsp;// Check to see if the backing memory has space left
&nbsp;&nbsp;&nbsp;&nbsp;if (arena_offset+size &lt;= arena_buffer_length) {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void *ptr = &arena_buffer[arena_offset];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arena_offset += size;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// Zero new memory by default
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;memset(ptr, 0, size);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return ptr;
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;// Return NULL if the arena is out of memory
&nbsp;&nbsp;&nbsp;&nbsp;return NULL;
}
</code></pre>
<ul>
	<li>
		<p>
            There are two issues with this basic approach:
		</p>
		<ul>
			<li>
				<p>
                    You cannot reuse this procedure for different arenas
				</p>
				<ul>
					<li>
						<p>
                            Can be easily solved by coupling that global data into a structure and passing that to the procedure 
                            <code>arena_alloc</code>
                            .
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
                    The pointer returned may not be aligned correctly for the data you need.
				</p>
				<ul>
					<li>
						<p>
                            This requires understanding the basic issues of 
							<em>
                                unaligned memory
							</em>
                            .
						</p>
					</li>
				</ul>
			</li>
		</ul>
	</li>
	<li>
		<p>
            It's also missing some important features of a practical implementation:
		</p>
		<ul>
			<li>
				<p>
                    <code>init</code>
                    , 
                    <code>alloc</code>
                    , 
                    <code>free</code>
                    , 
                    <code>resize</code>
                    , 
                    <code>free_all</code>
                    .
				</p>
			</li>
			<li>
				<p>
					<a
						href="https://www.gingerbill.org/code/memory-allocation-strategies/part002.c" 
						class="external-link" 
						target="_blank" >
                        Practical implementation of an arena allocator
					</a>
                    .
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="initialize-an-arena" >
    Initialize an arena
</h5>
<ul>
	<li>
		<p>
            Initializes the arena 
            <code>a</code>
            &nbsp;with memory region 
            <code>data</code>
            &nbsp;as its backing buffer.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">arena_init :: proc(a: ^Arena, data: []byte) {
Â  Â  a.data Â  Â  Â  = data
Â  Â  a.offset Â  Â  = 0
Â  Â  a.peak_used Â = 0
Â  Â  a.temp_count = 0
Â  Â  // sanitizer.address_poison(a.data)
}
</code></pre>
<h5
	id="allocator-procedure" >
    Allocator Procedure
</h5>
<pre><code class="language-odin" data-lang="odin">arena_allocator_proc :: proc(
Â  Â  allocator_data: rawptr,
Â  Â  mode: Â  Â  Â  Â  Â  Allocator_Mode,
Â  Â  size: Â  Â  Â  Â  Â  int,
Â  Â  alignment: Â  Â  Â int,
Â  Â  old_memory: Â  Â  rawptr,
Â  Â  old_size: Â  Â  Â  int,
Â  Â  loc := #caller_location,
) -&gt; ([]byte, Allocator_Error) Â {
Â  Â  arena := cast(^Arena)allocator_data
Â  Â  switch mode {
Â  Â  case .Alloc:
Â  Â  Â  Â  return arena_alloc_bytes(arena, size, alignment, loc)
Â  Â  case .Alloc_Non_Zeroed:
Â  Â  Â  Â  return arena_alloc_bytes_non_zeroed(arena, size, alignment, loc)
Â  Â  case .Free:
Â  Â  Â  Â  return nil, .Mode_Not_Implemented
Â  Â  case .Free_All:
Â  Â  Â  Â  arena_free_all(arena)
Â  Â  case .Resize:
Â  Â  Â  Â  return default_resize_bytes_align(byte_slice(old_memory, old_size), size, alignment, arena_allocator(arena), loc)
Â  Â  case .Resize_Non_Zeroed:
Â  Â  Â  Â  return default_resize_bytes_align_non_zeroed(byte_slice(old_memory, old_size), size, alignment, arena_allocator(arena), loc)
Â  Â  case .Query_Features:
Â  Â  Â  Â  set := (^Allocator_Mode_Set)(old_memory)
Â  Â  Â  Â  if set != nil {
Â  Â  Â  Â  Â  Â  set^ = {.Alloc, .Alloc_Non_Zeroed, .Free_All, .Resize, .Resize_Non_Zeroed, .Query_Features}
Â  Â  Â  Â  }
Â  Â  Â  Â  return nil, nil
Â  Â  case .Query_Info:
Â  Â  Â  Â  return nil, .Mode_Not_Implemented
Â  Â  }
Â  Â  return nil, nil
}
</code></pre>
<h5
	id="allocate" >
    Allocate
</h5>
<ul>
	<li>
		<p>
            All allocation procedures call this one:
		</p>
	</li>
	<li>
		<p>
            Allocate non-initialized memory from an arena.
		</p>
	</li>
	<li>
		<p>
            This procedure allocates 
            <code>size</code>
            &nbsp;bytes of memory aligned on a boundary specified by 
            <code>alignment</code>
            &nbsp;from an arena 
            <code>a</code>
            .
		</p>
	</li>
	<li>
		<p>
            The allocated memory is not explicitly zero-initialized. This procedure returns a slice of the newly allocated memory region.
		</p>
	</li>
	<li>
		<p>
            It creates a byte slice by using a pointer and a length. The pointer is within the region of the arena.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">@(require_results)
arena_alloc_bytes_non_zeroed :: proc(
Â  Â  a: Â  Â ^Arena,
Â  Â  size: int,
Â  Â  alignment := DEFAULT_ALIGNMENT,
Â  Â  loc Â  Â  Â  := #caller_location
) -&gt; ([]byte, Allocator_Error) {
Â  Â  if a.data == nil {
Â  Â  Â  Â  panic("Allocation on uninitialized Arena allocator.", loc)
Â  Â  }
Â  Â  #no_bounds_check end := &a.data[a.offset]
Â  Â  ptr := align_forward(end, uintptr(alignment))
Â  Â  total_size := size + ptr_sub((^byte)(ptr), (^byte)(end))
Â  Â  if a.offset + total_size &gt; len(a.data) {
Â  Â  Â  Â  return nil, .Out_Of_Memory
Â  Â  }
Â  Â  a.offset += total_size
Â  Â  a.peak_used = max(a.peak_used, a.offset)
Â  Â  result := byte_slice(ptr, size)
Â  Â  // ensure_poisoned(result)
Â  Â  // sanitizer.address_unpoison(result)
Â  Â  return result, nil
}
</code></pre>
<h5
	id="free-all" >
    Free All
</h5>
<ul>
	<li>
		<p>
            Free all memory back to the arena allocator.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">arena_free_all :: proc(a: ^Arena) {
Â  Â  a.offset = 0
Â  Â  // sanitizer.address_poison(a.data)
}
</code></pre>
<h4
	id="rollback-the-offset-from-codemem-arena-code-with-codemem-arena_temp_memory-code" >
    Rollback the offset from 
    <code>mem.Arena</code>
    &nbsp;with: 
    <code>mem.Arena_Temp_Memory</code>
</h4>
<ul>
	<li>
		<p>
            Temporary memory region of an 
            <code>Arena</code>
            &nbsp;allocator.
		</p>
	</li>
	<li>
		<p>
            Temporary memory regions of an arena act as &quot;save-points&quot; for the allocator.
		</p>
	</li>
	<li>
		<p>
            When one is created, the subsequent allocations are done inside the temporary memory region.
		</p>
	</li>
	<li>
		<p>
            When 
            <code>end_arena_temp_memory</code>
            &nbsp;is called, the arena is rolled back, and all of the memory that was allocated from the arena will be freed.
		</p>
	</li>
	<li>
		<p>
            Multiple temporary memory regions can exist at the same time for an arena.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Arena_Temp_Memory :: struct {
Â  Â  arena: Â  Â  Â  ^Arena,
Â  Â  prev_offset: int,
}
</code></pre>
<h5
	id="usage" >
    Usage
</h5>
<ul>
	<li>
		<p>
			<strong>
                Begin
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Creates a temporary memory region. After a temporary memory region is created, all allocations are said to be 
					<em>
                        inside
					</em>
                    &nbsp;the temporary memory region, until 
                    <code>end_arena_temp_memory</code>
                    &nbsp;is called.
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">@(require_results)
begin_arena_temp_memory :: proc(a: ^Arena) -&gt; Arena_Temp_Memory {
Â  Â  tmp: Arena_Temp_Memory
Â  Â  tmp.arena = a
Â  Â  tmp.prev_offset = a.offset
Â  Â  a.temp_count += 1
Â  Â  return tmp
}
</code></pre>
	</li>
	<li>
		<p>
			<strong>
                End
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Ends the temporary memory region for an arena. All of the allocations 
					<em>
                        inside
					</em>
                    &nbsp;the temporary memory region will be freed to the arena.
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">end_arena_temp_memory :: proc(tmp: Arena_Temp_Memory) {
Â  Â  assert(tmp.arena.offset &gt;= tmp.prev_offset)
Â  Â  assert(tmp.arena.temp_count &gt; 0)
Â  Â  // sanitizer.address_poison(tmp.arena.data[tmp.prev_offset:tmp.arena.offset])
Â  Â  tmp.arena.offset = tmp.prev_offset
Â  Â  tmp.arena.temp_count -= 1
}
</code></pre>
	</li>
	<li>
		<p>
			<strong>
                Guard
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    I didn't find any guard implementations for this one.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h3
	id="arena-growing-codemem-arena-code-codemem-dynamic_arena-code" >
    Arena: Growing 
    <code>mem.Arena</code>
    &nbsp;(
    <code>mem.Dynamic_Arena</code>
    )
</h3>
<ul>
	<li>
		<p>
            The dynamic arena allocator uses blocks of a specific size, allocated on-demand using the block allocator. This allocator acts similarly to 
            <code>Arena</code>
            .
		</p>
	</li>
	<li>
		<p>
            All allocations in a block happen contiguously, from start to end. If an allocation does not fit into the remaining space of the block and its size is smaller than the specified out-band size, a new block is allocated using the 
            <code>block_allocator</code>
            &nbsp;and the allocation is performed from a newly-allocated block.
		</p>
	</li>
	<li>
		<p>
            If an allocation is larger than the specified out-band size, a new block is allocated such that the allocation fits into this new block. This is referred to as an 
			<em>
                out-band allocation
			</em>
            . The out-band blocks are kept separately from normal blocks.
		</p>
	</li>
	<li>
		<p>
            Just like 
            <code>Arena</code>
            , the dynamic arena does not support freeing of individual objects.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Dynamic_Arena :: struct {
Â  Â  block_size: Â  Â  Â  Â  Â  int,
Â  Â  out_band_size: Â  Â  Â  Â int,
Â  Â  alignment: Â  Â  Â  Â  Â  Â int,
Â  Â  unused_blocks: Â  Â  Â  Â [dynamic]rawptr,
Â  Â  used_blocks: Â  Â  Â  Â  Â [dynamic]rawptr,
Â  Â  out_band_allocations: [dynamic]rawptr,
Â  Â  current_block: Â  Â  Â  Â rawptr,
Â  Â  current_pos: Â  Â  Â  Â  Â rawptr,
Â  Â  bytes_left: Â  Â  Â  Â  Â  int,
Â  Â  block_allocator: Â  Â  Â Allocator,
}
</code></pre>
<h3
	id="arena-codecontext-temp_allocator-code-coderuntime-default_temp_allocator-code" >
    Arena: 
    <code>context.temp_allocator</code>
    &nbsp;(
    <code>runtime.Default_Temp_Allocator</code>
    )
</h3>
<ul>
	<li>
		<p>
            <code>Arena</code>
            &nbsp;here is a 
            <code>runtime.Arena</code>
		</p>
		<ul>
			<li>
				<p>
                    This 
                    <code>Arena</code>
                    &nbsp;is a growing arena that is only used for the default temp allocator.
				</p>
			</li>
			<li>
				<p>
                    &quot;For your own growing arena needs, prefer 
                    <code>Arena</code>
                    &nbsp;from 
                    <code>core:mem/virtual</code>
                    &quot;.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            By default, every 
            <code>Memory_Block</code>
            &nbsp;is backed by the 
            <code>context.allocator</code>
            .
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Arena :: struct {
&nbsp;&nbsp;&nbsp;&nbsp;backing_allocator: Â Allocator,
&nbsp;&nbsp;&nbsp;&nbsp;curr_block: Â  Â  Â  Â  ^Memory_Block,
&nbsp;&nbsp;&nbsp;&nbsp;total_used: Â  Â  Â  Â  uint,
&nbsp;&nbsp;&nbsp;&nbsp;total_capacity: Â  Â  uint,
&nbsp;&nbsp;&nbsp;&nbsp;minimum_block_size: uint,
&nbsp;&nbsp;&nbsp;&nbsp;temp_count: Â  Â  Â  Â  uint,
}

Memory_Block :: struct {
&nbsp;&nbsp;&nbsp;&nbsp;prev: Â  Â  Â ^Memory_Block,
&nbsp;&nbsp;&nbsp;&nbsp;allocator: Allocator,
&nbsp;&nbsp;&nbsp;&nbsp;base: Â  Â  Â [^]byte,
&nbsp;&nbsp;&nbsp;&nbsp;used: Â  Â  Â uint,
&nbsp;&nbsp;&nbsp;&nbsp;capacity: Â uint,
}

Default_Temp_Allocator :: struct {
&nbsp;&nbsp;&nbsp;&nbsp;arena: Arena,
}

@(require_results)
default_temp_allocator :: proc(allocator: ^Default_Temp_Allocator) -&gt; Allocator {
Â  Â  return Allocator{
Â  Â  Â  Â  procedure = default_temp_allocator_proc,
Â  Â  Â  Â  data Â  Â  Â = allocator,
Â  Â  }
}
</code></pre>
<h5
	id="default-codecontext-temp_allocator-code" >
    Default 
    <code>context.temp_allocator</code>
</h5>
<ul>
	<li>
		<p>
            <code>Default_Temp_Allocator</code>
            &nbsp;is a 
            <code>nil_allocator</code>
            &nbsp;when 
            <code>NO_DEFAULT_TEMP_ALLOCATOR</code>
            &nbsp;is 
            <code>true</code>
            .
		</p>
	</li>
	<li>
		<p>
            <code>context.temp_allocator</code>
            &nbsp;is typically called with 
            <code>free_all(context.temp_allocator)</code>
            &nbsp;once per &quot;frame-loop&quot; to prevent it from &quot;leaking&quot; memory.
		</p>
	</li>
	<li>
		<p>
			<strong>
                No Default
			</strong>
            :
		</p>
<pre><code class="language-odin" data-lang="odin">NO_DEFAULT_TEMP_ALLOCATOR: bool : ODIN_OS == .Freestanding || ODIN_DEFAULT_TO_NIL_ALLOCATOR
</code></pre>
		<ul>
			<li>
				<p>
                    Consequence of calling 
                    <code>-default-to-nil-allocator</code>
                    &nbsp;as a compiler flag.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="where-is-the-memory-actually-stored" >
    Where is the memory actually stored
</h5>
<ul>
	<li>
		<p>
            The 
			<strong>
                <code>Memory_Blocks</code>
                &nbsp;struct
			</strong>
            &nbsp;and the 
			<strong>
                reserved region
			</strong>
            &nbsp;from within the 
            <code>context.temp_allocator</code>
            &nbsp;are stored in its 
            <code>arena.backing_allocator</code>
            &nbsp;(usually 
            <code>context.allocator</code>
            ).
		</p>
	</li>
	<li>
		<p>
			<em>
                Analysis
			</em>
            :
		</p>
<pre><code class="language-odin" data-lang="odin">@(require_results)
memory_block_alloc :: proc(allocator: Allocator, capacity: uint, alignment: uint, loc := #caller_location) -&gt; (block: ^Memory_Block, err: Allocator_Error) {
Â  Â  total_size Â := uint(capacity + max(alignment, size_of(Memory_Block)))
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // The total size of the data (`[]byte`) that will be used for `mem_alloc`.
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // It's the `base_offset + capacity`; in other words: `Memory_Block` struct + `block.base` region.
Â  Â  
Â  Â  base_offset := uintptr(max(alignment, size_of(Memory_Block)))
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // It's an offset from the data (`[]byte`) that will be allocated.
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // It represents the start of the `block.base`, which is the region the block uses to allocate new data when called `alloc_from_memory_block`.
Â  Â  
Â  Â  min_alignment: int = max(16, align_of(Memory_Block), int(alignment))
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // I'm not completely sure, but it's only used in `mem_alloc`.
Â  Â  
Â  Â  data := mem_alloc(int(total_size), min_alignment, allocator, loc) or_return
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // A `[]byte` is alloc using the backing_allocator.
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  
Â  Â  block = (^Memory_Block)(raw_data(data))
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // The pointer to this slice is used as the pointer to the block.
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // This means that the block metadata will be the first thing populating the `[]byte` allocated.
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  
Â  Â  end := uintptr(raw_data(data)[len(data):])
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // Fancy way to get the pointer of the last element in the data (`[]byte`) region.
 Â  Â  
Â  Â  block.allocator = allocator
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // The backing_allocator is saved as the `block.allocator`
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  
Â  Â  block.base = ([^]byte)(uintptr(block) + base_offset)
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // The `baseÂ´ will be right after the block struct end (considering a custom alignment from the procedure args).
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // It represents the start of the region the block uses to allocate new data when called `alloc_from_memory_block`.
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  
Â  Â  block.capacity = uint(end - uintptr(block.base))
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // The size of the `block.base`.
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // Represents the allocation "capacity" of the `block.base`, which is how much memory the block can store.
&nbsp;&nbsp;&nbsp;&nbsp;Â  Â  // Calculated by doing the pointer subtraction: `uintptr(end) - uintptr(block.base)`.
Â  Â  
Â  Â  return
}
</code></pre>
	</li>
	<li>
		<p>
            What 
            <code>arena.backing_allocator</code>
            &nbsp;should be used?
		</p>
		<ul>
			<li>
				<p>
                    The 
                    <code>Memory_Blocks</code>
                    &nbsp;needs to be able to be free individually, as this is the main strategy around the 
                    <code>context.temp_allocator</code>
                    .
				</p>
			</li>
			<li>
				<p>
                    In that sense, the 
                    <code>backing_allocator</code>
                    &nbsp;should be an allocator that implements 
                    <code>.Free</code>
                    ; this means that 
                    <code>mem.Arena</code>
                    &nbsp;is not good for this.
				</p>
			</li>
			<li>
				<p>
                    Any allocator that implements 
                    <code>.Free</code>
                    &nbsp;should be enough, I believe.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            So, what's stored &quot;inside the 
            <code>context.temp_allocator</code>
            &quot;?
		</p>
		<ul>
			<li>
				<p>
                    &quot;Nothing&quot;.
				</p>
			</li>
			<li>
				<p>
                    I mean, the 
                    <code>context.temp_allocator</code>
                    &nbsp;is a 
                    <code>runtime.Arena</code>
                    , which is:
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">Arena :: struct {
Â  Â  backing_allocator: Â Allocator,
Â  Â  curr_block: Â  Â  Â  Â  ^Memory_Block,
Â  Â  total_used: Â  Â  Â  Â  uint,
Â  Â  total_capacity: Â  Â  uint,
Â  Â  minimum_block_size: uint,
Â  Â  temp_count: Â  Â  Â  Â  uint,
}
</code></pre>
		<ul>
			<li>
				<p>
                    And it's stored inside the 
                    <code>context</code>
                    &nbsp;(which is on the stack), with its backing 
                    <code>.data</code>
                    &nbsp;being a pointer to 
                    <code>global_default_temp_allocator_data</code>
                    , which is a global variable.
				</p>
			</li>
			<li>
				<p>
                    So, the 
                    <code>context.temp_allocator</code>
                    &nbsp;is just a struct on the stack; it doesn't store anything on the heap. Its 
                    <code>arena.backing_allocator</code>
                    &nbsp;is what actually decides where the memory is stored.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="threading" >
    Threading
</h5>
<ul>
	<li>
		<p>
			<strong>
                Thread-safe?
			</strong>
		</p>
		<ul>
			<li>
				<p>
                    Ginger Bill:
				</p>
				<ul>
					<li>
						<p>
                            Within a thread, yes. Across? No.
						</p>
					</li>
					<li>
						<p>
                            It's a thread-local allocator.
						</p>
					</li>
				</ul>
			</li>
		</ul>
	</li>
	<li>
		<p>
            See&nbsp;&nbsp;&lt;a href=&quot;Odin#Context&gt;Odin#Context&quot;
            </a>
            &nbsp;for information on how to handle the 
            <code>context.temp_allocator</code>
            &nbsp;if a existing one is used or not.
		</p>
	</li>
	<li>
		<p>
			<strong>
                Practical example: CPU multithreaded texture loading
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
					<strong>
                        How I handled the 
                        <code>context.temp_allocator</code>
					</strong>
                    :
				</p>
				<ul>
					<li>
						<p>
                            Each thread has a functional 
                            <code>context.temp_allocator</code>
                            , completely thread-local.
						</p>
					</li>
				</ul>
			</li>
			<li>
				<p>
					<strong>
                        Storing the image data
					</strong>
                    :
				</p>
				<ul>
					<li>
						<p>
							<em>
                                Using 
                                <code>context.temp_allocator</code>
                                &nbsp;from the main thread
							</em>
                            :
						</p>
						<ul>
							<li>
								<p>
                                    I was first using this while using a mutex in the 
                                    <code>pixels = make([]byte, size, allocator)</code>
                                    &nbsp;from 
                                    <code>load_image_file</code>
                                    , as the 
                                    <code>context.temp_allocator</code>
                                    &nbsp;is not thread-safe.
								</p>
								<ul>
									<li>
										<p>
                                            If the allocator were a 
                                            <code>vmem.Arena</code>
                                            , this was not going to be necessary, as the 
                                            <code>vmem.Arena</code>
                                            &nbsp;already has a mutex inside it, being thread-safe.
										</p>
									</li>
								</ul>
							</li>
							<li>
								<p>
                                    My main idea at first is that I would use the main thread's 
                                    <code>context.temp_allocator</code>
                                    , so the main thread can keep the data loaded from the other threads, as I need the main thread to be the one responsible for managing the loaded data's lifetime, to later can call 
                                    <code>texture_copy_from_buffer()</code>
                                    .
								</p>
							</li>
							<li>
								<p>
                                    Tho, later I realized that the 
                                    <code>context.temp_allocator</code>
                                    &nbsp;from the main thread can not be used, as the main thread also participates in the 
                                    <code>jobs.try_execute_queued_job_globals()</code>
                                    , which then provokes its own 
                                    <code>context.temp_allocator</code>
                                    &nbsp;to do 
                                    <code>free_all()</code>
                                    &nbsp;after one of its jobs is executed, breaking everything.
								</p>
							</li>
							<li>
								<p>
                                    If a 
									<em>
                                        guard
									</em>
                                    &nbsp;is used instead of 
                                    <code>free_all()</code>
                                    , this fixes the freeing problem, but it would be 
									<strong>
                                        very
									</strong>
                                    &nbsp;weird handling 
									<em>
                                        guard
									</em>
                                    s when the 
                                    <code>context.temp_allocator</code>
                                    &nbsp;is being used in different threads; this is not a good option in this case.
								</p>
							</li>
						</ul>
					</li>
					<li>
						<p>
							<em>
                                Using a 
                                <code>vmem.Arena</code>
                                &nbsp;from the main thread
							</em>
                            :
						</p>
						<ul>
							<li>
								<p>
                                    Much better. This arena has a mutex and it's already thread-safe.
								</p>
							</li>
							<li>
								<p>
                                    There's no risk of freeing the data from this arena, as it's completely managed by the main thread and untouched by the Jobs System.
								</p>
							</li>
							<li>
								<p>
                                    There's no direct participation of a 
                                    <code>context.temp_allocator</code>
                                    &nbsp;from a different thread; it's much simpler.
								</p>
							</li>
							<li>
								<p>
                                    I'm now using a 
									<em>
                                        guard
									</em>
                                    &nbsp;for the 
                                    <code>context.temp_allocator</code>
                                    &nbsp;after the job is executed; this ensures no incorrect data is deleted by accident by calling 
                                    <code>free_all()</code>
                                    ; if this was not done, the main thread crashes 
									<em>
                                        after
									</em>
                                    &nbsp;all the jobs are executed, as it lost some important data from the dispatcher scope.
								</p>
							</li>
						</ul>
					</li>
				</ul>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="tracy-interaction" >
    Tracy interaction
</h5>
<ul>
	<li>
		<p>
            <code>free_all</code>
		</p>
		<ul>
			<li>
				<p>
                    Is ok, as it's just calling the 
                    <code>allocator_proc</code>
                    &nbsp;from inside its 
                    <code>backing_allocator</code>
                    .
				</p>
			</li>
			<li>
				<p>
                    If the 
                    <code>backing_allocator</code>
                    &nbsp;is profiled, then it works perfectly fine.
				</p>
			</li>
			<li>
				<p>
                    <code>.Free_All</code>
                    &nbsp;becames 
                    <code>.Free</code>
                    &nbsp;for every 
                    <code>Memory_Block</code>
                    , followed by the remaining 
                    <code>Memory_Block</code>
                    &nbsp;being zeroed out.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="init" >
    Init
</h5>
<ul>
	<li>
		<p>
			<strong>
                App initialization
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    The first thing done before calling the entry point of the code, is:
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">// Unix example
@(link_name="main", linkage="strong", require)
main :: proc "c" (argc: i32, argv: [^]cstring) -&gt; i32 {
&nbsp;&nbsp;&nbsp;&nbsp;args__ = argv[:argc]
&nbsp;&nbsp;&nbsp;&nbsp;context = default_context()
&nbsp;&nbsp;&nbsp;&nbsp;#force_no_inline _startup_runtime()
&nbsp;&nbsp;&nbsp;&nbsp;intrinsics.__entry_point()
&nbsp;&nbsp;&nbsp;&nbsp;#force_no_inline _cleanup_runtime()
&nbsp;&nbsp;&nbsp;&nbsp;return 0
}
</code></pre>
		<ul>
			<li>
				<p>
                    The 
                    <code>default_context()</code>
                    will internally call 
                    <code>__init_context()</code>
                    , which internally assigns:
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">c.temp_allocator.procedure = default_temp_allocator_proc
</code></pre>
	</li>
</ul>
<p>
    Â  Â  when !NO_DEFAULT_TEMP_ALLOCATOR {
    <br>
    Â  Â  Â  Â  c.temp_allocator.data = &amp;global_default_temp_allocator_data
    <br>
    Â  Â  }
    <br>
    <code>- The `global_default_temp_allocator_data` is defined at comp-time as:</code>
    odin
    <br>
    when !NO_DEFAULT_TEMP_ALLOCATOR {
    <br>
    Â  Â  when ODIN_ARCH == .i386 &amp;&amp; ODIN_OS == .Windows {
    <br>
    Â  Â  Â  Â  // Thread-local storage is problematic on Windows i386
    <br>
    Â  Â  Â  Â  global_default_temp_allocator_data: Default_Temp_Allocator
    <br>
    Â  Â  } else {
    <br>
    Â  Â  Â  Â  @thread_local global_default_temp_allocator_data: Default_Temp_Allocator
    <br>
    Â  Â  }
    <br>
    }
    <br>
    ```
    <br>
    - At this point, the 
    <code>.data</code>
    &nbsp;doesn't have anything, besides an empty `runtime.Arena`.
</p>
<ul>
	<li>
		<p>
			<strong>
                Let the 
                <code>context.temp_allocator</code>
                &nbsp;be initialized automatically
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    When using the 
                    <code>context.temp_allocator</code>
                    &nbsp;to alloc anything, this procedure will be called:
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">default_temp_allocator_proc :: proc(allocator_data: rawptr, mode: Allocator_Mode,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;size, alignment: int,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;old_memory: rawptr, old_size: int, loc := #caller_location) -&gt; (data: []byte, err: Allocator_Error) {
&nbsp;&nbsp;&nbsp;&nbsp;s := (^Default_Temp_Allocator)(allocator_data)
&nbsp;&nbsp;&nbsp;&nbsp;return arena_allocator_proc(&s.arena, mode, size, alignment, old_memory, old_size, loc)
}
</code></pre>
		<ul>
			<li>
				<p>
                    The 
                    <code>runtime.arena_allocator_proc</code>
                    &nbsp;will internally call 
                    <code>runtime.arena_alloc</code>
                    .
				</p>
			</li>
			<li>
				<p>
                    Finally, if no 
                    <code>backing_allocator</code>
                    &nbsp;was set for the 
                    <code>context.temp_allocator</code>
                    , the 
                    <code>default_allocator()</code>
                    &nbsp;will be used:
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">if arena.backing_allocator.procedure == nil {
&nbsp;&nbsp;&nbsp;&nbsp;arena.backing_allocator = default_allocator()
}
</code></pre>
		<ul>
			<li>
				<p>
                    The default size will be:
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">DEFAULT_TEMP_ALLOCATOR_BACKING_SIZE: int : #config(DEFAULT_TEMP_ALLOCATOR_BACKING_SIZE, 4 * Megabyte)
</code></pre>
		<ul>
			<li>
				<p>
                    The minimum size is 
                    <code>4 KiB</code>
                    ; this is enforced by the 
                    <code>arena_init</code>
                    .
				</p>
			</li>
			<li>
				<p>
                    The 
                    <code>default_allocator</code>
                    &nbsp;is the 
                    <code>heap_allocator</code>
                    &nbsp;if the conditions are met:
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">when ODIN_DEFAULT_TO_NIL_ALLOCATOR {
Â  Â  default_allocator_proc :: nil_allocator_proc
Â  Â  default_allocator :: nil_allocator
} else when ODIN_DEFAULT_TO_PANIC_ALLOCATOR {
Â  Â  default_allocator_proc :: panic_allocator_proc
Â  Â  default_allocator :: panic_allocator
} else when ODIN_OS != .Orca && (ODIN_ARCH == .wasm32 || ODIN_ARCH == .wasm64p32) {
Â  Â  default_allocator :: default_wasm_allocator
Â  Â  default_allocator_proc :: wasm_allocator_proc
} else {
Â  Â  default_allocator :: heap_allocator
Â  Â  default_allocator_proc :: heap_allocator_proc
}
</code></pre>
	</li>
	<li>
		<p>
			<strong>
                Manually initialize the 
                <code>context.temp_allocator</code>
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Initializes the global temporary allocator used as the default 
                    <code>context.temp_allocator</code>
                    .
				</p>
			</li>
			<li>
				<p>
                    This is ignored when 
                    <code>NO_DEFAULT_TEMP_ALLOCATOR</code>
                    &nbsp;is true.
				</p>
			</li>
			<li>
				<p>
                    &quot;This procedure is not necessary to use the Arena as the default zero as 
                    <code>arena_alloc</code>
                    &nbsp;will set things up if necessary&quot;; this means that if this is not called, the 
                    <code>context.temp_allocator</code>
                    &nbsp;will be initialized automatically during its first allocation.&quot;
				</p>
			</li>
			<li>
				<p>
                    As this is a builtin procedure, you can just call it as 
                    <code>init_global_temporary_allocator(..)</code>
                    .
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">@(builtin, disabled=NO_DEFAULT_TEMP_ALLOCATOR)
init_global_temporary_allocator :: proc(size: int, backup_allocator := context.allocator) {
Â  Â  when !NO_DEFAULT_TEMP_ALLOCATOR {
Â  Â  Â  Â  default_temp_allocator_init(&global_default_temp_allocator_data, size, backup_allocator)
Â  Â  }
}
</code></pre>
		<ul>
			<li>
				<p>
                    Internally, this will be called:
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">@(require_results)
memory_block_alloc :: proc(allocator: Allocator, capacity: uint, alignment: uint, loc := #caller_location) -&gt; (block: ^Memory_Block, err: Allocator_Error) {
Â  Â  total_size Â := uint(capacity + max(alignment, size_of(Memory_Block)))
Â  Â  base_offset := uintptr(max(alignment, size_of(Memory_Block)))
Â  Â  
Â  Â  min_alignment: int = max(16, align_of(Memory_Block), int(alignment))
Â  Â  data := mem_alloc(int(total_size), min_alignment, allocator, loc) or_return
Â  Â  block = (^Memory_Block)(raw_data(data))
Â  Â  end := uintptr(raw_data(data)[len(data):])
Â  Â  
Â  Â  block.allocator = allocator
Â  Â  block.base = ([^]byte)(uintptr(block) + base_offset)
Â  Â  block.capacity = uint(end - uintptr(block.base))
Â  Â  
Â  Â  // sanitizer.address_poison(block.base, block.capacity)
Â  Â  
Â  Â  // Should be zeroed
Â  Â  assert(block.used == 0)
Â  Â  assert(block.prev == nil)
Â  Â  return
}

// Initializes the arena with a usable block. 
@(require_results)
arena_init :: proc(arena: ^Arena, size: uint, backing_allocator: Allocator, loc := #caller_location) -&gt; Allocator_Error {
Â  Â  arena^ = {}
Â  Â  arena.backing_allocator = backing_allocator
Â  Â  arena.minimum_block_size = max(size, 1&lt;&lt;12) // minimum block size of 4 KiB
Â  Â  new_block := memory_block_alloc(arena.backing_allocator, arena.minimum_block_size, 0, loc) or_return
Â  Â  arena.curr_block = new_block
Â  Â  arena.total_capacity += new_block.capacity
Â  Â  return nil
}

default_temp_allocator_init :: proc(s: ^Default_Temp_Allocator, size: int, backing_allocator := context.allocator) {
&nbsp;&nbsp;&nbsp;&nbsp;_ = arena_init(&s.arena, uint(size), backing_allocator)
}
</code></pre>
	</li>
</ul>
<h5
	id="deinit" >
    Deinit
</h5>
<ul>
	<li>
		<p>
            Called automatically after the 
            <code>main</code>
            &nbsp;procedure ends (
            <code>@(fini)</code>
            ).
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">arena_destroy :: proc "contextless" (arena: ^Arena, loc := #caller_location) {
Â  Â  for arena.curr_block != nil {
Â  Â  Â  Â  free_block := arena.curr_block
Â  Â  Â  Â  arena.curr_block = free_block.prev
Â  Â  Â  Â  arena.total_capacity -= free_block.capacity
Â  Â  Â  Â  memory_block_dealloc(free_block, loc)
Â  Â  }
Â  Â  arena.total_used = 0
Â  Â  arena.total_capacity = 0
}

default_temp_allocator_destroy :: proc "contextless" (s: ^Default_Temp_Allocator) {
&nbsp;&nbsp;&nbsp;&nbsp;if s != nil {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arena_destroy(&s.arena)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s^ = {}
&nbsp;&nbsp;&nbsp;&nbsp;}
}

@(fini, private)
_destroy_temp_allocator_fini :: proc "contextless" () {
&nbsp;&nbsp;&nbsp;&nbsp;default_temp_allocator_destroy(&global_default_temp_allocator_data)
}
</code></pre>
<h5
	id="allocator-proc" >
    Allocator Proc
</h5>
<pre><code class="language-odin" data-lang="odin">default_temp_allocator_proc :: proc(allocator_data: rawptr, mode: Allocator_Mode,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;size, alignment: int,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;old_memory: rawptr, old_size: int, loc := #caller_location) -&gt; (data: []byte, err: Allocator_Error) {
&nbsp;&nbsp;&nbsp;&nbsp;s := (^Default_Temp_Allocator)(allocator_data)
&nbsp;&nbsp;&nbsp;&nbsp;return arena_allocator_proc(&s.arena, mode, size, alignment, old_memory, old_size, loc)
}

arena_allocator_proc :: proc(allocator_data: rawptr, mode: Allocator_Mode,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â size, alignment: int,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â old_memory: rawptr, old_size: int,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â location := #caller_location) -&gt; (data: []byte, err: Allocator_Error) {
Â  Â  arena := (^Arena)(allocator_data)
Â  Â  size, alignment := uint(size), uint(alignment)
Â  Â  old_size := uint(old_size)
Â  Â  switch mode {
Â  Â  case .Alloc, .Alloc_Non_Zeroed:
Â  Â  Â  Â  return arena_alloc(arena, size, alignment, location)
Â  Â  case .Free:
Â  Â  Â  Â  err = .Mode_Not_Implemented
Â  Â  case .Free_All:
Â  Â  Â  Â  arena_free_all(arena, location)
Â  Â  case .Resize, .Resize_Non_Zeroed:
Â  Â  Â  Â  old_data := ([^]byte)(old_memory)
Â  Â  Â  Â  switch {
Â  Â  Â  Â  case old_data == nil:
Â  Â  Â  Â  Â  Â  return arena_alloc(arena, size, alignment, location)
Â  Â  Â  Â  case size == old_size:
Â  Â  Â  Â  Â  Â  // return old memory
Â  Â  Â  Â  Â  Â  data = old_data[:size]
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  case size == 0:
Â  Â  Â  Â  Â  Â  err = .Mode_Not_Implemented
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  case uintptr(old_data) & uintptr(alignment-1) == 0:
Â  Â  Â  Â  Â  Â  if size &lt; old_size {
Â  Â  Â  Â  Â  Â  Â  Â  // shrink data in-place
Â  Â  Â  Â  Â  Â  Â  Â  data = old_data[:size]
Â  Â  Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  if block := arena.curr_block; block != nil {
Â  Â  Â  Â  Â  Â  Â  Â  start := uint(uintptr(old_memory)) - uint(uintptr(block.base))
Â  Â  Â  Â  Â  Â  Â  Â  old_end := start + old_size
Â  Â  Â  Â  Â  Â  Â  Â  new_end := start + size
Â  Â  Â  Â  Â  Â  Â  Â  if start &lt; old_end && old_end == block.used && new_end &lt;= block.capacity {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // grow data in-place, adjusting next allocation
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  block.used = uint(new_end)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data = block.base[start:new_end]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // sanitizer.address_unpoison(data)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  new_memory := arena_alloc(arena, size, alignment, location) or_return
Â  Â  Â  Â  if new_memory == nil {
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  }
Â  Â  Â  Â  copy(new_memory, old_data[:old_size])
Â  Â  Â  Â  return new_memory, nil
Â  Â  case .Query_Features:
Â  Â  Â  Â  set := (^Allocator_Mode_Set)(old_memory)
Â  Â  Â  Â  if set != nil {
Â  Â  Â  Â  Â  Â  set^ = {.Alloc, .Alloc_Non_Zeroed, .Free_All, .Resize, .Query_Features}
Â  Â  Â  Â  }
Â  Â  case .Query_Info:
Â  Â  Â  Â  err = .Mode_Not_Implemented
Â  Â  }
Â  Â  return
}
</code></pre>
<h4
	id="free-last-memory-block-from-coderuntime-arena-code-codecontext-temp_allocator-code-with-coderuntime-arena_temp-code-quotetemp-allocator-tempquote-coderuntime-default_temp_allocator_temp_guard-code" >
    Free last Memory Block from 
    <code>runtime.Arena</code>
    &nbsp;(
    <code>context.temp_allocator</code>
    ) with 
    <code>runtime.Arena_Temp</code>
    &nbsp;/ &quot;Temp Allocator Temp&quot; / 
    <code>runtime.DEFAULT_TEMP_ALLOCATOR_TEMP_GUARD</code>
</h4>
<ul>
	<li>
		<p>
            Is a way to produce temporary watermarks to reset an arena to a previous state.
		</p>
	</li>
	<li>
		<p>
            All uses of an 
            <code>Arena_Temp</code>
            &nbsp;must be handled by ending them with 
            <code>arena_temp_end</code>
            &nbsp;or ignoring them with 
            <code>arena_temp_ignore</code>
            .
		</p>
	</li>
	<li>
		<p>
            <code>Arena</code>
            &nbsp;here is a 
            <code>runtime.Arena</code>
		</p>
		<ul>
			<li>
				<p>
                    This 
                    <code>Arena</code>
                    &nbsp;is a growing arena that is only used for the default temp allocator.
				</p>
			</li>
			<li>
				<p>
                    &quot;For your own growing arena needs, prefer 
                    <code>Arena</code>
                    &nbsp;from 
                    <code>core:mem/virtual</code>
                    &quot;.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            <code>base:runtime -&gt; default_temp_allocator_arena.odin</code>
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Arena :: struct {
Â  Â  backing_allocator: Â Allocator,
Â  Â  curr_block: Â  Â  Â  Â  ^Memory_Block,
Â  Â  total_used: Â  Â  Â  Â  uint,
Â  Â  total_capacity: Â  Â  uint,
Â  Â  minimum_block_size: uint,
Â  Â  temp_count: Â  Â  Â  Â  uint,
}

Memory_Block :: struct {
Â  Â  prev: Â  Â  Â ^Memory_Block,
Â  Â  allocator: Allocator,
Â  Â  base: Â  Â  Â [^]byte,
Â  Â  used: Â  Â  Â uint,
Â  Â  capacity: Â uint,
}

Arena_Temp :: struct {
Â  Â  arena: ^Arena,
Â  Â  block: ^Memory_Block,
Â  Â  used: Â uint,
}
</code></pre>
<h5
	id="differences-from-the-codemem-arena_temp-code" >
    Differences from the 
    <code>mem.Arena_Temp</code>
</h5>
<ul>
	<li>
		<p>
            The 
            <code>runtime.Arena_Temp</code>
            &nbsp;has no 
            <code>Mutex</code>
            .
		</p>
	</li>
	<li>
		<p>
            The 
            <code>runtime.Arena_Temp</code>
            &nbsp;is made the 
            <code>runtime.Arena</code>
            , which is a growing arena; it's not for static arenas.
		</p>
	</li>
	<li>
		<p>
            Etc, I think these are the main differences.
		</p>
	</li>
</ul>
<h5
	id="tldr-and-faq-how-the-guard-works" >
    TLDR and FAQ: How the guard works
</h5>
<ul>
	<li>
		<p>
            When exiting the scope:
		</p>
		<ul>
			<li>
				<p>
                    It frees all the new memory blocks from the arena.
				</p>
			</li>
			<li>
				<p>
                    Any new things in the 
                    <code>temp.block</code>
                    &nbsp;(which is now the 
                    <code>arena.curr_block</code>
                    ) are zeroed.
				</p>
			</li>
			<li>
				<p>
                    The &quot;arena current position&quot; is rolled back (
                    <code>block.used</code>
                    ).
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Is it inefficient to use this guard everywhere? Where should I use this guard vs just using the 
            <code>context.temp_allocator</code>
            &nbsp;directly?
		</p>
		<ul>
			<li>
				<p>
                    The guard will not free any memory if there's no new block inside the arena, BUT, it will ensure the new memory created within the arena is zeroed and the &quot;arena current position&quot; is rolled back.
				</p>
			</li>
			<li>
				<p>
                    In that sense, even though it might have situations where nothing will be freed on the OS, the arena will have &quot;more space&quot;, as new things can be allocated disregarding the space used in allocations inside the guard scope.
				</p>
			</li>
			<li>
				<p>
                    As a conclusion, it might not be that performance efficient to use the guard everywhere, but it reduces memory spikes. The more guards used, the more frequent the frees can be, reducing the memory spike, but approximating the allocator to a &quot;general allocator&quot; with 
                    <code>new</code>
                    /
                    <code>free</code>
                    . It's all about lifetimes. A good use of the guard is when placed where it prevents memory spikes and it's not frequent enough so it becomes inefficient.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="usage" >
    Usage
</h5>
<p>
    <code>base:runtime -&gt; default_temp_allocator_arena.odin + default_temporary_allocator.odin</code>
</p>
<ul>
	<li>
		<p>
			<strong>
                Begin
			</strong>
            :
		</p>
<pre><code class="language-odin" data-lang="odin">@(require_results)
arena_temp_begin :: proc(arena: ^Arena, loc := #caller_location) -&gt; (temp: Arena_Temp) {
Â  Â  assert(arena != nil, "nil arena", loc)
Â  Â  temp.arena = arena
Â  Â  temp.block = arena.curr_block
Â  Â  if arena.curr_block != nil {
Â  Â  Â  Â  temp.used = arena.curr_block.used
Â  Â  }
Â  Â  arena.temp_count += 1
Â  Â  return
}

@(require_results)
default_temp_allocator_temp_begin :: proc(loc := #caller_location) -&gt; (temp: Arena_Temp) {
&nbsp;&nbsp;&nbsp;&nbsp;if context.temp_allocator.data == &global_default_temp_allocator_data {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;temp = arena_temp_begin(&global_default_temp_allocator_data.arena, loc)
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;return
}
</code></pre>
		<ul>
			<li>
				<p>
                    The 
                    <code>runtime.Arena</code>
                    &nbsp;has a 
                    <code>temp_count</code>
                    &nbsp;to keep track to not used 
                    <code>_end</code>
                    &nbsp;twice in a row; if you just use the 
					<strong>
                        guard
					</strong>
                    , then this shouldn't matter.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                End
			</strong>
            :
		</p>
<pre><code class="language-odin" data-lang="odin">mem_free :: #force_no_inline proc(ptr: rawptr, allocator := context.allocator, loc := #caller_location) -&gt; Allocator_Error {
Â  Â  if ptr == nil || allocator.procedure == nil {
Â  Â  Â  Â  return nil
Â  Â  }
Â  Â  _, err := allocator.procedure(allocator.data, .Free, 0, 0, ptr, 0, loc)
Â  Â  return err
}

memory_block_dealloc :: proc "contextless" (block_to_free: ^Memory_Block, loc := #caller_location) {
Â  Â  if block_to_free != nil {
Â  Â  Â  Â  allocator := block_to_free.allocator
Â  Â  Â  Â  // sanitizer.address_unpoison(block_to_free.base, block_to_free.capacity)
Â  Â  Â  Â  context = default_context()
Â  Â  Â  Â  context.allocator = allocator
Â  Â  Â  Â  mem_free(block_to_free, allocator, loc)
Â  Â  }
}

arena_free_last_memory_block :: proc(arena: ^Arena, loc := #caller_location) {
Â  Â  if free_block := arena.curr_block; free_block != nil {
Â  Â  Â  Â  arena.curr_block = free_block.prev
Â  Â  Â  Â  
Â  Â  Â  Â  arena.total_capacity -= free_block.capacity
Â  Â  Â  Â  memory_block_dealloc(free_block, loc)
Â  Â  }
}
&nbsp;&nbsp;
arena_temp_end :: proc(temp: Arena_Temp, loc := #caller_location) {
Â  Â  if temp.arena == nil {
Â  Â  Â  Â  assert(temp.block == nil)
Â  Â  Â  Â  assert(temp.used == 0)
Â  Â  Â  Â  return
Â  Â  }
Â  Â  arena := temp.arena
Â  Â  if temp.block != nil {
Â  Â  Â  Â  memory_block_found := false
Â  Â  Â  Â  for block := arena.curr_block; block != nil; block = block.prev {
Â  Â  Â  Â  Â  Â  if block == temp.block {
Â  Â  Â  Â  Â  Â  Â  Â  memory_block_found = true
Â  Â  Â  Â  Â  Â  Â  Â  break
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  if !memory_block_found {
Â  Â  Â  Â  Â  Â  assert(arena.curr_block == temp.block, "memory block stored within Arena_Temp not owned by Arena", loc)
Â  Â  Â  Â  }
Â  Â  Â  Â  for arena.curr_block != temp.block {
Â  Â  Â  Â  Â  Â  arena_free_last_memory_block(arena)
Â  Â  Â  Â  }
Â  Â  Â  Â  if block := arena.curr_block; block != nil {
Â  Â  Â  Â  Â  Â  assert(block.used &gt;= temp.used, "out of order use of arena_temp_end", loc)
Â  Â  Â  Â  Â  Â  amount_to_zero := block.used-temp.used
Â  Â  Â  Â  Â  Â  intrinsics.mem_zero(block.base[temp.used:], amount_to_zero)
Â  Â  Â  Â  Â  Â  // sanitizer.address_poison(block.base[temp.used:block.capacity])
Â  Â  Â  Â  Â  Â  block.used = temp.used
Â  Â  Â  Â  Â  Â  arena.total_used -= amount_to_zero
Â  Â  Â  Â  }
Â  Â  }
Â  Â  assert(arena.temp_count &gt; 0, "double-use of arena_temp_end", loc)
Â  Â  arena.temp_count -= 1
}

default_temp_allocator_temp_end :: proc(temp: Arena_Temp, loc := #caller_location) {
&nbsp;&nbsp;&nbsp;&nbsp;arena_temp_end(temp, loc)
}
</code></pre>
		<ul>
			<li>
				<p>
                    The most important operations are:
				</p>
				<ul>
					<li>
						<p>
                            Frees any 
							<em>
                                new
							</em>
                            &nbsp;memory blocks from the 
                            <code>context.temp_allocator</code>
                            , comparing to the memory block stored on 
                            <code>arena_temp_begin</code>
                            :
						</p>
<pre><code class="language-odin" data-lang="odin">for arena.curr_block != temp.block {
</code></pre>
					</li>
				</ul>
			</li>
		</ul>
		<p>
            Â  Â  Â  Â  Â  Â  arena_free_last_memory_block(arena)
            <br>
            }
            <br>
            <code>- Internally:</code>
            odin
            <br>
            arena.curr_block = free_block.prev
            <br>
            arena.total_capacity -= free_block.capacity
            <br>
            <code>- Zero the extra memory used during the scope:</code>
            odin
            <br>
            amount_to_zero := block.used-temp.used
            <br>
            intrinsics.mem_zero(block.base[temp.used:], amount_to_zero)
            <br>
            <code>- Revert the `arena.curr_block.used` and `arena.total_used` </code>
            odin
            <br>
            block.used = temp.used&nbsp;&nbsp;// 
            <code>block</code>
            &nbsp;is 
            <code>arena.curr_block</code>
            &nbsp;in this case.
            <br>
            arena.total_used -= amount_to_zero
            <br>
            ```
		</p>
	</li>
	<li>
		<p>
			<strong>
                Guard
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    This one is used 
					<strong>
                        A LOT
					</strong>
                    &nbsp;in the 
                    <code>core</code>
                    &nbsp;library.
				</p>
			</li>
			<li>
				<p>
                    The return value from this procedure is never handled on purpose. The only reason there is a return is to send it to the 
                    <code>default_temp_allocator_temp_end</code>
                    &nbsp;on exiting the scope. The user doesn't usually care about the 
                    <code>Arena_Temp</code>
                    .
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">@(deferred_out=default_temp_allocator_temp_end)
DEFAULT_TEMP_ALLOCATOR_TEMP_GUARD :: #force_inline proc(ignore := false, loc := #caller_location) -&gt; (Arena_Temp, Source_Code_Location) {
Â  Â  if ignore {
Â  Â  Â  Â  return {}, loc
Â  Â  } else {
Â  Â  Â  Â  return default_temp_allocator_temp_begin(loc), loc
Â  Â  }
}
</code></pre>
	</li>
	<li>
		<p>
			<strong>
                Ignore
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Ignore the use of a 
                    <code>arena_temp_begin</code>
                    &nbsp;entirely.
				</p>
			</li>
			<li>
				<p>
                    The 
                    <code>ignore</code>
                    &nbsp;is usually used like so, for example:
				</p>
			</li>
		</ul>
<pre><code class="language-odin" data-lang="odin">runtime.DEFAULT_TEMP_ALLOCATOR_TEMP_GUARD(ignore = context.temp_allocator == context.allocator)
</code></pre>
<pre><code class="language-odin" data-lang="odin">arena_temp_ignore :: proc(temp: Arena_Temp, loc := #caller_location) {
Â  Â  assert(temp.arena != nil, "nil arena", loc)
Â  Â  arena := temp.arena
Â  Â  assert(arena.temp_count &gt; 0, "double-use of arena_temp_end", loc)
Â  Â  arena.temp_count -= 1
}
</code></pre>
	</li>
	<li>
		<p>
			<strong>
                Check
			</strong>
            :
		</p>
<pre><code class="language-odin" data-lang="odin">arena_check_temp :: proc(arena: ^Arena, loc := #caller_location) {
Â  Â  assert(arena.temp_count == 0, "Arena_Temp not been ended", loc)
}
</code></pre>
	</li>
</ul>
<h3
	id="scratch-allocator" >
    Scratch Allocator
</h3>
<ul>
	<li>
		<p>
            The scratch allocator works in a similar way to the 
            <code>Arena</code>
            &nbsp;allocator.
		</p>
	</li>
	<li>
		<p>
            It has a backing buffer that is allocated in contiguous regions, from start to end.
		</p>
	</li>
	<li>
		<p>
            Each subsequent allocation will be the next adjacent region of memory in the backing buffer.
		</p>
	</li>
	<li>
		<p>
			<em>
                If the allocation doesn't fit into the remaining space of the backing buffer, this allocation is put at the start of the buffer, and all previous allocations will become invalidated.
			</em>
		</p>
	</li>
	<li>
		<p>
			<strong>
                If doesn't fit
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    If the allocation doesn't fit into the backing buffer as a whole, it will be allocated using a backing allocator, and the pointer to the allocated memory region will be put into the 
                    <code>leaked_allocations</code>
                    &nbsp;array. A 
                    <code>Warning</code>
                    -level log message will be sent as well.
				</p>
			</li>
			<li>
				<p>
                    The 
                    <code>leaked_allocations</code>
                    &nbsp;array is managed by the 
                    <code>context</code>
                    &nbsp;allocator if no 
                    <code>backup_allocator</code>
                    &nbsp;is specified in 
                    <code>scratch_init</code>
                    .
				</p>
			</li>
		</ul>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">@(require_results)
scratch_allocator :: proc(allocator: ^Scratch) -&gt; Allocator {
Â  Â  return Allocator{
Â  Â  Â  Â  procedure = scratch_allocator_proc,
Â  Â  Â  Â  data = allocator,
Â  Â  }
}
</code></pre>
<h5
	id="resize" >
    Resize
</h5>
<ul>
	<li>
		<p>
            Allocations which are resized will be resized in-place if they were the last allocation. Otherwise, they are re-allocated to avoid overwriting previous allocations.
		</p>
	</li>
</ul>
<h3
	id="stack-allocator-lifo" >
    Stack Allocator (LIFO)
</h3>
<ul>
	<li>
		<p>
            The stack allocator is an allocator that allocates data in the backing buffer linearly, from start to end. Each subsequent allocation will get the next adjacent memory region.
		</p>
	</li>
	<li>
		<p>
			<em>
                Unlike arena allocator, the stack allocator saves allocation metadata and has a strict freeing order. Only the last allocated element can be freed. After the last allocated element is freed, the next previous allocated element becomes available for freeing.
			</em>
		</p>
	</li>
	<li>
		<p>
            The metadata is stored in the allocation headers, that are located before the start of each allocated memory region. Each header points to the start of the previous allocation header.
		</p>
	</li>
	<li>
		<p>
			<a
				href="https://www.gingerbill.org/article/2019/02/15/memory-allocation-strategies-003/" 
				class="external-link" 
				target="_blank" >
                Stack Allocator - Ginger Bill
			</a>
            .
		</p>
	</li>
	<li>
		<p>
            A stack-like allocator means that the allocator acts like a data structure following the last-in, first-out (LIFO) principle.
		</p>
	</li>
	<li>
		<p>
            This has nothing to do with the stack or the stack frame.
		</p>
	</li>
	<li>
		<p>
			<strong>
                Evolution of an Arena Allocator
			</strong>
		</p>
		<ul>
			<li>
				<p>
                    As with the arena allocator, an offset into the memory block will be stored and will be moved forwards on every allocation.
				</p>
			</li>
			<li>
				<p>
                    The difference is that the offset can also be moved backwards when memory is freed. With an arena, you could only free all the memory all at once.
				</p>
			</li>
		</ul>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Stack :: struct {
Â  Â  data: Â  Â  Â  Â []byte,
Â  Â  prev_offset: int,
Â  Â  curr_offset: int,
Â  Â  peak_used: Â  int,
}


Stack_Allocation_Header :: struct {
Â  Â  prev_offset: int,
Â  Â  padding: Â  Â  int,
}

@(require_results)
stack_allocator :: proc(stack: ^Stack) -&gt; Allocator {
Â  Â  return Allocator{
Â  Â  Â  Â  procedure = stack_allocator_proc,
Â  Â  Â  Â  data Â  Â  Â = stack,
Â  Â  }
}
</code></pre>
<h5
	id="header" >
    Header
</h5>
<ul>
	<li>
		<p>
            The offset of the previous allocation needs to be tracked. This is required in order to free memory on a 
			<em>
                per-allocation
			</em>
            &nbsp;basis.
		</p>
	</li>
	<li>
		<p>
            One approach is to store a 
			<em>
                header
			</em>
            &nbsp;which stores information about that allocation. This 
			<em>
                header
			</em>
            &nbsp;allows the allocator to know how far back it should move the offset to free that memory.
		</p>
		<ul>
			<li>
				<p>
                    The stack allocator is the first of many allocators that will use the concept of a 
					<em>
                        header
					</em>
                    &nbsp;for allocations.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            To allocate some memory from the stack allocator, as with the arena allocator, it is as simple as moving the offset forward while accounting for the header. In Big-O notation, the allocation has complexity of 
			<em>
				<strong>
                    O(1)
				</strong>
			</em>
            &nbsp;(constant).
		</p>
	</li>
	<li>
		<p>
            To free a block, the header stored before the block of memory can be read in order to move the offset backwards. In Big-O notation, freeing this memory has complexity of 
			<em>
				<strong>
                    O(1)
				</strong>
			</em>
            &nbsp;(constant).
		</p>
	</li>
	<li>
		<p>
			<strong>
                What's stored in the header
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    There are three main approaches:
				</p>
				<ul>
					<li>
						<p>
                            Store the padding from the previous offset
						</p>
					</li>
					<li>
						<p>
                            Store the previous offset
						</p>
					</li>
					<li>
						<p>
                            Store the size of the allocation
						</p>
					</li>
				</ul>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="implementation" >
    Implementation
</h5>
<ul>
	<li>
		<p>
            See the article 
			<a
				href="https://www.gingerbill.org/article/2019/02/15/memory-allocation-strategies-003/" 
				class="external-link" 
				target="_blank" >
                Stack Allocator - Ginger Bill
			</a>
            .
		</p>
	</li>
	<li>
		<p>
			<strong>
                Improvements
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    You can extend the stack allocator even further by having two different offsets: one that starts at the beginning and increments forwards, and another that starts at the end and increments backwards. This is called a double-ended stack and allows for the maximization of memory usage whilst keeping fragmentation extremely low (as long as the offsets never overlap).
				</p>
			</li>
		</ul>
	</li>
</ul>
<h4
	id="small-stack-allocator" >
    Small Stack Allocator
</h4>
<ul>
	<li>
		<p>
            The small stack allocator is just like a 
            <code>Stack</code>
            &nbsp;allocator, with the only difference being an extremely small header size.
		</p>
	</li>
	<li>
		<p>
            Unlike the stack allocator, the small stack allows out-of order freeing of memory, with the stipulation that all allocations made after the freed allocation will become invalidated upon following allocations as they will begin to overwrite the memory formerly used by the freed allocation.
		</p>
	</li>
	<li>
		<p>
            The memory is allocated in the backing buffer linearly, from start to end. Each subsequent allocation will get the next adjacent memory region.
		</p>
	</li>
	<li>
		<p>
            The metadata is stored in the allocation headers, that are located before the start of each allocated memory region. Each header contains the amount of padding bytes between that header and end of the previous allocation.
		</p>
	</li>
</ul>
<h3
	id="buddy-memory-allocation" >
    Buddy Memory Allocation
</h3>
<ul>
	<li>
		<p>
            The buddy allocator is a type of allocator that splits the backing buffer into multiple regions called 
			<em>
                buddy blocks
			</em>
            .
		</p>
	</li>
	<li>
		<p>
            Initially, the allocator only has one block with the size of the backing buffer.
		</p>
	</li>
	<li>
		<p>
            Upon each allocation, the allocator finds the smallest block that can fit the size of requested memory region, and splits the block according to the allocation size. If no block can be found, the contiguous free blocks are coalesced and the search is performed again.
		</p>
	</li>
	<li>
		<p>
			<a
				href="https://www.gingerbill.org/article/2021/12/02/memory-allocation-strategies-006/" 
				class="external-link" 
				target="_blank" >
                Buddy Memory Allocation - Ginger Bill
			</a>
            .
		</p>
	</li>
	<li>
		<p>
            The buddy allocator is a powerful allocator and a conceptually simple algorithm, but implementing it efficiently is a 
			<strong>
                lot harder
			</strong>
            &nbsp;than all of the previous allocators above.
		</p>
	</li>
	<li>
		<p>
            The 
			<em>
                Buddy Algorithm
			</em>
            &nbsp;assumes that the backing memory block is a power-of-two in bytes.
		</p>
	</li>
	<li>
		<p>
            When an allocation is requested, the allocator looks for a block whose size is at least the size of the requested allocation (similar to a free list).
		</p>
	</li>
	<li>
		<p>
            If the requested allocation size is less than half of the block, it is split into two (left and right), and the two resulting blocks are called â€œbuddies.â€
		</p>
	</li>
	<li>
		<p>
            If this requested allocation size is still less than half the size of the left buddy, the buddy block is recursively split until the resulting buddy is as small as possible to fit the requested allocation size.
		</p>
	</li>
	<li>
		<p>
            When a block is released, we can try to perform coalescence on buddies (contiguous neighboring blocks).
		</p>
	</li>
	<li>
		<p>
            Similar to free lists, there are specific conditions that must be met. Coalescence cannot be performed if a block has no (free) buddy, the block is still in use, or the buddy block is partially used.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Buddy_Block :: struct #align(align_of(uint)) {
Â  Â  size: Â  Â uint,
Â  Â  is_free: bool,
}

Buddy_Allocator :: struct {
Â  Â  head: Â  Â  Â ^Buddy_Block,
Â  Â  tail: Â  Â  Â ^Buddy_Block `fmt:"-"`,
Â  Â  alignment: uint,
}
</code></pre>
<h3
	id="pool-allocator" >
    Pool Allocator
</h3>
<ul>
	<li>
		<p>
			<a
				href="https://www.gingerbill.org/article/2019/02/16/memory-allocation-strategies-004/" 
				class="external-link" 
				target="_blank" >
                Pool Allocator - Ginger Bill
			</a>
            .
		</p>
	</li>
	<li>
		<p>
            A pool splits the supplied backing buffer into 
			<em>
                chunks
			</em>
            &nbsp;of equal size and keeps track of which of the chunks are free.
		</p>
		<ul>
			<li>
				<p>
                    When an allocation is requested, a free chunk is given.
				</p>
			</li>
			<li>
				<p>
                    When a chunk is freed, it adds that chunk back to the list of free chunks.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Pool allocators are extremely useful when you need to allocate chunks of memory of the same size that are created and destroyed dynamically, especially in a random order.
		</p>
	</li>
	<li>
		<p>
            Pools also have the benefit that arenas and stacks have in that they provide very little fragmentation and allocate/free in constant time 
			<em>
				<strong>
                    O(1)
				</strong>
			</em>
            .
		</p>
	</li>
	<li>
		<p>
            Pool allocators are usually used to allocate 
			<em>
                groups
			</em>
            &nbsp;of â€œthingsâ€ at once which share the same lifetime.
		</p>
		<ul>
			<li>
				<p>
                    An example could be within a game that creates and destroys entities in batches where each entity within a batch shares the same lifetime.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Free List
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    A 
					<a
						href="https://wikipedia.org/wiki/Free_list" 
						class="external-link" 
						target="_blank" >
                        free list
					</a>
                    &nbsp;is a data structure that internally stores a 
					<a
						href="https://wikipedia.org/wiki/Linked_list" 
						class="external-link" 
						target="_blank" >
                        linked list
					</a>
                    &nbsp;of the free slots/chunks within the memory buffer.
				</p>
			</li>
			<li>
				<p>
                    The nodes of the list are stored in-place, meaning there is no need for an additional data structure (e.g., array, list, etc.) to keep track of the free slots.
				</p>
			</li>
			<li>
				<p>
                    The data is 
					<em>
                        only
					</em>
                    &nbsp;stored 
					<em>
                        within
					</em>
                    &nbsp;the backing buffer of the pool allocator.
				</p>
			</li>
			<li>
				<p>
                    The general approach is to store a header at the beginning of the chunk (not before the chunk like with the stack allocator) which 
					<em>
                        points
					</em>
                    &nbsp;to the next available free chunk.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="implementation" >
    Implementation
</h5>
<ul>
	<li>
		<p>
			<a
				href="https://www.gingerbill.org/code/memory-allocation-strategies/part004.c" 
				class="external-link" 
				target="_blank" >
                Full implementation - Ginger Bill
			</a>
            .
		</p>
	</li>
</ul>
<h3
	id="general-purpose-free-list-based-allocator" >
    General Purpose: Free List Based Allocator
</h3>
<ul>
	<li>
		<p>
			<a
				href="https://www.gingerbill.org/article/2021/11/30/memory-allocation-strategies-005/" 
				class="external-link" 
				target="_blank" >
                Free List Based Allocator - Ginger Bill
			</a>
            .
		</p>
	</li>
	<li>
		<p>
            A free list is a general-purpose allocator which, compared to the other allocators we previously looked at, does not impose any restrictions.
		</p>
	</li>
	<li>
		<p>
            It allows allocations and deallocations to be out of order and of any size.
		</p>
	</li>
	<li>
		<p>
            Due to its nature, the allocatorâ€™s 
			<strong>
                performance is not as good
			</strong>
            &nbsp;as the others previously discussed in this series.
		</p>
	</li>
</ul>
<h5
	id="implementation" >
    Implementation
</h5>
<ul>
	<li>
		<p>
            There are two common approaches to implementing a free list allocator:
		</p>
		<ul>
			<li>
				<p>
                    Using a 
					<a
						href="https://wikipedia.org/wiki/Linked_list" 
						class="external-link" 
						target="_blank" >
                        linked list
					</a>
				</p>
			</li>
			<li>
				<p>
                    Using a 
					<a
						href="https://wikipedia.org/wiki/Red%E2%80%93black_tree" 
						class="external-link" 
						target="_blank" >
                        red-black tree
					</a>
                    .
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            See the article for the implementations.
		</p>
	</li>
</ul>
<h3
	id="general-purpose-heap-allocator" >
    General Purpose: Heap Allocator
</h3>
<ul>
	<li>
		<p>
            Heap Allocators are a high level construct, and a specific kind of allocator.
		</p>
	</li>
	<li>
		<p>
            Odin just generalizes the concept of an allocator.
		</p>
	</li>
	<li>
		<p>
            A heap in general is a data structure and in the context of allocators it is a &quot;general purpose allocator&quot;. Most common heap allocators are built on top of allocating virtual memory directly. The point of the &quot;general purpose&quot; aspect means you can allocate &quot;things&quot; of varying size, alignment, and free them at arbitrary times (i.e. the lifetimes of each allocation is out of order). And to do this, they require storing some sort of metadata about the size of the allocation, and where the free allocations are (called a free list). More complicated algorithms do more things to be more efficient.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">@(require_results)
heap_allocator :: proc() -&gt; Allocator {
Â  Â  return Allocator{
Â  Â  Â  Â  procedure = heap_allocator_proc,
Â  Â  Â  Â  data = nil,
Â  Â  }
}
</code></pre>
<h5
	id="in-codeos2-code" >
    In 
    <code>os2</code>
</h5>
<ul>
	<li>
		<p>
            The 
            <code>heap_allocator</code>
            &nbsp;is redefined internally if using Windows.
		</p>
	</li>
	<li>
		<p>
            Barinzaya:
		</p>
		<ul>
			<li>
				<p>
                    I'd guess probably because 
					<a
						href="https://github.com/odin-lang/Odin/pull/4749" 
						class="external-link" 
						target="_blank" >
                        <code>runtime.heap_allocator</code>
                        &nbsp;may eventually become an Odin-implemented heap allocator
					</a>
                    , and 
                    <code>os.heap_allocator</code>
                    &nbsp;is intended to specifically use the underlying OS allocator (which 
                    <code>runtime.heap_allocator</code>
                    &nbsp;currently also is).
				</p>
			</li>
			<li>
				<p>
                    This is done so 
                    <code>os.heap_allocator</code>
                    &nbsp;is 
					<em>
                        the OS's heap allocator
					</em>
                    .
				</p>
			</li>
			<li>
				<p>
                    As for 
                    <code>os2</code>
                    &nbsp;using its own allocators instead of 
                    <code>context</code>
                    &nbsp;ones... OS Stuff is Differentâ„¢ is the usual reply I've seen.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="using-codeheap_allocator-code" >
    Using 
    <code>heap_allocator()</code>
</h5>
<ul>
	<li>
		<p>
            The procedure uses 
            <code>data = nil</code>
            , while the 
            <code>heap_allocator_proc</code>
            &nbsp;doesn't use the 
            <code>allocator_data: rawptr</code>
            . This means that every call to 
            <code>heap_allocator</code>
            &nbsp;uses the same backing region from the OS heap allocator implemented.
		</p>
	</li>
	<li>
		<p>
            Example:
		</p>
<pre><code class="language-odin" data-lang="odin">a := runtime.heap_allocator()
b := runtime.heap_allocator()
</code></pre>
		<ul>
			<li>
				<p>
                    <code>a</code>
                    &nbsp;and 
                    <code>b</code>
                    &nbsp;are the same. There's no new 
                    <code>mmap</code>
                    , or etc, being made.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="is-thread-safe" >
    Is thread-safe?
</h5>
<ul>
	<li>
		<p>
            Yes.
		</p>
	</li>
	<li>
		<p>
            It's just uses what the OS provides. which generally are, yes. And when we have our own malloc implementation, it'll be thread-safe too.
		</p>
		<ul>
			<li>
				<p>
                    The current PR for it: 
					<a
						href="https://github.com/odin-lang/Odin/pull/4749" 
						class="external-link" 
						target="_blank" >
                        https://github.com/odin-lang/Odin/pull/4749
					</a>
                    .
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            ChatGPT: &quot;The C standard library implementations of 
            <code>malloc</code>
            , 
            <code>calloc</code>
            , 
            <code>realloc</code>
            , and 
            <code>free</code>
            &nbsp;provided by all mainstream libc variants (glibc, musl, BSD libc, Windows CRT, etc.) are thread-safe. They use internal locking or per-thread arenas to avoid corruption.&quot;
		</p>
	</li>
</ul>
<h5
	id="allocator-proc" >
    Allocator Proc
</h5>
<pre><code class="language-odin" data-lang="odin">heap_allocator_proc :: proc(allocator_data: rawptr, mode: Allocator_Mode,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  size, alignment: int,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  old_memory: rawptr, old_size: int, loc := #caller_location) -&gt; ([]byte, Allocator_Error) {
Â  Â  // NOTE(tetra, 2020-01-14): The heap doesn't respect alignment.
Â  Â  // Instead, we overallocate by `alignment + size_of(rawptr) - 1`, and insert
Â  Â  // padding. We also store the original pointer returned by heap_alloc right before
Â  Â  // the pointer we return to the user.
Â  Â  aligned_alloc :: proc(size, alignment: int, old_ptr: rawptr, old_size: int, zero_memory := true) -&gt; ([]byte, Allocator_Error) {
Â  Â  Â  Â  // Not(flysand): We need to reserve enough space for alignment, which
Â  Â  Â  Â  // includes the user data itself, the space to store the pointer to
Â  Â  Â  Â  // allocation start, as well as the padding required to align both
Â  Â  Â  Â  // the user data and the pointer.
Â  Â  Â  Â  a := max(alignment, align_of(rawptr))
Â  Â  Â  Â  space := a-1 + size_of(rawptr) + size
Â  Â  Â  Â  allocated_mem: rawptr
Â  Â  Â  Â  force_copy := old_ptr != nil && alignment &gt; align_of(rawptr)
Â  Â  Â  Â  if old_ptr != nil && !force_copy {
Â  Â  Â  Â  Â  Â  original_old_ptr := ([^]rawptr)(old_ptr)[-1]
Â  Â  Â  Â  Â  Â  allocated_mem = heap_resize(original_old_ptr, space)
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  allocated_mem = heap_alloc(space, zero_memory)
Â  Â  Â  Â  }
Â  Â  Â  Â  aligned_mem := rawptr(([^]u8)(allocated_mem)[size_of(rawptr):])
Â  Â  Â  Â  ptr := uintptr(aligned_mem)
Â  Â  Â  Â  aligned_ptr := (ptr + uintptr(a)-1) & ~(uintptr(a)-1)
Â  Â  Â  Â  if allocated_mem == nil {
Â  Â  Â  Â  Â  Â  aligned_free(old_ptr)
Â  Â  Â  Â  Â  Â  aligned_free(allocated_mem)
Â  Â  Â  Â  Â  Â  return nil, .Out_Of_Memory
Â  Â  Â  Â  }
Â  Â  Â  Â  aligned_mem = rawptr(aligned_ptr)
Â  Â  Â  Â  ([^]rawptr)(aligned_mem)[-1] = allocated_mem
Â  Â  Â  Â  if force_copy {
Â  Â  Â  Â  Â  Â  mem_copy_non_overlapping(aligned_mem, old_ptr, min(old_size, size))
Â  Â  Â  Â  Â  Â  aligned_free(old_ptr)
Â  Â  Â  Â  }
Â  Â  Â  Â  return byte_slice(aligned_mem, size), nil
Â  Â  }
Â  Â  
Â  Â  aligned_free :: proc(p: rawptr) {
Â  Â  Â  Â  if p != nil {
Â  Â  Â  Â  Â  Â  heap_free(([^]rawptr)(p)[-1])
Â  Â  Â  Â  }
Â  Â  }
Â  Â  
Â  Â  aligned_resize :: proc(p: rawptr, old_size: int, new_size: int, new_alignment: int, zero_memory := true) -&gt; (new_memory: []byte, err: Allocator_Error) {
Â  Â  Â  Â  if p == nil {
Â  Â  Â  Â  Â  Â  return aligned_alloc(new_size, new_alignment, nil, old_size, zero_memory)
Â  Â  Â  Â  }
Â  Â  Â  Â  new_memory = aligned_alloc(new_size, new_alignment, p, old_size, zero_memory) or_return
Â  Â  Â  Â  when ODIN_OS != .Windows {
Â  Â  Â  Â  Â  Â  // NOTE: heap_resize does not zero the new memory, so we do it
Â  Â  Â  Â  Â  Â  if zero_memory && new_size &gt; old_size {
Â  Â  Â  Â  Â  Â  Â  Â  new_region := raw_data(new_memory[old_size:])
Â  Â  Â  Â  Â  Â  Â  Â  conditional_mem_zero(new_region, new_size - old_size)
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  return
Â  Â  }
Â  Â  
Â  Â  switch mode {
Â  Â  case .Alloc, .Alloc_Non_Zeroed:
Â  Â  Â  Â  return aligned_alloc(size, alignment, nil, 0, mode == .Alloc)
Â  Â  case .Free:
Â  Â  Â  Â  aligned_free(old_memory)
Â  Â  case .Free_All:
Â  Â  Â  Â  return nil, .Mode_Not_Implemented
Â  Â  case .Resize, .Resize_Non_Zeroed:
Â  Â  Â  Â  return aligned_resize(old_memory, old_size, size, alignment, mode == .Resize)
Â  Â  case .Query_Features:
Â  Â  Â  Â  set := (^Allocator_Mode_Set)(old_memory)
Â  Â  Â  Â  if set != nil {
Â  Â  Â  Â  Â  Â  set^ = {.Alloc, .Alloc_Non_Zeroed, .Free, .Resize, .Resize_Non_Zeroed, .Query_Features}
Â  Â  Â  Â  }
Â  Â  Â  Â  return nil, nil
Â  Â  case .Query_Info:
Â  Â  Â  Â  return nil, .Mode_Not_Implemented
Â  Â  }
Â  Â  return nil, nil
}
</code></pre>
<h5
	id="alloc" >
    Alloc
</h5>
<pre><code class="language-odin" data-lang="odin">heap_alloc :: proc "contextless" (size: int, zero_memory := true) -&gt; rawptr {
Â  Â  return _heap_alloc(size, zero_memory)
}
</code></pre>
<ul>
	<li>
		<p>
            Linux:
		</p>
<pre><code class="language-odin" data-lang="odin">@(default_calling_convention="c")
foreign libc {
Â  Â  @(link_name="malloc") Â  _unix_malloc Â  :: proc(size: int) -&gt; rawptr ---
Â  Â  @(link_name="calloc") Â  _unix_calloc Â  :: proc(num, size: int) -&gt; rawptr ---
}

_heap_alloc :: proc "contextless" (size: int, zero_memory := true) -&gt; rawptr {
Â  Â  if size &lt;= 0 {
Â  Â  Â  Â  return nil
Â  Â  }
Â  Â  if zero_memory {
Â  Â  Â  Â  return _unix_calloc(1, size)
Â  Â  } else {
Â  Â  Â  Â  return _unix_malloc(size)
Â  Â  }
}
</code></pre>
		<ul>
			<li>
				<p>
                    Uses the C library allocator (
                    <code>malloc</code>
                    , 
                    <code>calloc</code>
                    ) layered over 
                    <code>brk</code>
                    &nbsp;or 
                    <code>mmap</code>
                    &nbsp;system calls.
				</p>
			</li>
			<li>
				<p>
                    The kernel itself does not expose a &quot;heap&quot; API to user space.
				</p>
			</li>
			<li>
				<p>
                    Each C library (glibc, musl, jemalloc, etc.) implements its own allocator strategy.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Windows:
		</p>
<pre><code class="language-odin" data-lang="odin">_heap_alloc :: proc "contextless" (size: int, zero_memory := true) -&gt; rawptr {
Â  Â  HEAP_ZERO_MEMORY :: 0x00000008
Â  Â  ptr := HeapAlloc(GetProcessHeap(), HEAP_ZERO_MEMORY if zero_memory else 0, uint(size))
Â  Â  // NOTE(lucas): asan not guarunteed to unpoison win32 heap out of the box, do it ourselves
Â  Â  sanitizer.address_unpoison(ptr, size)
Â  Â  return ptr
}
</code></pre>
		<ul>
			<li>
				<p>
                    The heap system (
                    <code>HeapAlloc</code>
                    , 
                    <code>HeapFree</code>
                    , etc.) is part of the 
					<strong>
                        Win32 API
					</strong>
                    , built over the NT kernelâ€™s virtual memory manager.
				</p>
			</li>
			<li>
				<p>
                    Each process has one or more 
					<strong>
                        heaps
					</strong>
                    &nbsp;managed by the kernel.
				</p>
			</li>
			<li>
				<p>
                    <code>HeapAlloc(GetProcessHeap(), ...)</code>
                    &nbsp;allocates from the process heap directly, with flags controlling behavior (e.g., 
                    <code>HEAP_ZERO_MEMORY</code>
                    &nbsp;for zeroing).
				</p>
			</li>
			<li>
				<p>
                    This unifies allocation across the system and avoids relying on C runtime internals, which can differ between MSVC, MinGW, etc.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="resize" >
    Resize
</h5>
<pre><code class="language-odin" data-lang="odin">heap_resize :: proc "contextless" (ptr: rawptr, new_size: int) -&gt; rawptr {
Â  Â  return _heap_resize(ptr, new_size)
}
</code></pre>
<ul>
	<li>
		<p>
            Linux:
		</p>
<pre><code class="language-odin" data-lang="odin">@(default_calling_convention="c")
foreign libc {
Â  Â  @(link_name="realloc") Â _unix_realloc Â :: proc(ptr: rawptr, size: int) -&gt; rawptr ---
}

_heap_resize :: proc "contextless" (ptr: rawptr, new_size: int) -&gt; rawptr {
Â  Â  // NOTE: _unix_realloc doesn't guarantee new memory will be zeroed on
Â  Â  // POSIX platforms. Ensure your caller takes this into account.
Â  Â  return _unix_realloc(ptr, new_size)
}
</code></pre>
	</li>
	<li>
		<p>
            Windows:
		</p>
<pre><code class="language-odin" data-lang="odin">_heap_resize :: proc "contextless" (ptr: rawptr, new_size: int) -&gt; rawptr {
Â  Â  if new_size == 0 {
Â  Â  Â  Â  _heap_free(ptr)
Â  Â  Â  Â  return nil
Â  Â  }
Â  Â  if ptr == nil {
Â  Â  Â  Â  return _heap_alloc(new_size)
Â  Â  }
Â  Â  HEAP_ZERO_MEMORY :: 0x00000008
Â  Â  new_ptr := HeapReAlloc(GetProcessHeap(), HEAP_ZERO_MEMORY, ptr, uint(new_size))
Â  Â  // NOTE(lucas): asan not guarunteed to unpoison win32 heap out of the box, do it ourselves
Â  Â  sanitizer.address_unpoison(new_ptr, new_size)
Â  Â  return new_ptr
}
</code></pre>
	</li>
</ul>
<h5
	id="free" >
    Free
</h5>
<pre><code class="language-odin" data-lang="odin">heap_free :: proc "contextless" (ptr: rawptr) {
Â  Â  _heap_free(ptr)
}
</code></pre>
<ul>
	<li>
		<p>
            Linux:
		</p>
<pre><code class="language-odin" data-lang="odin">@(default_calling_convention="c")
foreign libc {
Â  Â  @(link_name="free") Â  Â  _unix_free Â  Â  :: proc(ptr: rawptr) ---
}

_heap_free :: proc "contextless" (ptr: rawptr) {
Â  Â  _unix_free(ptr)
}
</code></pre>
	</li>
	<li>
		<p>
            Windows:
		</p>
<pre><code class="language-odin" data-lang="odin">_heap_free :: proc "contextless" (ptr: rawptr) {
Â  Â  if ptr == nil {
Â  Â  Â  Â  return
Â  Â  }
Â  Â  HeapFree(GetProcessHeap(), 0, ptr)
}
</code></pre>
	</li>
</ul>
<h3
	id="compact-allocator" >
    Compact Allocator
</h3>
<ul>
	<li>
		<p>
            An allocator that keeps track of allocation sizes and passes it along to resizes.
		</p>
	</li>
	<li>
		<p>
            This is useful if you are using a library that needs an equivalent of 
            <code>realloc</code>
            &nbsp;but want to use the Odin allocator interface.
		</p>
	</li>
	<li>
		<p>
            You want to wrap your allocator into this one if you are trying to use any allocator that relies on the old size to work.
		</p>
	</li>
	<li>
		<p>
            The overhead of this allocator is an extra 
            <code>max(alignment, size_of(Header))</code>
            &nbsp;bytes allocated for each allocation, these bytes are used to store the size and alignment.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Compat_Allocator :: struct {
Â  Â  parent: Allocator,
}
</code></pre>
<h5
	id="allocator-procedure" >
    Allocator Procedure
</h5>
<pre><code class="language-odin" data-lang="odin">compat_allocator_proc :: proc(allocator_data: rawptr, mode: Allocator_Mode,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â size, alignment: int,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â old_memory: rawptr, old_size: int,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â location := #caller_location) -&gt; (data: []byte, err: Allocator_Error) {
Â  Â  Header :: struct {
Â  Â  Â  Â  size: Â  Â  Â int,
Â  Â  Â  Â  alignment: int,
Â  Â  }
Â  Â  @(no_sanitize_address)
Â  Â  get_unpoisoned_header :: #force_inline proc(ptr: rawptr) -&gt; Header {
Â  Â  Â  Â  header := ([^]Header)(ptr)[-1]
Â  Â  Â  Â  // a Â  Â  Â := max(header.alignment, size_of(Header))
Â  Â  Â  Â  // sanitizer.address_unpoison(rawptr(uintptr(ptr)-uintptr(a)), a)
Â  Â  Â  Â  return header
Â  Â  }
Â  Â  rra := (^Compat_Allocator)(allocator_data)
Â  Â  switch mode {
Â  Â  case .Alloc, .Alloc_Non_Zeroed:
Â  Â  Â  Â  a Â  Â  Â  Â := max(alignment, size_of(Header))
Â  Â  Â  Â  req_size := size + a
Â  Â  Â  Â  assert(req_size &gt;= 0, "overflow")
Â  Â  Â  Â  allocation := rra.parent.procedure(rra.parent.data, mode, req_size, alignment, old_memory, old_size, location) or_return
Â  Â  Â  Â  #no_bounds_check data = allocation[a:]
Â  Â  Â  Â  ([^]Header)(raw_data(data))[-1] = {
Â  Â  Â  Â  Â  Â  size Â  Â  Â = size,
Â  Â  Â  Â  Â  Â  alignment = alignment,
Â  Â  Â  Â  }
Â  Â  Â  Â  // sanitizer.address_poison(raw_data(allocation), a)
Â  Â  Â  Â  return
Â  Â  case .Free:
Â  Â  Â  Â  header Â  Â := get_unpoisoned_header(old_memory)
Â  Â  Â  Â  a Â  Â  Â  Â  := max(header.alignment, size_of(Header))
Â  Â  Â  Â  orig_ptr Â := rawptr(uintptr(old_memory)-uintptr(a))
Â  Â  Â  Â  orig_size := header.size + a
Â  Â  Â  Â  return rra.parent.procedure(rra.parent.data, mode, orig_size, header.alignment, orig_ptr, orig_size, location)
Â  Â  case .Resize, .Resize_Non_Zeroed:
Â  Â  Â  Â  header Â  Â := get_unpoisoned_header(old_memory)
Â  Â  Â  Â  orig_a Â  Â := max(header.alignment, size_of(Header))
Â  Â  Â  Â  orig_ptr Â := rawptr(uintptr(old_memory)-uintptr(orig_a))
Â  Â  Â  Â  orig_size := header.size + orig_a
Â  Â  Â  Â  new_alignment := max(header.alignment, alignment)
Â  Â  Â  Â  a Â  Â  Â  Â := max(new_alignment, size_of(header))
Â  Â  Â  Â  req_size := size + a
Â  Â  Â  Â  assert(size &gt;= 0, "overflow")
Â  Â  Â  Â  allocation := rra.parent.procedure(rra.parent.data, mode, req_size, new_alignment, orig_ptr, orig_size, location) or_return
Â  Â  Â  Â  #no_bounds_check data = allocation[a:]
Â  Â  Â  Â  ([^]Header)(raw_data(data))[-1] = {
Â  Â  Â  Â  Â  Â  size Â  Â  Â = size,
Â  Â  Â  Â  Â  Â  alignment = new_alignment,
Â  Â  Â  Â  }
Â  Â  Â  Â  // sanitizer.address_poison(raw_data(allocation), a)
Â  Â  Â  Â  return
Â  Â  case .Free_All:
Â  Â  Â  Â  return rra.parent.procedure(rra.parent.data, mode, size, alignment, old_memory, old_size, location)
Â  Â  case .Query_Info:
Â  Â  Â  Â  info := (^Allocator_Query_Info)(old_memory)
Â  Â  Â  Â  if info != nil && info.pointer != nil {
Â  Â  Â  Â  Â  Â  header := get_unpoisoned_header(info.pointer)
Â  Â  Â  Â  Â  Â  info.size Â  Â  Â = header.size
Â  Â  Â  Â  Â  Â  info.alignment = header.alignment
Â  Â  Â  Â  }
Â  Â  Â  Â  return
Â  Â  case .Query_Features:
Â  Â  Â  Â  data, err = rra.parent.procedure(rra.parent.data, mode, size, alignment, old_memory, old_size, location)
Â  Â  Â  Â  if err != nil {
Â  Â  Â  Â  Â  Â  set := (^Allocator_Mode_Set)(old_memory)
Â  Â  Â  Â  Â  Â  set^ += {.Query_Info}
Â  Â  Â  Â  }
Â  Â  Â  Â  return
Â  Â  case: unreachable()
Â  Â  }
}
</code></pre>
<h3
	id="mutex-allocator" >
    Mutex Allocator
</h3>
<ul>
	<li>
		<p>
            The mutex allocator is a wrapper for allocators that is used to serialize all allocator requests across multiple threads.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Mutex_Allocator :: struct {
Â  Â  backing: Allocator,
Â  Â  mutex: Â  sync.Mutex,
}

@(require_results)
mutex_allocator :: proc(m: ^Mutex_Allocator) -&gt; Allocator {
Â  Â  return Allocator{
Â  Â  Â  Â  procedure = mutex_allocator_proc,
Â  Â  Â  Â  data = m,
Â  Â  }
}
</code></pre>
<h5
	id="allocator-procedure" >
    Allocator Procedure
</h5>
<pre><code class="language-odin" data-lang="odin">mutex_allocator_proc :: proc(
Â  Â  allocator_data: rawptr,
Â  Â  mode: Allocator_Mode,
Â  Â  size: int,
Â  Â  alignment: int,
Â  Â  old_memory: rawptr,
Â  Â  old_size: int,
Â  Â  loc := #caller_location,
) -&gt; (result: []byte, err: Allocator_Error) {
Â  Â  m := (^Mutex_Allocator)(allocator_data)
Â  Â  sync.mutex_guard(&m.mutex)
Â  Â  return m.backing.procedure(m.backing.data, mode, size, alignment, old_memory, old_size, loc)
}
</code></pre>
<h3
	id="rollback-stack-allocator" >
    Rollback Stack Allocator
</h3>
<ul>
	<li>
		<p>
            The Rollback Stack Allocator was designed for the test runner to be fast, able to grow, and respect the Tracking Allocator's requirement for individual frees. It is not overly concerned with fragmentation, however.
		</p>
	</li>
	<li>
		<p>
            It has support for expansion when configured with a block allocator and limited support for out-of-order frees.
		</p>
	</li>
	<li>
		<p>
            Allocation has constant-time best and usual case performance. At worst, it is linear according to the number of memory blocks.
		</p>
	</li>
	<li>
		<p>
            Allocation follows a first-fit strategy when there are multiple memory blocks.
		</p>
	</li>
	<li>
		<p>
            Freeing has constant-time best and usual case performance. At worst, it is linear according to the number of memory blocks and number of freed items preceding the last item in a block.
		</p>
	</li>
	<li>
		<p>
            Resizing has constant-time performance, if it's the last item in a block, or the new size is smaller. Naturally, this becomes linear-time if there are multiple blocks to search for the pointer's owning block. Otherwise, the allocator defaults to a combined alloc &amp; free operation internally.
		</p>
	</li>
	<li>
		<p>
            Out-of-order freeing is accomplished by collapsing a run of freed items from the last allocation backwards.
		</p>
	</li>
	<li>
		<p>
            Each allocation has an overhead of 8 bytes and any extra bytes to satisfy the requested alignment.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Rollback_Stack_Block :: struct {
Â  Â  next_block: ^Rollback_Stack_Block,
Â  Â  last_alloc: rawptr,
Â  Â  offset: uintptr,
Â  Â  buffer: []byte,
}

Rollback_Stack :: struct {
Â  Â  head: ^Rollback_Stack_Block,
Â  Â  block_size: int,
Â  Â  block_allocator: Allocator,
}
</code></pre>
<h3
	id="wasm-allocator" >
    WASM Allocator
</h3>
<pre><code class="language-odin" data-lang="odin">WASM_Allocator :: struct {
Â  Â  // The minimum alignment of allocations.
Â  Â  alignment: uint,
Â  Â  
Â  Â  // A region that contains as payload a single forward linked list of pointers to
Â  Â  // root regions of each disjoint region blocks.
Â  Â  list_of_all_regions: ^Root_Region,
Â  Â  
Â  Â  // For each of the buckets, maintain a linked list head node. The head node for each
Â  Â  // free region is a sentinel node that does not actually represent any free space, but
Â  Â  // the sentinel is used to avoid awkward testing against (if node == freeRegionHeadNode)
Â  Â  // when adding and removing elements from the linked list, i.e. we are guaranteed that
Â  Â  // the sentinel node is always fixed and there, and the actual free region list elements
Â  Â  // start at free_region_buckets[i].next each.
Â  Â  free_region_buckets: [NUM_FREE_BUCKETS]Region,
Â  Â  
Â  Â  // A bitmask that tracks the population status for each of the 64 distinct memory regions:
Â  Â  // a zero at bit position i means that the free list bucket i is empty. This bitmask is
Â  Â  // used to avoid redundant scanning of the 64 different free region buckets: instead by
Â  Â  // looking at the bitmask we can find in constant time an index to a free region bucket
Â  Â  // that contains free memory of desired size.
Â  Â  free_region_buckets_used: BUCKET_BITMASK_T,
Â  Â  
Â  Â  // Because wasm memory can only be allocated in pages of 64k at a time, we keep any
Â  Â  // spilled/unused bytes that are left from the allocated pages here, first using this
Â  Â  // when bytes are needed.
Â  Â  spill: []byte,
Â  Â  
Â  Â  // Mutex for thread safety, only used if the target feature "atomics" is enabled.
Â  Â  mu: Mutex_State,
}
</code></pre>
<h3
	id="tracking-allocator" >
    Tracking Allocator
</h3>
<ul>
	<li>
		<p>
            The tracking allocator is an allocator wrapper that tracks memory allocations.
		</p>
	</li>
	<li>
		<p>
            This allocator stores all the allocations in a map.
		</p>
	</li>
	<li>
		<p>
            Whenever a pointer that's not inside of the map is freed, the 
            <code>bad_free_array</code>
            &nbsp;entry is added.
		</p>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">Tracking_Allocator :: struct {
Â  Â  backing: Allocator,
Â  Â  allocation_map: map[rawptr]Tracking_Allocator_Entry,
Â  Â  bad_free_callback: Tracking_Allocator_Bad_Free_Callback,
Â  Â  bad_free_array: [dynamic]Tracking_Allocator_Bad_Free_Entry,
Â  Â  mutex: sync.Mutex,
Â  Â  clear_on_free_all: bool,
Â  Â  total_memory_allocated: i64,
Â  Â  total_allocation_count: i64,
Â  Â  total_memory_freed: i64,
Â  Â  total_free_count: i64,
Â  Â  peak_memory_allocated: i64,
Â  Â  current_memory_allocated: i64,
}
</code></pre>
<h5
	id="demo" >
    Demo
</h5>
<ul>
	<li>
		<p>
			<a
				href="https://gist.github.com/kallixtus-git/b9e7c4ee856842e560c3eca0d0aed014" 
				class="external-link" 
				target="_blank" >
                Demo of Tracking Allocators
			</a>
            .
		</p>
	</li>
	<li>
		<p>
			<a
				href="https://youtu.be/jkJlpPyBdzk?si=6hBBATkB8eOoZsmH&t=1109" 
				class="external-link" 
				target="_blank" >
                Using the Tracking Allocator to detect memory leaks and double free {18:29 -&gt; 30:40}
			</a>
            .
		</p>
		<ul>
			<li>
				<p>
                    Very interesting.
				</p>
			</li>
			<li>
				<p>
                    The example includes RayLib.
				</p>
			</li>
		</ul>
	</li>
</ul>
<pre><code class="language-odin" data-lang="odin">package foo

import "core:mem"
import "core:fmt"

main :: proc() {
&nbsp;&nbsp;&nbsp;&nbsp;track: mem.Tracking_Allocator
&nbsp;&nbsp;&nbsp;&nbsp;mem.tracking_allocator_init(&track, context.allocator)
&nbsp;&nbsp;&nbsp;&nbsp;defer mem.tracking_allocator_destroy(&track)
&nbsp;&nbsp;&nbsp;&nbsp;context.allocator = mem.tracking_allocator(&track)
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;do_stuff()
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;for _, leak in track.allocation_map {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fmt.printf("%v leaked %m\n", leak.location, leak.size)
&nbsp;&nbsp;&nbsp;&nbsp;}
}
</code></pre>
<h5
	id="limitations" >
    Limitations
</h5>
<ul>
	<li>
		<p>
            &quot;I'm using the Track Allocator to know where I'm getting memory leaks, but it keeps saying the leak happened at 
            <code>C:/odin/core/strings/builder.odin(171:11) leaked 8 bytes</code>
            , but I have no idea what's the call stack, so I'm revisiting everything.&quot;
		</p>
		<ul>
			<li>
				<p>
                    &quot;It does attempt to log the location where the allocation was done, but it relies on the appropriate location being passed through. Unfortunately, that's 
					<a
						href="https://github.com/odin-lang/Odin/blob/4ec03a2d9b1c88a657829af7dc193fcb73d419bb/core/strings/builder.odin#L167" 
						class="external-link" 
						target="_blank" >
                        not always possible
					</a>
                    , e.g., the 
                    <code>io.Stream</code>
                    &nbsp;interface doesn't pass a location so when using a 
                    <code>strings.Builder</code>
                    &nbsp;as an 
                    <code>io.Stream</code>
                    &nbsp;(or anything else that 
                    <code>Stream</code>
                    s to dynamic memory), it can't easily track where it originated in 
					<em>
                        your
					</em>
                    &nbsp;code
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Virtual Arenas
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    <code>virtual.Arena</code>
                    &nbsp;doesn't use an 
                    <code>Allocator</code>
                    &nbsp;for its backing memory; it makes direct calls to the OS's virtual memory interface. So a 
                    <code>Tracking_Allocator</code>
                    &nbsp;can't be used to back it.
				</p>
			</li>
			<li>
				<p>
                    You can use a 
                    <code>Tracking_Allocator</code>
                    &nbsp;that 
					<em>
                        wraps
					</em>
                    &nbsp;the 
                    <code>Arena</code>
                    , and the 
                    <code>Tracking_Allocator</code>
                    &nbsp;can interpret 
                    <code>free_all</code>
                    &nbsp;on it correctly (you'd have to 
                    <code>free_all</code>
                    &nbsp;before you 
                    <code>destroy</code>
                    &nbsp;the arena, otherwise the tracking allocator will see it as leaking), but personally I don't see the value of using a tracking allocator on allocations made from an arena (regardless of which one).
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="allocator-procedure" >
    Allocator Procedure
</h5>
<pre><code class="language-odin" data-lang="odin">@(no_sanitize_address)
tracking_allocator_proc :: proc(
Â  Â  allocator_data: rawptr,
Â  Â  mode: Allocator_Mode,
Â  Â  size, alignment: int,
Â  Â  old_memory: rawptr,
Â  Â  old_size: int,
Â  Â  loc := #caller_location,
) -&gt; (result: []byte, err: Allocator_Error) {
Â  Â  @(no_sanitize_address)
Â  Â  track_alloc :: proc(data: ^Tracking_Allocator, entry: ^Tracking_Allocator_Entry) {
Â  Â  Â  Â  data.total_memory_allocated += i64(entry.size)
Â  Â  Â  Â  data.total_allocation_count += 1
Â  Â  Â  Â  data.current_memory_allocated += i64(entry.size)
Â  Â  Â  Â  if data.current_memory_allocated &gt; data.peak_memory_allocated {
Â  Â  Â  Â  Â  Â  data.peak_memory_allocated = data.current_memory_allocated
Â  Â  Â  Â  }
Â  Â  }
Â  Â  @(no_sanitize_address)
Â  Â  track_free :: proc(data: ^Tracking_Allocator, entry: ^Tracking_Allocator_Entry) {
Â  Â  Â  Â  data.total_memory_freed += i64(entry.size)
Â  Â  Â  Â  data.total_free_count += 1
Â  Â  Â  Â  data.current_memory_allocated -= i64(entry.size)
Â  Â  }
Â  Â  data := (^Tracking_Allocator)(allocator_data)
Â  Â  sync.mutex_guard(&data.mutex)
Â  Â  if mode == .Query_Info {
Â  Â  Â  Â  info := (^Allocator_Query_Info)(old_memory)
Â  Â  Â  Â  if info != nil && info.pointer != nil {
Â  Â  Â  Â  Â  Â  if entry, ok := data.allocation_map[info.pointer]; ok {
Â  Â  Â  Â  Â  Â  Â  Â  info.size = entry.size
Â  Â  Â  Â  Â  Â  Â  Â  info.alignment = entry.alignment
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  info.pointer = nil
Â  Â  Â  Â  }
Â  Â  Â  Â  return
Â  Â  }
Â  Â  if mode == .Free && old_memory != nil && old_memory not_in data.allocation_map {
Â  Â  Â  Â  if data.bad_free_callback != nil {
Â  Â  Â  Â  Â  Â  data.bad_free_callback(data, old_memory, loc)
Â  Â  Â  Â  }
Â  Â  } else {
Â  Â  Â  Â  result = data.backing.procedure(data.backing.data, mode, size, alignment, old_memory, old_size, loc) or_return
Â  Â  }
Â  Â  result_ptr := raw_data(result)
Â  Â  if data.allocation_map.allocator.procedure == nil {
Â  Â  Â  Â  data.allocation_map.allocator = context.allocator
Â  Â  }
Â  Â  switch mode {
Â  Â  case .Alloc, .Alloc_Non_Zeroed:
Â  Â  Â  Â  data.allocation_map[result_ptr] = Tracking_Allocator_Entry{
Â  Â  Â  Â  Â  Â  memory = result_ptr,
Â  Â  Â  Â  Â  Â  size = size,
Â  Â  Â  Â  Â  Â  mode = mode,
Â  Â  Â  Â  Â  Â  alignment = alignment,
Â  Â  Â  Â  Â  Â  err = err,
Â  Â  Â  Â  Â  Â  location = loc,
Â  Â  Â  Â  }
Â  Â  Â  Â  track_alloc(data, &data.allocation_map[result_ptr])
Â  Â  case .Free:
Â  Â  Â  Â  if old_memory != nil && old_memory in data.allocation_map {
Â  Â  Â  Â  Â  Â  track_free(data, &data.allocation_map[old_memory])
Â  Â  Â  Â  }
Â  Â  Â  Â  delete_key(&data.allocation_map, old_memory)
Â  Â  case .Free_All:
Â  Â  Â  Â  if data.clear_on_free_all {
Â  Â  Â  Â  Â  Â  clear_map(&data.allocation_map)
Â  Â  Â  Â  Â  Â  data.current_memory_allocated = 0
Â  Â  Â  Â  }
Â  Â  case .Resize, .Resize_Non_Zeroed:
Â  Â  Â  Â  if old_memory != nil && old_memory in data.allocation_map {
Â  Â  Â  Â  Â  Â  track_free(data, &data.allocation_map[old_memory])
Â  Â  Â  Â  }
Â  Â  Â  Â  if old_memory != result_ptr {
Â  Â  Â  Â  Â  Â  delete_key(&data.allocation_map, old_memory)
Â  Â  Â  Â  }
Â  Â  Â  Â  data.allocation_map[result_ptr] = Tracking_Allocator_Entry{
Â  Â  Â  Â  Â  Â  memory = result_ptr,
Â  Â  Â  Â  Â  Â  size = size,
Â  Â  Â  Â  Â  Â  mode = mode,
Â  Â  Â  Â  Â  Â  alignment = alignment,
Â  Â  Â  Â  Â  Â  err = err,
Â  Â  Â  Â  Â  Â  location = loc,
Â  Â  Â  Â  }
Â  Â  Â  Â  track_alloc(data, &data.allocation_map[result_ptr])
Â  Â  case .Query_Features:
Â  Â  Â  Â  set := (^Allocator_Mode_Set)(old_memory)
Â  Â  Â  Â  if set != nil {
Â  Â  Â  Â  Â  Â  set^ = {.Alloc, .Alloc_Non_Zeroed, .Free, .Free_All, .Resize, .Query_Features, .Query_Info}
Â  Â  Â  Â  }
Â  Â  Â  Â  return nil, nil
Â  Â  case .Query_Info:
Â  Â  Â  Â  unreachable()
Â  Â  }
Â  Â  return
}
</code></pre>

					</div>
					<footer
						id="previous-next" >
					</footer>
				</article>
			</main>
			<footer
				id="central-footer" >
                ðŸ§‘â€ðŸ’» built by and copyright
				<a
					href="https://github.com/caioraphael1" 
					target="_blank" >
                    Caio Raphael
				</a>
                ðŸ“… 2025-10-21 .&nbsp;&nbsp;2026-01-21 ðŸš€
			</footer>
		</div>
		<script
			src="/static/studies.36380.js" >
		</script>
	</body>
</html>
