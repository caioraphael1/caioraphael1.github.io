<!doctype html>
<html
	lang="en" >
	<head>
		<title>
            Caio Raphael
		</title>
		<meta
			charset="utf-8" >
		<meta
			name="viewport" 
			content="width=device-width, initial-scale=1" >
		<meta
			name="description" 
			content="Senior Game Developer, Engine Developer, Low-Level Network, Low-Level Systems" >
		<meta
			name="author" 
			content="Caio Raphael" >
		<meta
			name="theme-color" 
			content="#ffffff" 
			media="(prefers-color-scheme: light)" >
		<meta
			name="theme-color" 
			content="#101010" 
			media="(prefers-color-scheme: dark)" >
		<link
			rel="icon" 
			href="/assets/favicon.ico" >
		<link
			rel="icon" 
			href="/assets/favicon-16x16.png" 
			sizes="16x16" 
			type="image/png" >
		<link
			rel="icon" 
			href="/assets/favicon-32x32.png" 
			sizes="32x32" 
			type="image/png" >
		<script>
window.MathJax = {
                tex: {
                    inlineMath: [['$', '$']],
                    displayMath: [['$$', '$$']]
                }
                };
		</script>
		<script
			src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" >
		</script>
		<script
			type="module" >

                    import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.11.1/es/highlight.min.js';
                    import hljs_glsl from 'https://unpkg.com/@highlightjs/cdn-assets@11.11.1/es/languages/glsl.min.js';
                    import hljs_odin from 'https://unpkg.com/highlightjs-odinlang@1.4.0/dist/odin.es.min.js';
                    hljs.registerLanguage('odin', hljs_odin);
                    hljs.registerLanguage('glsl', hljs_glsl);
                    hljs.highlightAll();
                
		</script>
		<link
			rel="stylesheet" 
			href="/static/studies.css" >
	</head>
	<body>
		<aside
			id="left-sidebar" >
			<a
				href="/" 
				class="site-logo" >
                Caio Raphael
			</a>
			<nav>
				<details
					open="">
					<summary>
                        Graphics Programming
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Graphics Programming/Vulkan/Vulkan.html" >
                                Vulkan
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Graphics Programming/Render Engineering/Render Engineering.html" >
                                Render Engineering
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Graphics Programming/Graphics and Shaders/Graphics and Shaders.html" >
                                Graphics and Shaders
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Graphics Programming/GLSL/GLSL.html" >
                                GLSL
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="active" 
								href="/studies/Graphics Programming/GPU/GPU.html" >
                                GPU
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Graphics Programming/OpenGL/OpenGL.html" >
                                OpenGL
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Graphics Programming/Slang.html" >
                                Slang
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Design
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Design/Design - DOD e COP/Design - DOD e COP.html" >
                                Design - DOD e COP
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Design/Design - ECS/Design - ECS.html" >
                                Design - ECS
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Design/Design - Design Patterns/Design - Design Patterns.html" >
                                Design - Design Patterns
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Design/Design - Architecture Patterns.html" >
                                Design - Architecture Patterns
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Design/Design - Concepts and Terminology.html" >
                                Design - Concepts and Terminology
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Design/Design - Rules of thumb - Laws - Guidelines and Principles/Design - Rules of thumb - Laws - Guidelines and Principles.html" >
                                Design - Rules of thumb - Laws - Guidelines and Principles
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Design/Design - Paradigms.html" >
                                Design - Paradigms
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Design/Design - Production Methodologies/Design - Production Methodologies.html" >
                                Design - Production Methodologies
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Network
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Network/Network - Backend/Network - Backend.html" >
                                Network - Backend
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Network/Network - Low Level e Etc/Network - Low Level e Etc.html" >
                                Network - Low Level e Etc
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Network/Network - Netcode/Network - Netcode.html" >
                                Network - Netcode
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Network/Network - HTTP/Network - HTTP.html" >
                                Network - HTTP
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Network/Encryption.html" >
                                Encryption
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Network/SSH.html" >
                                SSH
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Network/Serialization - Encoding/Serialization - Encoding.html" >
                                Serialization - Encoding
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Things
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Build Systems - Compilation - Linking/Build Systems - Compilation - Linking.html" >
                                Build Systems - Compilation - Linking
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/CPU/CPU.html" >
                                CPU
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Code Editors/NeoVim - Setup/NeoVim - Setup.html" >
                                NeoVim - Setup
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Code Editors/NeoVim - Uso/NeoVim - Uso.html" >
                                NeoVim - Uso
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Code Editors/VSCode - VSCodium.html" >
                                VSCode - VSCodium
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Code Editors/Visual Studio/Visual Studio.html" >
                                Visual Studio
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Debuggers.html" >
                                Debuggers
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Dependencies.html" >
                                Dependencies
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Git/Git.html" >
                                Git
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Handmade Hero/Handmade Hero.html" >
                                Handmade Hero
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Linux/Linux.html" >
                                Linux
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Memory/Memory.html" >
                                Memory
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Multithreading/Multithreading.html" >
                                Multithreading
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/RegEx.html" >
                                RegEx
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Shells/Shells.html" >
                                Shells
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Things/Terminal/Terminal.html" >
                                Terminal
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Programming Languages
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Assembly - ASM.html" >
                                Assembly - ASM
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/C++/C++.html" >
                                C++
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/C.html" >
                                C
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/CSharp/CSharp.html" >
                                CSharp
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Go.html" >
                                Go
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Haxe.html" >
                                Haxe
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/JAI.html" >
                                JAI
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Java.html" >
                                Java
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Kotlin.html" >
                                Kotlin
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Lua.html" >
                                Lua
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Nim/Nim.html" >
                                Nim
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Odin/Odin.html" >
                                Odin
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Python.html" >
                                Python
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Rust/Rust.html" >
                                Rust
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Swift/Swift.html" >
                                Swift
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Programming Languages/Zig/Zig.html" >
                                Zig
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        WebDev
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/WebDev/WebDev.html" >
                                WebDev
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/HTML/HTML.html" >
                                HTML
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/HTMX.html" >
                                HTMX
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/WebAssembly - WASM/WebAssembly - WASM.html" >
                                WebAssembly - WASM
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/CSS/CSS.html" >
                                CSS
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/JavaScript/JavaScript.html" >
                                JavaScript
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/TypeScript.html" >
                                TypeScript
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/JavaScript - Frameworks and Libraries/JavaScript - Frameworks and Libraries.html" >
                                JavaScript - Frameworks and Libraries
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/JavaScript - Runtime Environments.html" >
                                JavaScript - Runtime Environments
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/Hugo/Hugo.html" >
                                Hugo
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/Static Site Generators.html" >
                                Static Site Generators
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/WebDev/HTML - Tests/HTML - Tests.html" >
                                HTML - Tests
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Databases
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Databases/Databases - MongoDB.html" >
                                Databases - MongoDB
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Databases/Databases - SQL - Relational/Databases - SQL - Relational.html" >
                                Databases - SQL - Relational
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Databases/Databases - Document Oriented.html" >
                                Databases - Document Oriented
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Databases/Databases - Object Oriented.html" >
                                Databases - Object Oriented
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Databases/Databases - ORMs.html" >
                                Databases - ORMs
							</a>
						</li>
					</ul>
				</details>
				<details
>
					<summary>
                        Electronics
					</summary>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Electronics/Electronics - Sources and Studies.html" >
                                Electronics - Sources and Studies
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Electronics/Electronics - Projects and Tutorials.html" >
                                Electronics - Projects and Tutorials
							</a>
						</li>
					</ul>
					<ul>
						<li>
							<a
								class="" 
								href="/studies/Electronics/Arduino.html" >
                                Arduino
							</a>
						</li>
					</ul>
				</details>
			</nav>
		</aside>
		<div
			id="central-wrapper" >
			<header
				id="central-header" >
			</header>
			<main>
				<article
					id="note-article" >
					<header>
						<h1>
                            GPU
						</h1>
						<p>
							<time
								datetime="2025-08-11" >
                                🕒 Created: 2025-08-11
							</time>
							<time
								datetime="2025-10-28" >
                                | Updated: 2025-10-28
							</time>
						</p>
					</header>
					<div
						id="note-content" >
<h3
	id="where-i-stopped" >
    Where I Stopped
</h3>
<h5
	id="bar" >
    BAR
</h5>
<ul>
	<li>
		<p>
            Jesse:
		</p>
		<ul>
			<li>
				<p>
                    <code>BAR_pcie_access_flags := vk.MemoryPropertyFlags{.DEVICE_LOCAL, .HOST_VISIBLE, .HOST_COHERENT}</code>
                    &nbsp;I use that for my UBO buffer
				</p>
			</li>
			<li>
				<p>
                    It's what the BAR is (and where &quot;resizable bar&quot; comes from if you've heard the term)
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Caio:
		</p>
		<ul>
			<li>
				<p>
                    Can it be 
                    <code>DEVICE_LOCAL</code>
                    &nbsp;and 
                    <code>HOST_VISIBLE</code>
                    &nbsp;at the same time? I assumed it was exclusive. How do you update the buffer?
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Jesse:
		</p>
		<ul>
			<li>
				<p>
                    Yes, within some limits
				</p>
			</li>
			<li>
				<p>
                    It's what the BAR is (and where &quot;resizable bar&quot; comes from if you've heard the term)
				</p>
			</li>
			<li>
				<p>
                    I just write through to the pointer 
                    <code>intrinsics.mem_copy_non_overlapping(rawptr(ubo_frame_01_ptr), &per_frame_ubo, size_of(per_frame_ubo))</code>
				</p>
			</li>
			<li>
				<p>
                    <code>ubo_frame_01_ptr</code>
                    &nbsp;ping pongs at an offset determined by the frame index
				</p>
			</li>
			<li>
				<p>
                    Because multiple frames can be in flight at once
				</p>
			</li>
			<li>
				<p>
                    They need different cameras
				</p>
			</li>
			<li>
				<p>
                    In practice this means I effectively have 2 UBOs I source from
				</p>
			</li>
			<li>
				<p>
                    I also have two sets of positions for each mesh
				</p>
			</li>
			<li>
				<p>
                    BAR is a small segment of CPU-addressable memory on the GPU that is also relatively high-performance read access from the GPU
				</p>
			</li>
			<li>
				<p>
                    You want that allocation to be very small
				</p>
			</li>
			<li>
				<p>
                    Because it's not virtualized
				</p>
			</li>
			<li>
				<p>
                    And if multiple applications want it, they cannot share
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Lee Michael:
		</p>
		<ul>
			<li>
				<p>
                    I had not heard of this! My last Vulkan app actually just assumed ReBAR, and I didn't imagine that would be a downside.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Jesse:
		</p>
		<ul>
			<li>
				<p>
                    Yeah, at least in Vulkan you can try to allocate upfront and if it fails, just use the ordinary fallback
				</p>
			</li>
			<li>
				<p>
                    So at least it won't crash in the middle of the application runtime
				</p>
			</li>
		</ul>
	</li>
</ul>
<h3
	id="about" >
    About
</h3>
<ul>
	<li>
		<p>
			<a
				href="https://www.youtube.com/watch?v=h9Z4oGN89MU" 
				class="external-link" 
				target="_blank" >
                GPUs Explained - Branch Education
			</a>
            .
		</p>
		<ul>
			<li>
				<p>
                    Cool.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h2
	id="execution-building-blocks" >
    Execution Building Blocks
</h2>
<ul>
	<li>
		<p>
            From smallest to largest.
		</p>
	</li>
</ul>
<h3
	id="thread" >
    Thread
</h3>
<ul>
	<li>
		<p>
            Has its own registers and private variables.
		</p>
	</li>
</ul>
<h3
	id="wave-warp" >
    Wave / Warp
</h3>
<ul>
	<li>
		<p>
            Fixed-size group of threads executed together in lockstep.
		</p>
	</li>
	<li>
		<p>
            These are 
			<strong>
                hardware
			</strong>
            &nbsp;scheduling units — the smallest batch of threads that can be executed together.
		</p>
	</li>
	<li>
		<p>
            The SM/CU scheduler runs one warp/wave at a time on its execution units.
		</p>
		<ul>
			<li>
				<p>
                    The SM does 
					<em>
                        not
					</em>
                    &nbsp;literally execute a whole warp in a single cycle always; the SM issues instructions for a warp and can interleave instructions from multiple warps to hide latency.
				</p>
			</li>
			<li>
				<p>
                    The warp is the smallest scheduling/issue granularity, but instruction dispatch and active lanes depend on pipeline and issue width.
				</p>
			</li>
			<li>
				<p>
                    Reconvergence is implemented by hardware (and compiler) mechanisms; divergent threads are masked and the SM executes each path serially until reconvergence.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Wavefront
			</strong>
            &nbsp;(AMD) or 
			<strong>
                Warp
			</strong>
            &nbsp;(NVIDIA).
		</p>
	</li>
	<li>
		<p>
            Common sizes:
		</p>
		<ul>
			<li>
				<p>
                    NVIDIA warp: 32 threads.
				</p>
			</li>
			<li>
				<p>
                    AMD Wavefront: 64 threads.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            These threads share a 
			<em>
                program counter
			</em>
            &nbsp;and execute the same instruction at the same time (SIMT model).
		</p>
	</li>
	<li>
		<p>
            If threads diverge in control flow, the hardware masks off threads not taking the current branch until they reconverge.
		</p>
	</li>
</ul>
<h5
	id="workgroup-api-abstraction" >
    Workgroup (API abstraction)
</h5>
<ul>
	<li>
		<p>
			<strong>
                Defined by you
			</strong>
            &nbsp;in Vulkan’s compute shader or GLSL/HLSL.
		</p>
	</li>
	<li>
		<p>
            Group of threads that can share 
			<em>
                shared memory
			</em>
            &nbsp;within a single SM/CU.
		</p>
	</li>
	<li>
		<p>
            A workgroup is scheduled to a single SM/CU for its lifetime while active, but a workgroup may be split across multiple SMs over time if the runtime re-schedules (e.g., after preemption or context switch).
		</p>
		<ul>
			<li>
				<p>
                    Practically, code semantics assume the workgroup runs on a single SM until completion.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Size: arbitrary (within hardware limits), e.g., 
            <code>local_size_x = 256</code>
            .
		</p>
	</li>
	<li>
		<p>
            Purpose: group of threads that:
		</p>
		<ul>
			<li>
				<p>
                    Can share 
					<strong>
                        shared memory / LDS
					</strong>
                    .
				</p>
			</li>
			<li>
				<p>
                    Can synchronize using 
                    <code>barrier()</code>
                    &nbsp;calls.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Hardware: The entire workgroup runs 
			<strong>
                within one SM/CU
			</strong>
            &nbsp;(so they can share its on-chip memory).
		</p>
	</li>
	<li>
		<p>
            Example:
		</p>
		<ul>
			<li>
				<p>
                    If you set 
                    <code>local_size_x = 256</code>
                    , that’s 256 threads in the workgroup.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Subgroup (API Abstraction)
			</strong>
		</p>
		<ul>
			<li>
				<p>
                    Subset of threads in a workgroup that maps to a warp/wave (e.g., 32 threads).
				</p>
			</li>
			<li>
				<p>
                    Enables warp-level operations (shuffles, reductions) 
					<em>
                        without shared memory
					</em>
                    .
				</p>
			</li>
			<li>
				<p>
                    Exposed in Vulkan/OpenCL; size is queried at runtime.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h3
	id="sm-cu" >
    SM / CU
</h3>
<ul>
	<li>
		<p>
			<strong>
                SM
			</strong>
            &nbsp;= 
			<em>
                Streaming Multiprocessor
			</em>
            &nbsp;(NVIDIA terminology).
		</p>
	</li>
	<li>
		<p>
			<strong>
                CU
			</strong>
            &nbsp;= 
			<em>
                Compute Unit
			</em>
            &nbsp;(AMD terminology).
		</p>
	</li>
	<li>
		<p>
            Hardware block that runs multiple warps/waves.
		</p>
	</li>
	<li>
		<p>
            This is the fundamental hardware block that executes shader threads.
		</p>
	</li>
	<li>
		<p>
            Has per-SM caches and shared memory.
		</p>
		<ul>
			<li>
				<p>
					<strong>
                        Registers
					</strong>
                    &nbsp;(not shared between SMs).
				</p>
			</li>
			<li>
				<p>
					<strong>
                        Shared memory
					</strong>
                    &nbsp;(LDS).
				</p>
			</li>
			<li>
				<p>
					<strong>
                        L1 cache
					</strong>
                    &nbsp;(per-SM).
				</p>
			</li>
			<li>
				<p>
                    Implication: If one SM’s L1 cache is filled with certain data, another SM won’t see it — coherence happens at L2.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Resource Partitioning
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Fixed registers/thread (e.g., 255 regs/thread on NVIDIA Ampere).
				</p>
			</li>
			<li>
				<p>
                    Shared memory configurable (e.g., 64–164 KB on NVIDIA).
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Concurrent Execution
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Runs multiple warps/waves simultaneously (e.g., 64 warps/SM on NVIDIA).
				</p>
			</li>
			<li>
				<p>
                    Hides latency via zero-cost warp switching.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Each SM/CU has
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Its own set of registers (private to threads assigned to it).
				</p>
			</li>
			<li>
				<p>
                    Its own shared memory / LDS (Local Data Store), accessible to all threads in a workgroup.
				</p>
			</li>
			<li>
				<p>
                    Access to L1 cache and special-function units (SFUs).
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Vulkan equivalent: A 
			<em>
                workgroup
			</em>
            &nbsp;in a compute shader runs entirely within one SM/CU.
		</p>
	</li>
</ul>
<h3
	id="tpc-gpc-nvidia-sa-amd" >
    TPC/GPC (NVIDIA) / SA (AMD)
</h3>
<ul>
	<li>
		<p>
			<strong>
                NVIDIA
			</strong>
            : &quot;Texture Processing Cluster&quot; (TPC) or &quot;Graphics Processing Cluster&quot; (GPC)
		</p>
		<ul>
			<li>
				<p>
                    Groups 2–8 SMs sharing raster/tessellation units.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                AMD
			</strong>
            : &quot;Shader Array&quot; (SA) in RDNA
		</p>
		<ul>
			<li>
				<p>
                    Groups 2 CUs sharing instruction cache/ray accelerators.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h3
	id="cluster" >
    Cluster
</h3>
<ul>
	<li>
		<p>
            A group of SMs/CUs that may share intermediate caches or specialized hardware.
		</p>
	</li>
	<li>
		<p>
            NVIDIA:
		</p>
		<ul>
			<li>
				<p>
                    Sometimes calls this a “TPC” (Texture Processing Cluster) or “GPC” (Graphics Processing Cluster) — names vary by generation.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            AMD:
		</p>
		<ul>
			<li>
				<p>
                    Uses “Shader Array” or “Workgroup Processor” as a cluster-like grouping.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Shared at cluster level: Sometimes texture units, geometry units, or a shared instruction cache.
		</p>
	</li>
</ul>
<h3
	id="gpu-die" >
    GPU Die
</h3>
<ul>
	<li>
		<p>
            Graphics Engine (e.g., AMD's Shader Engine, NVIDIA's GPC).
		</p>
	</li>
	<li>
		<p>
            Contains multiple clusters + fixed-function units (geometry, raster).
		</p>
	</li>
</ul>
<h3
	id="gpu" >
    GPU
</h3>
<ul>
	<li>
		<p>
            All clusters together, sharing the L2 cache and global memory.
		</p>
	</li>
</ul>
<h2
	id="specialized-units-amp-instructions" >
    Specialized units &amp; instructions
</h2>
<h3
	id="sfus-special-function-units" >
    SFUs (special function units)
</h3>
<ul>
	<li>
		<p>
            Note that transcendental operations (sin/cos, rsqrt) may be executed on SFUs with different latencies/throughput.
		</p>
	</li>
</ul>
<h3
	id="tensor-matrix-cores-ray-tracing-cores" >
    Tensor/Matrix cores, Ray-tracing cores
</h3>
<ul>
	<li>
		<p>
            Mention specialized units for matrix multiply/accumulate or ray traversal that change performance characteristics for algorithms that use them.
		</p>
	</li>
</ul>
<h3
	id="asynchronous-copies-dma-engines" >
    Asynchronous copies / DMA engines
</h3>
<ul>
	<li>
		<p>
            Add async copy mechanisms (device to shared, or staging) that allow overlap of memory transfer with compute, when supported.
		</p>
	</li>
</ul>
<h2
	id="memory" >
    Memory
</h2>
<ul>
	<li>
		<p>
            <img src="assets/image_20250812175721.png" width="525" >
            .
		</p>
	</li>
	<li>
		<p>
            Deep Seek:
		</p>
		<ul>
			<li>
				<p>
                    <img src="assets/image_20250812192004.png" width="1175" >
                    .
				</p>
			</li>
		</ul>
	</li>
</ul>
<h3
	id="registers" >
    Registers
</h3>
<ul>
	<li>
		<p>
			<strong>
                Physical Location
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    On-chip in each shader core.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Scope / Visibility
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Private to a single thread.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Registers are the fastest memory components on a GPU, comprising the register file that supplies data directly into the CUDA cores.
		</p>
	</li>
	<li>
		<p>
            A kernel function uses registers to store variables private to the thread and accessed frequently.
		</p>
	</li>
	<li>
		<p>
            Both registers and shared memory are 
			<em>
                on-chip memories
			</em>
            &nbsp;where variables residing in these memories can be accessed at very high speeds in a parallel manner.
		</p>
	</li>
	<li>
		<p>
            By leveraging registers effectively, data reuse can be maximized and performance can be optimized.
		</p>
	</li>
	<li>
		<p>
            Per-thread fast storage, not addressable from shaders as normal memory.
		</p>
	</li>
</ul>
<h3
	id="local" >
    Local
</h3>
<ul>
	<li>
		<p>
			<strong>
                Physical Location
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Off-chip in global memory.
				</p>
			</li>
			<li>
				<p>
                    “Local” in shader languages is a per-thread address space.
				</p>
			</li>
			<li>
				<p>
                    Physically it may be kept in registers, spilled to on-chip memory, or spilled to device memory (global DRAM) depending on register pressure and compiler decisions. Saying it is 
					<em>
                        always
					</em>
                    &nbsp;off-chip is misleading.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Scope / Visibility
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Private to a thread, but lives in DRAM
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Is private to each thread, but it’s slower than register memory.
		</p>
	</li>
</ul>
<h3
	id="shared-quotscratchquot" >
    Shared (&quot;scratch&quot;)
</h3>
<ul>
	<li>
		<p>
			<strong>
                Physical Location
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    On-chip in each compute unit (SM/Wave/Compute Unit).
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Scope / Visibility
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Shared by threads in a workgroup.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Low-latency buffer for thread-group cooperation. Useful for explicitly managed caches and reductions.
		</p>
	</li>
	<li>
		<p>
            Is accessible to all threads in the same block and lasts for the block’s lifetime.
		</p>
	</li>
</ul>
<h3
	id="l1-cache" >
    L1 Cache
</h3>
<ul>
	<li>
		<p>
			<strong>
                Physical Location
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    On-chip per-SM/CU.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Scope / Visibility
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Caches global/shared accesses
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            L1 or level 1 cache is attached to the processor core directly.
		</p>
	</li>
	<li>
		<p>
            It functions as a backup storage area when the amount of active data exceeds the capacity of a SM’s register file.
		</p>
	</li>
	<li>
		<p>
            Small, very low-latency caches often configurable (texture vs load/store/shared) on many architectures; behavior and size vary by vendor/generation.
		</p>
	</li>
	<li>
		<p>
            L1 may be partitioned between shared memory and cache.
		</p>
	</li>
</ul>
<h3
	id="l2-cache" >
    L2 Cache
</h3>
<ul>
	<li>
		<p>
			<strong>
                Physical Location
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    On-chip, shared across GPU.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Scope / Visibility
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    GPU-wide.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            L2 or level 2 cache is larger and often shared across SMs.
		</p>
	</li>
	<li>
		<p>
            Unlike the L1 cache(s), there is only 
			<strong>
                one
			</strong>
            &nbsp;L2 cache.
		</p>
	</li>
	<li>
		<p>
            Larger cache shared across multiple SMs/CUs; services DRAM, texture and load/store requests; a common coherence point for the chip.
		</p>
	</li>
</ul>
<h3
	id="constant-cache" >
    Constant Cache
</h3>
<ul>
	<li>
		<p>
            Constant cache captures frequently used variables for each kernel leading to improved performance.
		</p>
	</li>
	<li>
		<p>
            When designing memory systems for massively parallel processors, there will be constant memory variables. Rewriting these variables would be redundant and pointless. Thus, a specialized memory system like the constant cache eliminates the need for computationally costly hardware logic.
		</p>
	</li>
</ul>
<h3
	id="global-memory-vram-on-discrete-gpus" >
    Global Memory (VRAM on Discrete GPUs)
</h3>
<ul>
	<li>
		<p>
			<strong>
                Physical Location
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Off-chip DRAM (VRAM on discrete GPUs, DRAM on integrated GPUs)
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Scope / Visibility
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    GPU-wide.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            “Global memory” is a 
			<em>
                logical/architectural term
			</em>
            , “VRAM” is a 
			<em>
                physical/hardware term
			</em>
            .
		</p>
	</li>
	<li>
		<p>
            On discrete GPUs, this 
			<em>
                usually
			</em>
            &nbsp;maps to VRAM.
		</p>
	</li>
	<li>
		<p>
            On integrated GPUs or APUs (where GPU and CPU share DRAM), “global memory” is just 
			<em>
                system RAM
			</em>
            .
		</p>
		<ul>
			<li>
				<p>
                    In that case, there is no separate VRAM, but the hardware still calls it “global” because it’s visible to all threads.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Holds data that lasts for the duration of the grid/host.
		</p>
	</li>
	<li>
		<p>
            All threads and the host have access to global memory.
		</p>
	</li>
	<li>
		<p>
            High-bandwidth, higher-latency global memory; large capacity.
		</p>
	</li>
	<li>
		<p>
            Some platforms provide unified system/GPU memory where the GPU uses system DRAM.
		</p>
	</li>
</ul>
<h3
	id="texture-memory" >
    Texture memory
</h3>
<ul>
	<li>
		<p>
			<strong>
                Physical Location
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    On-chip, specialized hardware
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Scope / Visibility
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Optimized for spatial locality (texture) or broadcast (constant)
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            Is another read-only memory type ideal for physically adjacent data access. Its use can mitigate memory traffic and increase performance compared to global memory.
		</p>
	</li>
</ul>
<h2
	id="memory-cpu-lt-gt-gpu" >
    Memory: CPU &lt;-&gt; GPU
</h2>
<h5
	id="host-visible-physical-memory" >
    Host-Visible Physical Memory
</h5>
<ul>
	<li>
		<p>
			<strong>
                Discrete GPUs
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
					<strong>
                        System RAM
					</strong>
                    &nbsp;allocated by the driver and 
					<strong>
                        mapped into the GPU’s address space
					</strong>
                    &nbsp;via PCIe BAR (Base Address Register).
				</p>
			</li>
			<li>
				<p>
                    Or a 
					<strong>
                        special region of VRAM
					</strong>
                    &nbsp;that is directly mapped into CPU address space via PCIe — but this is rare for large allocations because PCIe mapping windows are small.
				</p>
			</li>
			<li>
				<p>
                    If it’s 
					<strong>
                        system RAM
					</strong>
                    &nbsp;→ CPU reads/writes are as fast as normal RAM, but GPU access is limited by PCIe bandwidth/latency.
				</p>
			</li>
			<li>
				<p>
                    If it’s 
					<strong>
                        mapped VRAM
					</strong>
                    &nbsp;→ GPU access is fast, but CPU writes/reads are slow compared to normal RAM (still crossing PCIe).
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Integrated GPUs / APUs
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Host-visible memory is simply 
					<strong>
                        normal DRAM
					</strong>
                    &nbsp;that both CPU and GPU share.
				</p>
			</li>
			<li>
				<p>
                    No PCIe transfer is needed — the GPU’s memory controller directly accesses the same DIMMs as the CPU.
				</p>
			</li>
			<li>
				<p>
                    Performance difference between CPU and GPU access is smaller here, but they still contend for bandwidth.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            <code>HOST_VISIBLE</code>
		</p>
		<ul>
			<li>
				<p>
                    CPU can map the memory with 
                    <code>vkMapMemory</code>
                    &nbsp;and read/write it.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Why not make all VRAM host-visible?
			</strong>
		</p>
		<ul>
			<li>
				<p>
                    Mapping all VRAM to the CPU would waste PCIe BAR address space and could reduce GPU performance by forcing VRAM into a less optimal configuration.
				</p>
			</li>
			<li>
				<p>
                    Host-visible VRAM is generally slower for the GPU than purely device-local VRAM because of cacheability and controller constraints.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="host-coherent" >
    Host-Coherent
</h5>
<ul>
	<li>
		<p>
			<strong>
                Host-coherent memory
			</strong>
            &nbsp;means CPU and GPU share the same 
			<em>
                coherent view
			</em>
            &nbsp;of the data — no explicit flush/invalidate needed.
		</p>
		<ul>
			<li>
				<p>
                    Often backed by system RAM (on discrete GPUs, that’s typical for PCIe-mapped system memory).
				</p>
			</li>
			<li>
				<p>
                    On integrated GPUs, system DRAM is naturally coherent if the architecture supports it.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Non-coherent host-visible memory
			</strong>
            &nbsp;means CPU and GPU caches aren’t kept in sync automatically.
		</p>
		<ul>
			<li>
				<p>
                    Requires manual flush/invalidate via Vulkan commands.
				</p>
			</li>
			<li>
				<p>
                    This often happens when host-visible memory is still on the GPU’s side of the PCIe mapping.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            <code>HOST_COHERENT</code>
		</p>
		<ul>
			<li>
				<p>
                    CPU writes/reads are automatically visible to the GPU without 
                    <code>vkFlushMappedMemoryRanges</code>
                    &nbsp;/ 
                    <code>vkInvalidateMappedMemoryRanges</code>
                    .
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="properties" >
    Properties
</h5>
<ul>
	<li>
		<p>
            <code>HOST_CACHED</code>
		</p>
		<ul>
			<li>
				<p>
                    CPU accesses are cached in the CPU’s cache hierarchy (good for reads, but may need explicit flush for writes).
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            <code>DEVICE_LOCAL</code>
		</p>
		<ul>
			<li>
				<p>
                    Memory is physically close to the GPU (VRAM on discrete GPUs, DRAM on integrated GPUs).
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="patterns" >
    Patterns
</h5>
<ul>
	<li>
		<p>
			<strong>
                Discrete GPUs
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Allocate a 
					<strong>
                        host-visible
					</strong>
                    &nbsp;memory type (often not the fastest for GPU access) for small or frequently updated buffers.
				</p>
			</li>
			<li>
				<p>
                    Host-visible memory is limited and slower for GPU access.
				</p>
			</li>
			<li>
				<p>
                    Best practice: use it for small, dynamic data; keep heavy GPU workloads in device-local VRAM.
				</p>
			</li>
			<li>
				<p>
                    For large transfers, use staging buffers and 
                    <code>vkCmdCopyBuffer/Image</code>
                    .
				</p>
			</li>
			<li>
				<p>
                    Or use a 
					<strong>
                        staging buffer
					</strong>
                    : CPU writes to host-visible memory, then issues a GPU copy to 
					<strong>
                        device-local
					</strong>
                    &nbsp;VRAM.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Integrated GPUs
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    GPU and CPU share the same physical DRAM.
				</p>
			</li>
			<li>
				<p>
                    Host-visible memory is the same physical memory the GPU uses for its “VRAM” (there’s no separate pool).
				</p>
			</li>
			<li>
				<p>
                    Access is faster than PCIe but still slower than on-chip GPU caches.
				</p>
			</li>
			<li>
				<p>
                    The penalty for using host-visible memory is much smaller.
				</p>
			</li>
			<li>
				<p>
                    Sometimes you can use the same allocation for both CPU and GPU to avoid copies.
				</p>
			</li>
			<li>
				<p>
                    Vulkan's 
                    <code>VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT</code>
                    &nbsp;and 
                    <code>VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT</code>
                    &nbsp;can be set together here — meaning the same allocation is optimal for both CPU and GPU access.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h5
	id="examples-of-data-flow" >
    Examples of Data Flow
</h5>
<ul>
	<li>
		<p>
			<strong>
                Example
			</strong>
            : CPU updates vertex buffer for GPU rendering
		</p>
		<ol>
			<li>
				<p>
                    CPU maps a host-visible buffer (
                    <code>vkMapMemory</code>
                    ).
				</p>
			</li>
			<li>
				<p>
                    CPU writes new vertex data.
				</p>
			</li>
			<li>
				<p>
                    If memory is 
					<strong>
                        not coherent
					</strong>
                    &nbsp;→ call 
                    <code>vkFlushMappedMemoryRanges</code>
                    .
				</p>
			</li>
			<li>
				<p>
                    Use a pipeline barrier or proper synchronization so GPU sees the new data.
				</p>
			</li>
			<li>
				<p>
                    GPU reads from the buffer during rendering.
				</p>
			</li>
		</ol>
	</li>
	<li>
		<p>
			<strong>
                Example
			</strong>
            : GPU writes results for CPU readback
		</p>
		<ol>
			<li>
				<p>
                    GPU writes to a host-visible buffer (e.g., compute shader output).
				</p>
			</li>
			<li>
				<p>
                    Insert a barrier to ensure the writes are complete and visible.
				</p>
			</li>
			<li>
				<p>
                    If memory is 
					<strong>
                        not coherent
					</strong>
                    &nbsp;→ call 
                    <code>vkInvalidateMappedMemoryRanges</code>
                    .
				</p>
			</li>
			<li>
				<p>
                    CPU reads the data via the mapped pointer.
				</p>
			</li>
		</ol>
	</li>
</ul>
<h2
	id="cache" >
    Cache
</h2>
<h5
	id="coalescing-contiguous-access" >
    Coalescing / contiguous access
</h5>
<ul>
	<li>
		<p>
            A coalesced memory transaction is one in which all of the threads in a half-warp access global memory at the same time. The correct way to do it is just have consecutive threads access consecutive memory addresses.
		</p>
	</li>
	<li>
		<p>
            GPUs batch many threads (warps/wavefronts).
		</p>
	</li>
	<li>
		<p>
            If threads in a group load adjacent addresses, the hardware can merge requests into fewer memory transactions (coalescing).
		</p>
	</li>
	<li>
		<p>
            Non-sequential or strided accesses increase transactions and reduce effective bandwidth.
		</p>
	</li>
	<li>
		<p>
			<a
				href="https://homepages.math.uic.edu/~jan/mcs572f16/mcs572notes/lec35.html?utm_source=chatgpt.com" 
				class="external-link" 
				target="_blank" >
                Memory Coalescing Techniques
			</a>
            .
		</p>
	</li>
</ul>
<h5
	id="cache-lines-and-alignment" >
    Cache lines and alignment
</h5>
<ul>
	<li>
		<p>
            Accesses are serviced in cache-line granularity; unaligned or small scattered loads can cause full-line fetches or multiple lines, increasing bandwidth pressure. Designing buffer layouts for aligned, contiguous reads reduces misses.
		</p>
	</li>
</ul>
<h5
	id="bank-conflicts-shared-memory" >
    Bank conflicts (shared memory)
</h5>
<ul>
	<li>
		<p>
            When many threads access the same bank with conflicting addresses, accesses serialize. Layout transforms (padding/transpose) can avoid conflicts.
		</p>
	</li>
</ul>
<h5
	id="texture-texture-caches" >
    Texture/texture caches
</h5>
<ul>
	<li>
		<p>
            Sampled image access can use specialized caches with different locality assumptions versus raw buffer loads; memory layout (tiling) influences cache efficiency.
		</p>
	</li>
</ul>
<h2
	id="gpu-va-virtual-address" >
    GPU VA (Virtual Address)
</h2>
<ul>
	<li>
		<p>
            It's a virtual pointer inside the GPU’s virtual address space that the GPU and drivers use to reference device memory.
		</p>
	</li>
	<li>
		<p>
            It is not a physical address; the GPU MMU translates it to physical backing memory.
		</p>
	</li>
</ul>
<h5
	id="64-bit-vs-32-bit-va" >
    64-bit vs 32-bit VA
</h5>
<ul>
	<li>
		<p>
			<strong>
                64-bit
			</strong>
            : Default for general buffers.
		</p>
	</li>
	<li>
		<p>
			<strong>
                32-bit
			</strong>
            : Used for descriptors (e.g., 
            <code>VK_EXT_descriptor_buffer</code>
            &nbsp;saves memory).
		</p>
	</li>
</ul>
<h5
	id="mmu-translation" >
    MMU Translation
</h5>
<ul>
	<li>
		<p>
            GPU VA → Physical address (VRAM or system RAM) via page tables.
		</p>
	</li>
	<li>
		<p>
			<strong>
                Fault Handling
			</strong>
            : Driver-managed page faults (sparse residency).
		</p>
	</li>
</ul>
<h5
	id="vulkan" >
    Vulkan
</h5>
<ul>
	<li>
		<p>
			<strong>
                Feature exposure
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Vulkan exposes GPU virtual addresses via a feature/extension set (commonly 
                    <code>VK_KHR_buffer_device_address</code>
                    &nbsp;/ Vulkan 1.2 core feature). An implementation must advertise and the application must enable the corresponding feature(s) at device creation to use GPU addresses.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Buffer creation and usage bits
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    To obtain a GPU VA for a buffer, the buffer must be created with the shader/device-address usage bit (e.g. 
                    <code>VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT</code>
                    ) so the implementation knows the buffer will be addressable.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Memory binding
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    The buffer’s memory must be allocated and bound as usual.
				</p>
			</li>
			<li>
				<p>
                    The GPU VA refers to the buffer object while that memory is bound.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Querying the address
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    Vulkan provides an API (e.g. 
                    <code>vkGetBufferDeviceAddress</code>
                    &nbsp;with a 
                    <code>VkBufferDeviceAddressInfo</code>
                    ) that returns a 64-bit GPU address for the buffer or memory object. That value is a device-virtual address suitable for use by GPU code or by other Vulkan objects that accept device addresses (acceleration structures, device address based pointer data, etc.).
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Using the address in shaders / GPU code
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    The address can be passed to shaders (e.g., as a 64-bit integer pushed into a descriptor or push constant) and used by shaders that support buffer-address operations (SPIR-V features / shader capability required). Ray-tracing acceleration structures and some GPU pointer-chasing data structures commonly rely on device addresses.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
			<strong>
                Driver/GPU translation and constraints
			</strong>
            :
		</p>
		<ul>
			<li>
				<p>
                    The GPU VA is translated by the GPU MMU. The value is only valid while the buffer’s memory remains bound and resident. If memory is freed, reallocated, or pages are made non-resident (sparse binding), dereferencing the GPU VA causes undefined behavior or faults.
				</p>
			</li>
		</ul>
	</li>
	<li>
		<p>
            <code>VK_EXT_descriptor_buffer</code>
            :
		</p>
		<ul>
			<li>
				<p>
                    On some drivers, descriptor buffers live in a restricted GPU VA space, which allows those drivers to only spend 32-bits instead of 64-bits to bind a descriptor VA.
				</p>
			</li>
			<li>
				<p>
                    This VA range is precious. On these drivers, you’ll likely see new memory types that allocate 32-bit VA under the hood.
				</p>
			</li>
		</ul>
	</li>
</ul>
<h2
	id="tiled-gpus" >
    Tiled-GPUs
</h2>
<ul>
	<li>
		<p>
            <img src="assets/image_20250930085522.png" width="576" >
            .
		</p>
	</li>
</ul>

					</div>
					<footer
						id="previous-next" >
						<a
							href="/studies/Graphics Programming/GLSL/GLSL.html" >
                            &nbsp;&lsaquo; Previous
						</a>
						<a
							href="/studies/Graphics Programming/OpenGL/OpenGL.html" >
                            Next &rsaquo; 
						</a>
					</footer>
				</article>
			</main>
			<footer
				id="central-footer" >
                🧑‍💻 built by and copyright
				<a
					href="https://github.com/caioraphael1" 
					target="_blank" >
                    Caio Raphael
				</a>
                📅 2025-10-21 .&nbsp;&nbsp;2025-10-31 🚀
			</footer>
		</div>
		<aside
			id="right-sidebar" >
			<nav
				id="table-of-contents" >
				<strong>
                    On this page
				</strong>
				<ul>
					<ul>
						<li>
							<a
								href="#where-i-stopped" >
                                Where I Stopped
							</a>
						</li>
						<li>
							<a
								href="#about" >
                                About
							</a>
						</li>
					</ul>
					<li>
						<a
							href="#execution-building-blocks" >
                            Execution Building Blocks
						</a>
						<ul>
							<li>
								<a
									href="#thread" >
                                    Thread
								</a>
							</li>
							<li>
								<a
									href="#wave-warp" >
                                    Wave / Warp
								</a>
							</li>
							<li>
								<a
									href="#sm-cu" >
                                    SM / CU
								</a>
							</li>
							<li>
								<a
									href="#tpc-gpc-nvidia-sa-amd" >
                                    TPC/GPC (NVIDIA) / SA (AMD)
								</a>
							</li>
							<li>
								<a
									href="#cluster" >
                                    Cluster
								</a>
							</li>
							<li>
								<a
									href="#gpu-die" >
                                    GPU Die
								</a>
							</li>
							<li>
								<a
									href="#gpu" >
                                    GPU
								</a>
							</li>
						</ul>
					</li>
					<li>
						<a
							href="#specialized-units-amp-instructions" >
                            Specialized units &amp; instructions
						</a>
						<ul>
							<li>
								<a
									href="#sfus-special-function-units" >
                                    SFUs (special function units)
								</a>
							</li>
							<li>
								<a
									href="#tensor-matrix-cores-ray-tracing-cores" >
                                    Tensor/Matrix cores, Ray-tracing cores
								</a>
							</li>
							<li>
								<a
									href="#asynchronous-copies-dma-engines" >
                                    Asynchronous copies / DMA engines
								</a>
							</li>
						</ul>
					</li>
					<li>
						<a
							href="#memory" >
                            Memory
						</a>
						<ul>
							<li>
								<a
									href="#registers" >
                                    Registers
								</a>
							</li>
							<li>
								<a
									href="#local" >
                                    Local
								</a>
							</li>
							<li>
								<a
									href="#shared-quotscratchquot" >
                                    Shared (&quot;scratch&quot;)
								</a>
							</li>
							<li>
								<a
									href="#l1-cache" >
                                    L1 Cache
								</a>
							</li>
							<li>
								<a
									href="#l2-cache" >
                                    L2 Cache
								</a>
							</li>
							<li>
								<a
									href="#constant-cache" >
                                    Constant Cache
								</a>
							</li>
							<li>
								<a
									href="#global-memory-vram-on-discrete-gpus" >
                                    Global Memory (VRAM on Discrete GPUs)
								</a>
							</li>
							<li>
								<a
									href="#texture-memory" >
                                    Texture memory
								</a>
							</li>
						</ul>
					</li>
					<li>
						<a
							href="#memory-cpu-lt-gt-gpu" >
                            Memory: CPU &lt;-&gt; GPU
						</a>
						<ul>
						</ul>
					</li>
					<li>
						<a
							href="#cache" >
                            Cache
						</a>
						<ul>
						</ul>
					</li>
					<li>
						<a
							href="#gpu-va-virtual-address" >
                            GPU VA (Virtual Address)
						</a>
						<ul>
						</ul>
					</li>
					<li>
						<a
							href="#tiled-gpus" >
                            Tiled-GPUs
						</a>
					</li>
				</ul>
			</nav>
		</aside>
		<script
			src="/static/studies.js" >
		</script>
	</body>
</html>
